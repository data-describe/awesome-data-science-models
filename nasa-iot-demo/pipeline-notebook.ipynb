{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the template file for creating the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./pipeline/sensor_training_pipeline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./pipeline/sensor_training_pipeline.py\n",
    "import os\n",
    "from func_components import load_raw_data\n",
    "from func_components import split_data\n",
    "from func_components import disp_loss\n",
    "from jinja2 import Template\n",
    "import kfp\n",
    "from kfp.components import func_to_container_op\n",
    "from kfp.dsl.types import Dict\n",
    "from kfp.dsl.types import GCPProjectID\n",
    "from kfp.dsl.types import GCPRegion\n",
    "from kfp.dsl.types import GCSPath\n",
    "from kfp.dsl.types import String\n",
    "from kfp.gcp import use_gcp_secret\n",
    "\n",
    "# Defaults and environment settings\n",
    "BASE_IMAGE = os.getenv('BASE_IMAGE')\n",
    "TRAINER_IMAGE = os.getenv('TRAINER_IMAGE')\n",
    "DD_IMAGE = os.getenv('DD_IMAGE')\n",
    "RUNTIME_VERSION = os.getenv('RUNTIME_VERSION')\n",
    "PYTHON_VERSION = os.getenv('PYTHON_VERSION')\n",
    "COMPONENT_URL_SEARCH_PREFIX = os.getenv('COMPONENT_URL_SEARCH_PREFIX')\n",
    "USE_KFP_SA = os.getenv('USE_KFP_SA')\n",
    "\n",
    "# Create component factories\n",
    "component_store = kfp.components.ComponentStore(\n",
    "    local_search_paths=None, url_search_prefixes=[COMPONENT_URL_SEARCH_PREFIX])\n",
    "\n",
    "# Create all the component ops\n",
    "caip_train_op = component_store.load_component('ml_engine/train')\n",
    "\n",
    "retrieve_raw_data_op = func_to_container_op(\n",
    "    load_raw_data, base_image=BASE_IMAGE)\n",
    "\n",
    "split_preprocess_data_op = func_to_container_op(\n",
    "    split_data, base_image=BASE_IMAGE)\n",
    "\n",
    "disp_loss_op = func_to_container_op(\n",
    "    disp_loss)\n",
    "\n",
    "def datadescribe_op(gcs_root, filepath):\n",
    "    return kfp.dsl.ContainerOp(\n",
    "        name='Run_Data_Decsribe',\n",
    "        #image = 'gcr.io/mwpmltr/rrusson_kubeflow_datadescribe:v1',\n",
    "        image = DD_IMAGE,\n",
    "        arguments=[\n",
    "            '--gcs_root', gcs_root,\n",
    "            '--file', filepath\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "# Define the pipeline\n",
    "@kfp.dsl.pipeline(\n",
    "    name='Bearing Sensor Data Training',\n",
    "    description='The pipeline for training and deploying an anomaly detector based on an autoencoder')\n",
    "\n",
    "def pipeline_run(project_id,\n",
    "                 region,\n",
    "                 source_bucket_name, \n",
    "                 prefix,\n",
    "                 dest_bucket_name,\n",
    "                 dest_file_name,\n",
    "                 gcs_root=\"gs://rrusson-kubeflow-test\",\n",
    "                 dataset_location='US'):\n",
    "    \n",
    "    # Read in the raw sensor data from the public dataset and load in the project bucket\n",
    "    raw_data = retrieve_raw_data_op(source_bucket_name,\n",
    "                                    prefix,\n",
    "                                    dest_bucket_name,\n",
    "                                    dest_file_name)\n",
    "    \n",
    "    \n",
    "    # Prepare some output from Data Describe\n",
    "    dd_out = datadescribe_op(gcs_root, \n",
    "                             raw_data.outputs['dest_file_name'])\n",
    "    \n",
    "    \n",
    "    # Preprocess and split the raw data by time\n",
    "    split_data = split_preprocess_data_op(raw_data.outputs['dest_bucket_name'],\n",
    "                                          raw_data.outputs['dest_file_name'],\n",
    "                                          '2004-02-15 12:52:39',\n",
    "                                          True)\n",
    "    \n",
    "    # Set up the training args\n",
    "    train_args = [\"--bucket\", split_data.outputs['bucket_name'],\n",
    "                  \"--train_file\", split_data.outputs['train_dest_file'],\n",
    "                  \"--test_file\", split_data.outputs['test_dest_file']\n",
    "                 ]\n",
    "    \n",
    "    job_dir = \"{0}/{1}/{2}\".format(gcs_root, 'jobdir', kfp.dsl.RUN_ID_PLACEHOLDER)\n",
    "    \n",
    "    # Train the model on AI Platform\n",
    "    train_model = caip_train_op(project_id,\n",
    "                                region=region,\n",
    "                                master_image_uri=TRAINER_IMAGE,\n",
    "                                job_id_prefix='anomaly-detection_',\n",
    "                                job_dir=job_dir,\n",
    "                                args=train_args)\n",
    "    \n",
    "    # Expose artifacts to the Kubeflow UI\n",
    "    disp_loss_img = disp_loss_op(train_model.outputs['job_id'])\n",
    "    disp_loss_dist_img = disp_loss_op(train_model.outputs['job_id'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "ENDPOINT = '629f42fe6886c9d5-dot-us-central2.pipelines.googleusercontent.com'\n",
    "ARTIFACT_STORE_URI = 'gs://rrusson-kubeflow-test'\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the base image and load it into gcr.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME='rrusson_kubeflow_base'\n",
    "TAG='v1'\n",
    "BASE_IMAGE='gcr.io/{}/{}:{}'.format(PROJECT_ID, IMAGE_NAME, TAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T RUN THIS IF THE IMAGE EXISTS!\n",
    "#!gcloud builds submit --timeout 15m --tag $BASE_IMAGE base_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the training image from the base image and load it into the gcr.io (maybe just have one image?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME='rrusson_kubeflow_tf2_trainer'\n",
    "TAG='v5'\n",
    "TRAINER_IMAGE='gcr.io/{}/{}:{}'.format(PROJECT_ID, IMAGE_NAME, TAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T RUN THIS IF THE IMAGE EXISTS!\n",
    "#!gcloud builds submit --timeout 15m --tag $TRAINER_IMAGE train_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Data Describe image from the base image and load it into gcr.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME='rrusson_kubeflow_datadescribe'\n",
    "TAG='v1'\n",
    "DD_IMAGE='gcr.io/{}/{}:{}'.format(PROJECT_ID, IMAGE_NAME, TAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T RUN THIS IF THE IMAGE EXISTS!\n",
    "#!gcloud builds submit --timeout 15m --tag $DD_IMAGE dd_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: USE_KFP_SA=False\n",
      "env: BASE_IMAGE=gcr.io/mwpmltr/rrusson_kubeflow_base:v1\n",
      "env: TRAINER_IMAGE=gcr.io/mwpmltr/rrusson_kubeflow_tf2_trainer:v5\n",
      "env: COMPONENT_URL_SEARCH_PREFIX=https://raw.githubusercontent.com/kubeflow/pipelines/0.2.5/components/gcp/\n",
      "env: RUNTIME_VERSION=1.15\n",
      "env: PYTHON_VERSION=3.7\n"
     ]
    }
   ],
   "source": [
    "USE_KFP_SA = False\n",
    "\n",
    "COMPONENT_URL_SEARCH_PREFIX = 'https://raw.githubusercontent.com/kubeflow/pipelines/0.2.5/components/gcp/'\n",
    "RUNTIME_VERSION = '1.15'\n",
    "PYTHON_VERSION = '3.7'\n",
    "\n",
    "%env USE_KFP_SA={USE_KFP_SA}\n",
    "%env BASE_IMAGE={BASE_IMAGE}\n",
    "%env TRAINER_IMAGE={TRAINER_IMAGE}\n",
    "%env DD_IMAGE={DD_IMAGE}\n",
    "%env COMPONENT_URL_SEARCH_PREFIX={COMPONENT_URL_SEARCH_PREFIX}\n",
    "%env RUNTIME_VERSION={RUNTIME_VERSION}\n",
    "%env PYTHON_VERSION={PYTHON_VERSION}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dsl-compile --py pipeline/sensor_training_pipeline.py --output sensor_training_pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the Pipeline in AI Platform Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline aa671d0b-b5e8-4137-b5fa-329fc35557d7 has been submitted\n",
      "\n",
      "Pipeline Details\n",
      "------------------\n",
      "ID           aa671d0b-b5e8-4137-b5fa-329fc35557d7\n",
      "Name         bearing_sensor_anomaly_v1.0\n",
      "Description\n",
      "Uploaded at  2020-12-04T17:05:52+00:00\n",
      "+--------------------+----------------------------+\n",
      "| Parameter Name     | Default Value              |\n",
      "+====================+============================+\n",
      "| project_id         |                            |\n",
      "+--------------------+----------------------------+\n",
      "| region             |                            |\n",
      "+--------------------+----------------------------+\n",
      "| source_bucket_name |                            |\n",
      "+--------------------+----------------------------+\n",
      "| prefix             |                            |\n",
      "+--------------------+----------------------------+\n",
      "| dest_bucket_name   |                            |\n",
      "+--------------------+----------------------------+\n",
      "| dest_file_name     |                            |\n",
      "+--------------------+----------------------------+\n",
      "| gcs_root           | gs://rrusson-kubeflow-test |\n",
      "+--------------------+----------------------------+\n",
      "| dataset_location   | US                         |\n",
      "+--------------------+----------------------------+\n"
     ]
    }
   ],
   "source": [
    "PIPELINE_NAME='bearing_sensor_anomaly_v1.0'\n",
    "\n",
    "!kfp --endpoint $ENDPOINT pipeline upload \\\n",
    "-p $PIPELINE_NAME \\\n",
    "sensor_training_pipeline.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+-------------------------------------------------+---------------------------+\n",
      "| Pipeline ID                          | Name                                            | Uploaded at               |\n",
      "+======================================+=================================================+===========================+\n",
      "| 8f258509-2c2b-4179-8950-38d6fa5280e4 | bearing_sensor_anomaly_v8                       | 2020-12-04T04:36:41+00:00 |\n",
      "+--------------------------------------+-------------------------------------------------+---------------------------+\n",
      "| fe571e93-1965-4c1f-8afc-a7f5059cc03b | bearing_sensor_anomaly_v7                       | 2020-12-04T03:56:55+00:00 |\n",
      "+--------------------------------------+-------------------------------------------------+---------------------------+\n",
      "| b9d3a470-891f-4b5e-b2bb-d02fbf929816 | bearing_sensor_anomaly_v6                       | 2020-12-03T20:34:57+00:00 |\n",
      "+--------------------------------------+-------------------------------------------------+---------------------------+\n",
      "| 5c85e06e-0a59-44c1-b730-9690fd270bc6 | bearing_sensor_anomaly_v5                       | 2020-12-03T18:51:30+00:00 |\n",
      "+--------------------------------------+-------------------------------------------------+---------------------------+\n",
      "| 506c600d-ce1b-4ac5-9c5c-00d99925eb3c | bearing_sensor_anomaly_v4                       | 2020-12-03T18:21:22+00:00 |\n",
      "+--------------------------------------+-------------------------------------------------+---------------------------+\n",
      "| c6df4bac-ecf1-4545-8671-320824b86d4b | [Tutorial] DSL - Control structures             | 2020-12-02T20:28:42+00:00 |\n",
      "+--------------------------------------+-------------------------------------------------+---------------------------+\n",
      "| 3627955d-7130-4b68-aef7-6424eee323b1 | [Tutorial] Data passing in python components    | 2020-12-02T20:28:41+00:00 |\n",
      "+--------------------------------------+-------------------------------------------------+---------------------------+\n",
      "| 3657dde6-86d0-4438-9e6a-0d955c24f3f3 | [Demo] TFX - Iris classification pipeline       | 2020-12-02T20:28:40+00:00 |\n",
      "+--------------------------------------+-------------------------------------------------+---------------------------+\n",
      "| c8cf0c71-12e0-475d-a971-044a436586fc | [Demo] TFX - Taxi tip prediction model trainer  | 2020-12-02T20:28:38+00:00 |\n",
      "+--------------------------------------+-------------------------------------------------+---------------------------+\n",
      "| b5489501-ec7d-4363-9a33-fec5391dc8b5 | [Demo] XGBoost - Training with confusion matrix | 2020-12-02T20:28:37+00:00 |\n",
      "+--------------------------------------+-------------------------------------------------+---------------------------+\n"
     ]
    }
   ],
   "source": [
    "!kfp --endpoint $ENDPOINT pipeline list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit a Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_ID='c9cda641-e37b-422f-a195-57e77d504f91'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = 'Train Anomaly Detector'\n",
    "RUN_ID = 'Run_001'\n",
    "SOURCE_BUCKET_NAME = 'amazing-public-data'\n",
    "PREFIX = 'bearing_sensor_data/bearing_sensor_data/'\n",
    "DEST_BUCKET_NAME = 'rrusson-kubeflow-test'\n",
    "DEST_FILE_NAME = 'raw_data_v3.csv'\n",
    "\n",
    "GCS_STAGING_PATH = '{}/staging'.format(ARTIFACT_STORE_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary update sequence element #0 has length 1; 2 is required\n"
     ]
    }
   ],
   "source": [
    "!kfp --endpoint $ENDPOINT run submit \\\n",
    "-e $EXPERIMENT_NAME \\\n",
    "-r $RUN_ID \\\n",
    "-p $PIPELINE_ID \\\n",
    "project_id=$PROJECT_ID \\\n",
    "gcs_root=$GCS_STAGING_PATH \\\n",
    "region=$REGION \\\n",
    "source_bucket_name=$SOURCE_BUCKET_NAME \\\n",
    "prefix=$PREFIX \\\n",
    "dest_bucket_name=$DEST_BUCKET_NAME \\\n",
    "DEST_FILE_NAME=$DEST_FILE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mwpmltr'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
