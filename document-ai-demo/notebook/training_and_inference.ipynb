{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de667a89",
   "metadata": {},
   "source": [
    "# Notebook for Training and Running Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "403441f2-9f0d-4bf6-a97f-8b9a88296c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export GOOGLE_APPLICATION_CREDENTIALS=\"mwpmltr-f1668dcc0858.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "000553c7-a4d3-4743-a2ca-e50076a09106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training_data\n",
    "import os\n",
    "document_classes=os.listdir(\"training_document_samples\")\n",
    "\n",
    "#get current working directory\n",
    "current_path=os.getcwd()\n",
    "\n",
    "# get list of files and labels\n",
    "list_files=[]\n",
    "labels=[]\n",
    "for classes in document_classes:\n",
    "    class_path=str(current_path)+'/'+\"training_document_samples\"+'/'+str(classes)\n",
    "    files=os.listdir(class_path)\n",
    "    for file in files:\n",
    "        file_path=class_path+'/' +file\n",
    "        list_files.append(file_path)\n",
    "        labels.append(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b1b31ed9-d343-4b06-bd6d-38cce5c5b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE DOCUMENT AI for ocr\n",
    "from google.cloud import documentai_v1 as documentai\n",
    "\n",
    "def process_document(project_id: str, location: str,\n",
    "                     processor_id: str, file_path: str,\n",
    "                     mime_type: str) -> documentai.Document:\n",
    "    \"\"\"\n",
    "    Processes a document using the Document AI API.\n",
    "    \"\"\"\n",
    "\n",
    "    # Instantiates a client\n",
    "    documentai_client = documentai.DocumentProcessorServiceClient()\n",
    "\n",
    "    # The full resource name of the processor, e.g.:\n",
    "    # projects/project-id/locations/location/processor/processor-id\n",
    "    # You must create new processors in the Cloud Console first\n",
    "    resource_name = documentai_client.processor_path(\n",
    "        project_id, location, processor_id)\n",
    "\n",
    "    # Read the file into memory\n",
    "    with open(file_path, \"rb\") as image:\n",
    "        image_content = image.read()\n",
    "\n",
    "        # Load Binary Data into Document AI RawDocument Object\n",
    "        raw_document = documentai.RawDocument(\n",
    "            content=image_content, mime_type=mime_type)\n",
    "\n",
    "        # Configure the process request\n",
    "        request = documentai.ProcessRequest(\n",
    "            name=resource_name, raw_document=raw_document)\n",
    "\n",
    "        # Use the Document AI client to process the sample form\n",
    "        result = documentai_client.process_document(request=request)\n",
    "\n",
    "        return result.document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d543ca2e-fee6-438e-bc66-326bc5efee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "project_id= 'mwpmltr'\n",
    "location = 'us' # Format is 'us' or 'eu'\n",
    "processor_id = '5146e2e343bf6d70' # document ocr #  Create processor in Cloud Console\n",
    "mime_type = 'application/pdf'\n",
    "\n",
    "# extract the text from the files\n",
    "# all text contains the text from all the files\n",
    "all_text=[]\n",
    "for file in list_files:\n",
    "    try:\n",
    "        document = process_document(project_id=project_id, location=location,\n",
    "                            processor_id=processor_id, file_path=file,\n",
    "                            mime_type=mime_type)\n",
    "        text=\" \".join(document.text.splitlines()).strip()\n",
    "        all_text.append(text)\n",
    "    except:\n",
    "        print(\"the file not processed is...\",file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5a6ed45a-cc53-4525-8073-13a45003354c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a classifier using tf-idf for feature generation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "training_data=all_text\n",
    "training_labels=labels\n",
    "\n",
    "#Train classification model using random forest\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "model = RandomForestClassifier(n_estimators = 100)\n",
    "pipeline = make_pipeline(vectorizer, model)\n",
    "\n",
    "pipeline.fit(training_data, training_labels)\n",
    "\n",
    "# save the model in a pickle file\n",
    "import pickle\n",
    "pickle.dump(pipeline, open('classification_pipeline.pickle', 'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913b1a7c-918b-4d68-b38a-805f6c205ffc",
   "metadata": {},
   "source": [
    "PREDICTION SERVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2e5fabb0-c1ed-4552-adeb-94cb1e1caa76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invoice\n"
     ]
    }
   ],
   "source": [
    "# classify document using randomforest\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import pickle\n",
    "\n",
    "\n",
    "file_path=list_files[23]\n",
    "document = process_document(project_id=project_id, location=location,\n",
    "                            processor_id=processor_id, file_path=file_path,\n",
    "                            mime_type=mime_type)\n",
    "text=[\" \".join(document.text.splitlines()).strip()]\n",
    "\n",
    "# read the pipeline from pickle\n",
    "pickle.load(open('classification_pipeline.pickle', 'rb'))\n",
    "prediction = str(list(pipeline.predict(text))[0])\n",
    "print(prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3d7be022-b2bd-47cb-b4d4-97e64b0c6929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform Key Value pair\n",
    "from google.cloud import documentai_v1 as documentai\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#Set up processor variables\n",
    "PROJECT_ID = project_id\n",
    "LOCATION = \"us\"  # Format is 'us' or 'eu'\n",
    "PDF_PATH = file_path # Update to path of target document\n",
    "\n",
    "if prediction=='w-9':\n",
    "    PROCESSOR_ID ='ece6aa307cb0d855'\n",
    "    \n",
    "def process_document_sample():\n",
    "    # Instantiates a client\n",
    "    client_options = {\"api_endpoint\": \"{}-documentai.googleapis.com\".format(LOCATION)}\n",
    "    client = documentai.DocumentProcessorServiceClient(client_options=client_options)\n",
    "\n",
    "    # The full resource name of the processor, e.g.:\n",
    "    # projects/project-id/locations/location/processor/processor-id\n",
    "    # You must create new processors in the Cloud Console first\n",
    "    name = f\"projects/{PROJECT_ID}/locations/{LOCATION}/processors/{PROCESSOR_ID}\"\n",
    "\n",
    "    with open(PDF_PATH, \"rb\") as image:\n",
    "        image_content = image.read()\n",
    "\n",
    "    # Read the file into memory\n",
    "    document = {\"content\": image_content, \"mime_type\": \"application/pdf\"}\n",
    "\n",
    "    # Configure the process request\n",
    "    request = {\"name\": name, \"raw_document\": document}\n",
    "\n",
    "    # Recognizes text entities in the PDF document\n",
    "    result = client.process_document(request=request)\n",
    "    document = result.document\n",
    "    entities = document.entities\n",
    "    print(\"Document processing complete.\\n\\n\")\n",
    "\n",
    "    # For a full list of Document object attributes, please reference this page: https://googleapis.dev/python/documentai/latest/_modules/google/cloud/documentai_v1beta3/types/document.html#Document  \n",
    "    types = []\n",
    "    values = []\n",
    "    confidence = []\n",
    "    \n",
    "    # Grab each key/value pair and their corresponding confidence scores.\n",
    "    for entity in entities:\n",
    "        types.append(entity.type_)\n",
    "        values.append(entity.mention_text)\n",
    "        confidence.append(round(entity.confidence,4))\n",
    "        \n",
    "    # Create a Pandas Dataframe to print the values in tabular format. \n",
    "    df = pd.DataFrame({'Type': types, 'Value': values, 'Confidence': confidence})\n",
    "    display(df)\n",
    "    \n",
    "    #if result.human_review_operation:\n",
    "    #    print (\"Triggered HITL long running operation: {}\".format(result.human_review_operation))\n",
    "\n",
    "    return document\n",
    "\n",
    "\n",
    "def get_text(doc_element: dict, document: dict):\n",
    "    \"\"\"\n",
    "    Document AI identifies form fields by their offsets\n",
    "    in document text. This function converts offsets\n",
    "    to text snippets.\n",
    "    \"\"\"\n",
    "    response = \"\"\n",
    "    # If a text segment spans several lines, it will\n",
    "    # be stored in different text segments.\n",
    "    for segment in doc_element.text_anchor.text_segments:\n",
    "        start_index = (\n",
    "            int(segment.start_index)\n",
    "            if segment in doc_element.text_anchor.text_segments\n",
    "            else 0\n",
    "        )\n",
    "        end_index = int(segment.end_index)\n",
    "        response += document.text[start_index:end_index]\n",
    "    return response    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "04a867f9-7050-4e37-a462-e52612ab0109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document processing complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Value</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FormRevisionDate</td>\n",
       "      <td>October 2018</td>\n",
       "      <td>0.9597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HasSignature</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HasSignatureDate</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SSN</td>\n",
       "      <td>721074732</td>\n",
       "      <td>0.9872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Name</td>\n",
       "      <td>Rose Jeppson</td>\n",
       "      <td>0.9853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FederalTaxClassification</td>\n",
       "      <td>Individual/sole proprietor or single-member LLC</td>\n",
       "      <td>0.9387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Address</td>\n",
       "      <td>101 South Orange Ave</td>\n",
       "      <td>0.9790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CityStateZip</td>\n",
       "      <td>Pasadena, CA 91001</td>\n",
       "      <td>0.9889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Type                                            Value  \\\n",
       "0          FormRevisionDate                                     October 2018   \n",
       "1              HasSignature                                              YES   \n",
       "2          HasSignatureDate                                              YES   \n",
       "3                       SSN                                        721074732   \n",
       "4                      Name                                     Rose Jeppson   \n",
       "5  FederalTaxClassification  Individual/sole proprietor or single-member LLC   \n",
       "6                   Address                             101 South Orange Ave   \n",
       "7              CityStateZip                               Pasadena, CA 91001   \n",
       "\n",
       "   Confidence  \n",
       "0      0.9597  \n",
       "1      0.9000  \n",
       "2      0.9000  \n",
       "3      0.9872  \n",
       "4      0.9853  \n",
       "5      0.9387  \n",
       "6      0.9790  \n",
       "7      0.9889  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = process_document_sample()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m86",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m86"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
