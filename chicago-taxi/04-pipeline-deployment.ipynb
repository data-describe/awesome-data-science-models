{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "109707f2",
   "metadata": {},
   "source": [
    "# 04 - Test and Deploy Training Pipeline to Vertex Pipelines\n",
    "\n",
    "The purpose of this notebook is to test, deploy, and run the `TFX` pipeline on `Vertex Pipelines`. The notebook covers the following tasks:\n",
    "1. Run the tests locally.\n",
    "2. Run the pipeline using `Vertex Pipelines`\n",
    "3. Execute the pipeline deployment `CI/CD` steps using `Cloud Build`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a51af1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133e7d80",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3bb184e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 1.8.0\n",
      "KFP Version: 1.8.12\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import kfp\n",
    "import tfx\n",
    "\n",
    "print(\"Tensorflow Version:\", tfx.__version__)\n",
    "print(\"KFP Version:\", kfp.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7bdded",
   "metadata": {},
   "source": [
    "### Setup Google Cloud project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b4b22be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID: mwpmltr\n",
      "Region: us-central1\n",
      "Bucket name: gcp-certification-chicago-taxi-demo\n",
      "Service Account: 55590906972-compute@developer.gserviceaccount.com\n"
     ]
    }
   ],
   "source": [
    "PROJECT = 'mwpmltr' # Change to your project id.\n",
    "REGION = 'us-central1' # Change to your region.\n",
    "BUCKET = 'gcp-certification-chicago-taxi-demo' # Change to your bucket name.\n",
    "SERVICE_ACCOUNT = \"55590906972-compute@developer.gserviceaccount.com\"\n",
    "\n",
    "if PROJECT == \"\" or PROJECT is None or PROJECT == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT = shell_output[0]\n",
    "    \n",
    "if SERVICE_ACCOUNT == \"\" or SERVICE_ACCOUNT is None or SERVICE_ACCOUNT == \"[your-service-account]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = !gcloud config list --format 'value(core.account)' 2>/dev/null\n",
    "    SERVICE_ACCOUNT = shell_output[0]\n",
    "    \n",
    "if BUCKET == \"\" or BUCKET is None or BUCKET == \"[your-bucket-name]\":\n",
    "    # Get your bucket name to GCP project id\n",
    "    BUCKET = PROJECT\n",
    "    # Try to create the bucket if it doesn't exists\n",
    "    ! gsutil mb -l $REGION gs://$BUCKET\n",
    "    print(\"\")\n",
    "    \n",
    "print(\"Project ID:\", PROJECT)\n",
    "print(\"Region:\", REGION)\n",
    "print(\"Bucket name:\", BUCKET)\n",
    "print(\"Service Account:\", SERVICE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb3467ae-cc94-4d58-b2f7-2236fd4e008b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/account].\n"
     ]
    }
   ],
   "source": [
    "!gcloud config set account $SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660a9dc9",
   "metadata": {},
   "source": [
    "### Set configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a75e169",
   "metadata": {},
   "outputs": [],
   "source": [
    "BQ_LOCATION = 'us-central1'\n",
    "BQ_DATASET_NAME = 'playground_central' # Change to your BQ dataset name.\n",
    "BQ_TABLE_NAME = 'chicago_taxitrips_prep'\n",
    "\n",
    "VERSION = 'v01'\n",
    "DATASET_DISPLAY_NAME = 'chicago-taxi-tips'\n",
    "MODEL_DISPLAY_NAME = f'{DATASET_DISPLAY_NAME}-classifier-{VERSION}'\n",
    "PIPELINE_NAME = f'{MODEL_DISPLAY_NAME}-train-pipeline'\n",
    "\n",
    "CICD_IMAGE_NAME = 'cicd:latest'\n",
    "CICD_IMAGE_URI = f\"gcr.io/{PROJECT}/{CICD_IMAGE_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06be3555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'src/raw_schema/.ipynb_checkpoints/': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm -r src/raw_schema/.ipynb_checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ea5c6f3-55bd-4f86-9f6a-06d91c29dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix this error:\n",
    "# ImportError: /lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.30' not found\n",
    "LD_LIBRARY_PATH = f'/opt/conda/lib/'\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = LD_LIBRARY_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44678373",
   "metadata": {},
   "source": [
    "## 1. Run the CICD steps locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68204ed",
   "metadata": {},
   "source": [
    "### Set pipeline configurations for the local run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05a1d20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"DATASET_DISPLAY_NAME\"] = DATASET_DISPLAY_NAME\n",
    "os.environ[\"MODEL_DISPLAY_NAME\"] =  MODEL_DISPLAY_NAME\n",
    "os.environ[\"PIPELINE_NAME\"] = PIPELINE_NAME\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"REGION\"] = REGION\n",
    "os.environ[\"BQ_LOCATION\"] = BQ_LOCATION\n",
    "os.environ[\"BQ_DATASET_NAME\"] = BQ_DATASET_NAME\n",
    "os.environ[\"BQ_TABLE_NAME\"] = BQ_TABLE_NAME\n",
    "os.environ[\"GCS_LOCATION\"] = f\"gs://{BUCKET}/{DATASET_DISPLAY_NAME}/e2e_tests\"\n",
    "os.environ[\"TRAIN_LIMIT\"] = \"1000\"\n",
    "os.environ[\"TEST_LIMIT\"] = \"100\"\n",
    "os.environ[\"UPLOAD_MODEL\"] = \"0\"\n",
    "os.environ[\"ACCURACY_THRESHOLD\"] = \"0.1\"\n",
    "os.environ[\"BEAM_RUNNER\"] = \"DirectRunner\"\n",
    "os.environ[\"TRAINING_RUNNER\"] = \"local\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d353e3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-10 23:46:28.076616: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/\n",
      "2022-09-10 23:46:28.076660: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT: mwpmltr\n",
      "REGION: us-central1\n",
      "GCS_LOCATION: gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests\n",
      "ARTIFACT_STORE_URI: gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts\n",
      "MODEL_REGISTRY_URI: gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/model_registry\n",
      "DATASET_DISPLAY_NAME: chicago-taxi-tips\n",
      "MODEL_DISPLAY_NAME: chicago-taxi-tips-classifier-v01\n",
      "PIPELINE_NAME: chicago-taxi-tips-classifier-v01-train-pipeline\n",
      "ML_USE_COLUMN: ml_use\n",
      "EXCLUDE_COLUMNS: trip_start_timestamp\n",
      "TRAIN_LIMIT: 1000\n",
      "TEST_LIMIT: 100\n",
      "SERVE_LIMIT: 0\n",
      "NUM_TRAIN_SPLITS: 4\n",
      "NUM_EVAL_SPLITS: 1\n",
      "ACCURACY_THRESHOLD: 0.1\n",
      "USE_KFP_SA: False\n",
      "TFX_IMAGE_URI: gcr.io/mwpmltr/tfx-chicago-taxi-tips:latest\n",
      "BEAM_RUNNER: DirectRunner\n",
      "BEAM_DIRECT_PIPELINE_ARGS: ['--project=mwpmltr', '--temp_location=gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/temp']\n",
      "BEAM_DATAFLOW_PIPELINE_ARGS: ['--project=mwpmltr', '--temp_location=gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/temp', '--region=us-central1', '--runner=DirectRunner']\n",
      "TRAINING_RUNNER: local\n",
      "VERTEX_TRAINING_ARGS: {'project': 'mwpmltr', 'worker_pool_specs': [{'machine_spec': {'machine_type': 'n1-standard-4'}, 'replica_count': 1, 'container_spec': {'image_uri': 'gcr.io/mwpmltr/tfx-chicago-taxi-tips:latest'}}]}\n",
      "VERTEX_TRAINING_CONFIG: {'ai_platform_training_enable_ucaip': True, 'ai_platform_training_ucaip_region': 'us-central1', 'ai_platform_training_args': {'project': 'mwpmltr', 'worker_pool_specs': [{'machine_spec': {'machine_type': 'n1-standard-4'}, 'replica_count': 1, 'container_spec': {'image_uri': 'gcr.io/mwpmltr/tfx-chicago-taxi-tips:latest'}}]}, 'use_gpu': False}\n",
      "SERVING_RUNTIME: tf2-cpu.2-8\n",
      "SERVING_IMAGE_URI: us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-8:latest\n",
      "BATCH_PREDICTION_BQ_DATASET_NAME: playground_us\n",
      "BATCH_PREDICTION_BQ_TABLE_NAME: chicago_taxitrips_prep\n",
      "BATCH_PREDICTION_BEAM_ARGS: {'runner': 'DirectRunner', 'temporary_dir': 'gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/temp', 'gcs_location': 'gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/temp', 'project': 'mwpmltr', 'region': 'us-central1', 'setup_file': './setup.py'}\n",
      "BATCH_PREDICTION_JOB_RESOURCES: {'machine_type': 'n1-standard-2', 'starting_replica_count': 1, 'max_replica_count': 10}\n",
      "DATASTORE_PREDICTION_KIND: chicago-taxi-tips-classifier-v01-predictions\n",
      "ENABLE_CACHE: 0\n",
      "UPLOAD_MODEL: 0\n"
     ]
    }
   ],
   "source": [
    "from src.tfx_pipelines import config\n",
    "import importlib\n",
    "importlib.reload(config)\n",
    "\n",
    "for key, value in config.__dict__.items():\n",
    "    if key.isupper(): print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d51c12",
   "metadata": {},
   "source": [
    "### Run unit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9be84a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.7.12, pytest-7.1.2, pluggy-1.0.0\n",
      "rootdir: /home/jupyter/mlops-with-vertex-ai\n",
      "plugins: anyio-3.6.1\n",
      "collected 2 items                                                              \u001b[0m\u001b[1m\n",
      "\n",
      "src/tests/datasource_utils_tests.py BigQuery Source: mwpmltr.playground_central.chicago_taxitrips_prep\n",
      "\u001b[32m.\u001b[0mBigQuery Source: mwpmltr.playground_central.chicago_taxitrips_prep\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 4.71s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest src/tests/datasource_utils_tests.py -s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4358f955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.7.12, pytest-7.1.2, pluggy-1.0.0\n",
      "rootdir: /home/jupyter/mlops-with-vertex-ai\n",
      "plugins: anyio-3.6.1\n",
      "collected 2 items                                                              \u001b[0m\u001b[1m\n",
      "\n",
      "src/tests/model_tests.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33m                                              [100%]\u001b[0m\n",
      "\n",
      "\u001b[33m======================== \u001b[32m2 passed\u001b[0m, \u001b[33m\u001b[1m10 warnings\u001b[0m\u001b[33m in 2.70s\u001b[0m\u001b[33m ========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest src/tests/model_tests.py --disable-warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa00fd5",
   "metadata": {},
   "source": [
    "### Run e2e pipeline test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb9aad70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.7.12, pytest-7.1.2, pluggy-1.0.0\n",
      "rootdir: /home/jupyter/mlops-with-vertex-ai\n",
      "plugins: anyio-3.6.1\n",
      "\u001b[1mcollecting ... \u001b[0m2022-09-10 23:46:42.185084: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/\n",
      "2022-09-10 23:46:42.185136: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "collected 1 item                                                               \u001b[0m\u001b[1m\n",
      "\n",
      "src/tests/pipeline_deployment_tests.py upload_model: 0\n",
      "Pipeline e2e test artifacts stored in: gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests\n",
      "ML metadata store is ready.\n",
      "Excluding no splits because exclude_splits is not set.\n",
      "Excluding no splits because exclude_splits is not set.\n",
      "Pipeline components: ['HyperparamsGen', 'TrainDataGen', 'TestDataGen', 'StatisticsGen', 'SchemaImporter', 'ExampleValidator', 'DataTransformer', 'WarmstartModelResolver', 'ModelTrainer', 'BaselineModelResolver', 'ModelEvaluator', 'ModelPusher']\n",
      "Beam pipeline args: ['--project=mwpmltr', '--temp_location=gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/temp', '--region=us-central1', '--runner=DirectRunner']\n",
      "Generating ephemeral wheel package for '/home/jupyter/mlops-with-vertex-ai/src/preprocessing/transformations.py' (including modules: ['etl', 'transformations']).\n",
      "User module package has hash fingerprint version de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d.\n",
      "Executing: ['/opt/conda/bin/python', '/tmp/tmpjqkb_4mg/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/tmp/tmpcv0z3p_a', '--dist-dir', '/tmp/tmprpvt86k6']\n",
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying etl.py -> build/lib\n",
      "copying transformations.py -> build/lib\n",
      "/opt/conda/lib/python3.7/site-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  setuptools.SetuptoolsDeprecationWarning,\n",
      "installing to /tmp/tmpcv0z3p_a\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/transformations.py -> /tmp/tmpcv0z3p_a\n",
      "copying build/lib/etl.py -> /tmp/tmpcv0z3p_a\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_DataTransformer.egg-info\n",
      "writing tfx_user_code_DataTransformer.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_DataTransformer.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_DataTransformer.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_DataTransformer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_DataTransformer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_DataTransformer.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_DataTransformer.egg-info to /tmp/tmpcv0z3p_a/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3.7.egg-info\n",
      "running install_scripts\n",
      "creating /tmp/tmpcv0z3p_a/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d.dist-info/WHEEL\n",
      "creating '/tmp/tmprpvt86k6/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl' and adding '/tmp/tmpcv0z3p_a' to it\n",
      "adding 'etl.py'\n",
      "adding 'transformations.py'\n",
      "adding 'tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d.dist-info/METADATA'\n",
      "adding 'tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d.dist-info/RECORD'\n",
      "removing /tmp/tmpcv0z3p_a\n",
      "Successfully built user code wheel distribution at 'gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/_wheels/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl'; target user module is 'transformations'.\n",
      "Full user module path is 'transformations@gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/_wheels/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl'\n",
      "Generating ephemeral wheel package for '/home/jupyter/mlops-with-vertex-ai/src/model_training/runner.py' (including modules: ['data', 'exporter', 'trainer', 'task', 'model', 'runner', 'defaults']).\n",
      "User module package has hash fingerprint version 437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8.\n",
      "Executing: ['/opt/conda/bin/python', '/tmp/tmpnc4to2rs/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/tmp/tmpjqle583s', '--dist-dir', '/tmp/tmpmn2gzwdp']\n",
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying data.py -> build/lib\n",
      "copying exporter.py -> build/lib\n",
      "copying trainer.py -> build/lib\n",
      "copying task.py -> build/lib\n",
      "copying model.py -> build/lib\n",
      "copying runner.py -> build/lib\n",
      "copying defaults.py -> build/lib\n",
      "/opt/conda/lib/python3.7/site-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  setuptools.SetuptoolsDeprecationWarning,\n",
      "installing to /tmp/tmpjqle583s\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/trainer.py -> /tmp/tmpjqle583s\n",
      "copying build/lib/model.py -> /tmp/tmpjqle583s\n",
      "copying build/lib/runner.py -> /tmp/tmpjqle583s\n",
      "copying build/lib/task.py -> /tmp/tmpjqle583s\n",
      "copying build/lib/data.py -> /tmp/tmpjqle583s\n",
      "copying build/lib/defaults.py -> /tmp/tmpjqle583s\n",
      "copying build/lib/exporter.py -> /tmp/tmpjqle583s\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_ModelTrainer.egg-info\n",
      "writing tfx_user_code_ModelTrainer.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_ModelTrainer.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_ModelTrainer.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_ModelTrainer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_ModelTrainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_ModelTrainer.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_ModelTrainer.egg-info to /tmp/tmpjqle583s/tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8-py3.7.egg-info\n",
      "running install_scripts\n",
      "creating /tmp/tmpjqle583s/tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8.dist-info/WHEEL\n",
      "creating '/tmp/tmpmn2gzwdp/tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8-py3-none-any.whl' and adding '/tmp/tmpjqle583s' to it\n",
      "adding 'data.py'\n",
      "adding 'defaults.py'\n",
      "adding 'exporter.py'\n",
      "adding 'model.py'\n",
      "adding 'runner.py'\n",
      "adding 'task.py'\n",
      "adding 'trainer.py'\n",
      "adding 'tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8.dist-info/METADATA'\n",
      "adding 'tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8.dist-info/RECORD'\n",
      "removing /tmp/tmpjqle583s\n",
      "Successfully built user code wheel distribution at 'gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/_wheels/tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8-py3-none-any.whl'; target user module is 'runner'.\n",
      "Full user module path is 'runner@gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/_wheels/tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8-py3-none-any.whl'\n",
      "Using deployment config:\n",
      " executor_specs {\n",
      "  key: \"DataTransformer\"\n",
      "  value {\n",
      "    beam_executable_spec {\n",
      "      python_executor_spec {\n",
      "        class_path: \"tfx.components.transform.executor.Executor\"\n",
      "      }\n",
      "      beam_pipeline_args: \"--project=mwpmltr\"\n",
      "      beam_pipeline_args: \"--temp_location=gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/temp\"\n",
      "      beam_pipeline_args: \"--region=us-central1\"\n",
      "      beam_pipeline_args: \"--runner=DirectRunner\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"ExampleValidator\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.example_validator.executor.Executor\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"HyperparamsGen\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"src.tfx_pipelines.components.hyperparameters_gen_Executor\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"ModelEvaluator\"\n",
      "  value {\n",
      "    beam_executable_spec {\n",
      "      python_executor_spec {\n",
      "        class_path: \"tfx.components.evaluator.executor.Executor\"\n",
      "      }\n",
      "      beam_pipeline_args: \"--project=mwpmltr\"\n",
      "      beam_pipeline_args: \"--temp_location=gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/temp\"\n",
      "      beam_pipeline_args: \"--region=us-central1\"\n",
      "      beam_pipeline_args: \"--runner=DirectRunner\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"ModelPusher\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.pusher.executor.Executor\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"ModelTrainer\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.trainer.executor.GenericExecutor\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"StatisticsGen\"\n",
      "  value {\n",
      "    beam_executable_spec {\n",
      "      python_executor_spec {\n",
      "        class_path: \"tfx.components.statistics_gen.executor.Executor\"\n",
      "      }\n",
      "      beam_pipeline_args: \"--project=mwpmltr\"\n",
      "      beam_pipeline_args: \"--temp_location=gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/temp\"\n",
      "      beam_pipeline_args: \"--region=us-central1\"\n",
      "      beam_pipeline_args: \"--runner=DirectRunner\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"TestDataGen\"\n",
      "  value {\n",
      "    beam_executable_spec {\n",
      "      python_executor_spec {\n",
      "        class_path: \"tfx.extensions.google_cloud_big_query.example_gen.executor.Executor\"\n",
      "      }\n",
      "      beam_pipeline_args: \"--project=mwpmltr\"\n",
      "      beam_pipeline_args: \"--temp_location=gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/temp\"\n",
      "      beam_pipeline_args: \"--region=us-central1\"\n",
      "      beam_pipeline_args: \"--runner=DirectRunner\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"TrainDataGen\"\n",
      "  value {\n",
      "    beam_executable_spec {\n",
      "      python_executor_spec {\n",
      "        class_path: \"tfx.extensions.google_cloud_big_query.example_gen.executor.Executor\"\n",
      "      }\n",
      "      beam_pipeline_args: \"--project=mwpmltr\"\n",
      "      beam_pipeline_args: \"--temp_location=gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/temp\"\n",
      "      beam_pipeline_args: \"--region=us-central1\"\n",
      "      beam_pipeline_args: \"--runner=DirectRunner\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "custom_driver_specs {\n",
      "  key: \"TestDataGen\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.example_gen.driver.QueryBasedDriver\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "custom_driver_specs {\n",
      "  key: \"TrainDataGen\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.example_gen.driver.QueryBasedDriver\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "metadata_connection_config {\n",
      "  database_connection_config {\n",
      "    sqlite {\n",
      "      filename_uri: \"mlmd.sqllite\"\n",
      "      connection_mode: READWRITE_OPENCREATE\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "Using connection config:\n",
      " sqlite {\n",
      "  filename_uri: \"mlmd.sqllite\"\n",
      "  connection_mode: READWRITE_OPENCREATE\n",
      "}\n",
      "\n",
      "Component BaselineModelResolver is running.\n",
      "Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.dsl.components.common.resolver.Resolver\"\n",
      "  }\n",
      "  id: \"BaselineModelResolver\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.BaselineModelResolver\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model_blessing\"\n",
      "    value {\n",
      "      channels {\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ModelBlessing\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  resolver_config {\n",
      "    resolver_steps {\n",
      "      class_path: \"tfx.dsl.input_resolution.strategies.latest_blessed_model_strategy.LatestBlessedModelStrategy\"\n",
      "      config_json: \"{}\"\n",
      "      input_keys: \"model\"\n",
      "      input_keys: \"model_blessing\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"ModelEvaluator\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "Running as an resolver node.\n",
      "MetadataStore with DB connection initialized\n",
      "Artifact type ModelBlessing is not found in MLMD.\n",
      "Artifact type Model is not found in MLMD.\n",
      "Component BaselineModelResolver is finished.\n",
      "Component HyperparamsGen is running.\n",
      "Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"src.tfx_pipelines.components.hyperparameters_gen\"\n",
      "  }\n",
      "  id: \"HyperparamsGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.HyperparamsGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"hyperparameters\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"HyperParameters\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"batch_size\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 512\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"hidden_units\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"128,128\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"learning_rate\"\n",
      "    value {\n",
      "      field_value {\n",
      "        double_value: 0.001\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"num_epochs\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"ModelTrainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "MetadataStore with DB connection initialized\n",
      "MetadataStore with DB connection initialized\n",
      "Going to run a new execution 2\n",
      "Going to run a new execution: ExecutionInfo(execution_id=2, input_dict={}, output_dict=defaultdict(<class 'list'>, {'hyperparameters': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/HyperparamsGen/hyperparameters/2\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:HyperparamsGen:hyperparameters:0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:HyperparamsGen:hyperparameters:0\"\n",
      ", artifact_type: name: \"HyperParameters\"\n",
      ")]}), exec_properties={'hidden_units': '128,128', 'num_epochs': 1, 'learning_rate': 0.001, 'batch_size': 512}, execution_output_uri='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/HyperparamsGen/.system/executor_execution/2/executor_output.pb', stateful_working_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/HyperparamsGen/.system/stateful_working_dir/2022-09-10T23:47:00.785303', tmp_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/HyperparamsGen/.system/executor_execution/2/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"src.tfx_pipelines.components.hyperparameters_gen\"\n",
      "  }\n",
      "  id: \"HyperparamsGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.HyperparamsGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"hyperparameters\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"HyperParameters\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"batch_size\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 512\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"hidden_units\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"128,128\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"learning_rate\"\n",
      "    value {\n",
      "      field_value {\n",
      "        double_value: 0.001\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"num_epochs\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"ModelTrainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      ", pipeline_run_id='2022-09-10T23:47:00.785303')\n",
      "Hyperparameters: {'num_epochs': 1, 'batch_size': 512, 'learning_rate': 0.001, 'hidden_units': [128, 128]}\n",
      "Hyperparameters are written to: gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/HyperparamsGen/hyperparameters/2/hyperparameters.json\n",
      "Cleaning up stateless execution info.\n",
      "Execution 2 succeeded.\n",
      "Cleaning up stateful execution info.\n",
      "stateful_working_dir /home/jupyter/mlops-with-vertex-ai/gs:/gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/HyperparamsGen/.system/stateful_working_dir is not found, not going to delete it.\n",
      "Publishing output artifacts defaultdict(<class 'list'>, {'hyperparameters': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/HyperparamsGen/hyperparameters/2\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:HyperparamsGen:hyperparameters:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:HyperparamsGen:hyperparameters:0\"\n",
      ", artifact_type: name: \"HyperParameters\"\n",
      ")]}) for execution 2\n",
      "MetadataStore with DB connection initialized\n",
      "Component HyperparamsGen is finished.\n",
      "Component SchemaImporter is running.\n",
      "Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.dsl.components.common.importer.Importer\"\n",
      "  }\n",
      "  id: \"SchemaImporter\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.SchemaImporter\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"result\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"artifact_uri\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"src/raw_schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"reimport\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"DataTransformer\"\n",
      "downstream_nodes: \"ExampleValidator\"\n",
      "downstream_nodes: \"ModelEvaluator\"\n",
      "downstream_nodes: \"ModelTrainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "Running as an importer node.\n",
      "MetadataStore with DB connection initialized\n",
      "Processing source uri: src/raw_schema, properties: {}, custom_properties: {}\n",
      "Component SchemaImporter is finished.\n",
      "Component TestDataGen is running.\n",
      "Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.extensions.google_cloud_big_query.example_gen.component.BigQueryExampleGen\"\n",
      "    base_type: PROCESS\n",
      "  }\n",
      "  id: \"TestDataGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.TestDataGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "          base_type: DATASET\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"input_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"\\\\n    SELECT \\\\n        IF(trip_month IS NULL, -1, trip_month) trip_month,\\\\n        IF(trip_day IS NULL, -1, trip_day) trip_day,\\\\n        IF(trip_day_of_week IS NULL, -1, trip_day_of_week) trip_day_of_week,\\\\n        IF(trip_hour IS NULL, -1, trip_hour) trip_hour,\\\\n        IF(trip_seconds IS NULL, -1, trip_seconds) trip_seconds,\\\\n        IF(trip_miles IS NULL, -1, trip_miles) trip_miles,\\\\n        IF(payment_type IS NULL, \\'NA\\', payment_type) payment_type,\\\\n        IF(pickup_grid IS NULL, \\'NA\\', pickup_grid) pickup_grid,\\\\n        IF(dropoff_grid IS NULL, \\'NA\\', dropoff_grid) dropoff_grid,\\\\n        IF(euclidean IS NULL, -1, euclidean) euclidean,\\\\n        IF(loc_cross IS NULL, \\'NA\\', loc_cross) loc_cross,\\\\n        tip_bin\\\\n    FROM playground_central.chicago_taxitrips_prep \\\\n    WHERE ML_use = \\'TEST\\'\\\\n    LIMIT 100\\\"\\n    }\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"test\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_data_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 6\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_file_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 5\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"ModelEvaluator\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "MetadataStore with DB connection initialized\n",
      "MetadataStore with DB connection initialized\n",
      "Going to run a new execution 4\n",
      "Going to run a new execution: ExecutionInfo(execution_id=4, input_dict={}, output_dict=defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/TestDataGen/examples/4\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:TestDataGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:TestDataGen:examples:0\"\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}), exec_properties={'output_data_format': 6, 'output_config': '{\\n  \"split_config\": {\\n    \"splits\": [\\n      {\\n        \"hash_buckets\": 1,\\n        \"name\": \"test\"\\n      }\\n    ]\\n  }\\n}', 'output_file_format': 5, 'input_config': '{\\n  \"splits\": [\\n    {\\n      \"name\": \"single_split\",\\n      \"pattern\": \"\\\\n    SELECT \\\\n        IF(trip_month IS NULL, -1, trip_month) trip_month,\\\\n        IF(trip_day IS NULL, -1, trip_day) trip_day,\\\\n        IF(trip_day_of_week IS NULL, -1, trip_day_of_week) trip_day_of_week,\\\\n        IF(trip_hour IS NULL, -1, trip_hour) trip_hour,\\\\n        IF(trip_seconds IS NULL, -1, trip_seconds) trip_seconds,\\\\n        IF(trip_miles IS NULL, -1, trip_miles) trip_miles,\\\\n        IF(payment_type IS NULL, \\'NA\\', payment_type) payment_type,\\\\n        IF(pickup_grid IS NULL, \\'NA\\', pickup_grid) pickup_grid,\\\\n        IF(dropoff_grid IS NULL, \\'NA\\', dropoff_grid) dropoff_grid,\\\\n        IF(euclidean IS NULL, -1, euclidean) euclidean,\\\\n        IF(loc_cross IS NULL, \\'NA\\', loc_cross) loc_cross,\\\\n        tip_bin\\\\n    FROM playground_central.chicago_taxitrips_prep \\\\n    WHERE ML_use = \\'TEST\\'\\\\n    LIMIT 100\"\\n    }\\n  ]\\n}', 'span': 0, 'version': None, 'input_fingerprint': None}, execution_output_uri='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/TestDataGen/.system/executor_execution/4/executor_output.pb', stateful_working_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/TestDataGen/.system/stateful_working_dir/2022-09-10T23:47:00.785303', tmp_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/TestDataGen/.system/executor_execution/4/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.extensions.google_cloud_big_query.example_gen.component.BigQueryExampleGen\"\n",
      "    base_type: PROCESS\n",
      "  }\n",
      "  id: \"TestDataGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.TestDataGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "          base_type: DATASET\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"input_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"\\\\n    SELECT \\\\n        IF(trip_month IS NULL, -1, trip_month) trip_month,\\\\n        IF(trip_day IS NULL, -1, trip_day) trip_day,\\\\n        IF(trip_day_of_week IS NULL, -1, trip_day_of_week) trip_day_of_week,\\\\n        IF(trip_hour IS NULL, -1, trip_hour) trip_hour,\\\\n        IF(trip_seconds IS NULL, -1, trip_seconds) trip_seconds,\\\\n        IF(trip_miles IS NULL, -1, trip_miles) trip_miles,\\\\n        IF(payment_type IS NULL, \\'NA\\', payment_type) payment_type,\\\\n        IF(pickup_grid IS NULL, \\'NA\\', pickup_grid) pickup_grid,\\\\n        IF(dropoff_grid IS NULL, \\'NA\\', dropoff_grid) dropoff_grid,\\\\n        IF(euclidean IS NULL, -1, euclidean) euclidean,\\\\n        IF(loc_cross IS NULL, \\'NA\\', loc_cross) loc_cross,\\\\n        tip_bin\\\\n    FROM playground_central.chicago_taxitrips_prep \\\\n    WHERE ML_use = \\'TEST\\'\\\\n    LIMIT 100\\\"\\n    }\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"test\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_data_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 6\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_file_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 5\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"ModelEvaluator\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      ", pipeline_run_id='2022-09-10T23:47:00.785303')\n",
      "Attempting to infer TFX Python dependency for beam\n",
      "Copying all content from install dir /home/jupyter/.local/lib/python3.7/site-packages/tfx to temp dir /tmp/tmp26_kt8kr/build/tfx\n",
      "Generating a temp setup file at /tmp/tmp26_kt8kr/build/tfx/setup.py\n",
      "Creating temporary sdist package, logs available at /tmp/tmp26_kt8kr/build/tfx/setup.log\n",
      "E0910 23:47:06.905173224    2595 fork_posix.cc:76]           Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "Added --extra_package=/tmp/tmp26_kt8kr/build/tfx/dist/tfx_ephemeral-1.8.0.tar.gz to beam args\n",
      "Length of label `tfx-extensions-google_cloud_big_query-example_gen-executor-executor` exceeds maximum length(63), trimmed.\n",
      "Generating examples.\n",
      "Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n",
      "Default Python SDK image for environment is apache/beam_python3.7_sdk:2.39.0\n",
      "==================== <function annotate_downstream_side_inputs at 0x7f48d14ee5f0> ====================\n",
      "==================== <function fix_side_input_pcoll_coders at 0x7f48d14ee710> ====================\n",
      "==================== <function pack_combiners at 0x7f48d14eec20> ====================\n",
      "==================== <function lift_combiners at 0x7f48d14eecb0> ====================\n",
      "==================== <function expand_sdf at 0x7f48d14eee60> ====================\n",
      "==================== <function expand_gbk at 0x7f48d14eeef0> ====================\n",
      "==================== <function sink_flattens at 0x7f48d14ef050> ====================\n",
      "==================== <function greedily_fuse at 0x7f48d14ef0e0> ====================\n",
      "==================== <function read_to_impulse at 0x7f48d14ef170> ====================\n",
      "==================== <function impulse_to_input at 0x7f48d14ef200> ====================\n",
      "==================== <function sort_stages at 0x7f48d14ef440> ====================\n",
      "==================== <function add_impulse_to_dangling_transforms at 0x7f48d14ef560> ====================\n",
      "==================== <function setup_timer_mapping at 0x7f48d14ef3b0> ====================\n",
      "==================== <function populate_data_channel_coders at 0x7f48d14ef4d0> ====================\n",
      "Creating state cache with size 100\n",
      "Created Worker handler <apache_beam.runners.portability.fn_api_runner.worker_handlers.EmbeddedWorkerHandler object at 0x7f48fe733910> for environment ref_Environment_default_environment_1 (beam:env:embedded_python:v1, b'')\n",
      "E0910 23:47:09.034934930    2595 fork_posix.cc:76]           Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "Setting socket default timeout to 60 seconds.\n",
      "socket default timeout is 60.0 seconds.\n",
      "Started BigQuery job: <JobReference\n",
      " location: 'us-central1'\n",
      " projectId: 'mwpmltr'>\n",
      " bq show -j --format=prettyjson --project_id=mwpmltr None\n",
      "Using location 'us-central1' from table <TableReference\n",
      " datasetId: 'playground_central'\n",
      " projectId: 'mwpmltr'\n",
      " tableId: 'chicago_taxitrips_prep'> referenced by query \n",
      "    SELECT \n",
      "        IF(trip_month IS NULL, -1, trip_month) trip_month,\n",
      "        IF(trip_day IS NULL, -1, trip_day) trip_day,\n",
      "        IF(trip_day_of_week IS NULL, -1, trip_day_of_week) trip_day_of_week,\n",
      "        IF(trip_hour IS NULL, -1, trip_hour) trip_hour,\n",
      "        IF(trip_seconds IS NULL, -1, trip_seconds) trip_seconds,\n",
      "        IF(trip_miles IS NULL, -1, trip_miles) trip_miles,\n",
      "        IF(payment_type IS NULL, 'NA', payment_type) payment_type,\n",
      "        IF(pickup_grid IS NULL, 'NA', pickup_grid) pickup_grid,\n",
      "        IF(dropoff_grid IS NULL, 'NA', dropoff_grid) dropoff_grid,\n",
      "        IF(euclidean IS NULL, -1, euclidean) euclidean,\n",
      "        IF(loc_cross IS NULL, 'NA', loc_cross) loc_cross,\n",
      "        tip_bin\n",
      "    FROM playground_central.chicago_taxitrips_prep \n",
      "    WHERE ML_use = 'TEST'\n",
      "    LIMIT 100\n",
      "Dataset mwpmltr:beam_temp_dataset_69f3bfda333441b1aaece9fefd6c8433 does not exist so we will create it as temporary with location=us-central1\n",
      "Started BigQuery job: <JobReference\n",
      " jobId: 'beam_bq_job_QUERY_BQ_EXPORT_JOB_b0f2fd48-d_1662853630_600'\n",
      " location: 'us-central1'\n",
      " projectId: 'mwpmltr'>\n",
      " bq show -j --format=prettyjson --project_id=mwpmltr beam_bq_job_QUERY_BQ_EXPORT_JOB_b0f2fd48-d_1662853630_600\n",
      "Job status: RUNNING\n",
      "Job status: DONE\n",
      "Started BigQuery job: <JobReference\n",
      " jobId: 'beam_bq_job_EXPORT_BQ_EXPORT_JOB_b0f2fd48-d_1662853635_700'\n",
      " location: 'us-central1'\n",
      " projectId: 'mwpmltr'>\n",
      " bq show -j --format=prettyjson --project_id=mwpmltr beam_bq_job_EXPORT_BQ_EXPORT_JOB_b0f2fd48-d_1662853635_700\n",
      "Job status: RUNNING\n",
      "Job status: DONE\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.043398141860961914 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.03715634346008301 seconds.\n",
      "Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.029029369354248047 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.03907179832458496 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.03478527069091797 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.20 seconds.\n",
      "Examples generated.\n",
      "Value type <class 'NoneType'> of key version in exec_properties is not supported, going to drop it\n",
      "Value type <class 'NoneType'> of key input_fingerprint in exec_properties is not supported, going to drop it\n",
      "Value type <class 'list'> of key _beam_pipeline_args in exec_properties is not supported, going to drop it\n",
      "Cleaning up stateless execution info.\n",
      "Execution 4 succeeded.\n",
      "Cleaning up stateful execution info.\n",
      "stateful_working_dir /home/jupyter/mlops-with-vertex-ai/gs:/gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/TestDataGen/.system/stateful_working_dir is not found, not going to delete it.\n",
      "Publishing output artifacts defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/TestDataGen/examples/4\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:TestDataGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:TestDataGen:examples:0\"\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}) for execution 4\n",
      "MetadataStore with DB connection initialized\n",
      "Component TestDataGen is finished.\n",
      "Component TrainDataGen is running.\n",
      "Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.extensions.google_cloud_big_query.example_gen.component.BigQueryExampleGen\"\n",
      "    base_type: PROCESS\n",
      "  }\n",
      "  id: \"TrainDataGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.TrainDataGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "          base_type: DATASET\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"input_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"\\\\n    SELECT \\\\n        IF(trip_month IS NULL, -1, trip_month) trip_month,\\\\n        IF(trip_day IS NULL, -1, trip_day) trip_day,\\\\n        IF(trip_day_of_week IS NULL, -1, trip_day_of_week) trip_day_of_week,\\\\n        IF(trip_hour IS NULL, -1, trip_hour) trip_hour,\\\\n        IF(trip_seconds IS NULL, -1, trip_seconds) trip_seconds,\\\\n        IF(trip_miles IS NULL, -1, trip_miles) trip_miles,\\\\n        IF(payment_type IS NULL, \\'NA\\', payment_type) payment_type,\\\\n        IF(pickup_grid IS NULL, \\'NA\\', pickup_grid) pickup_grid,\\\\n        IF(dropoff_grid IS NULL, \\'NA\\', dropoff_grid) dropoff_grid,\\\\n        IF(euclidean IS NULL, -1, euclidean) euclidean,\\\\n        IF(loc_cross IS NULL, \\'NA\\', loc_cross) loc_cross,\\\\n        tip_bin\\\\n    FROM playground_central.chicago_taxitrips_prep \\\\n    WHERE ML_use = \\'UNASSIGNED\\'\\\\n    LIMIT 1000\\\"\\n    }\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 4,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_data_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 6\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_file_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 5\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"DataTransformer\"\n",
      "downstream_nodes: \"StatisticsGen\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "MetadataStore with DB connection initialized\n",
      "MetadataStore with DB connection initialized\n",
      "Going to run a new execution 5\n",
      "Going to run a new execution: ExecutionInfo(execution_id=5, input_dict={}, output_dict=defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/TrainDataGen/examples/5\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:TrainDataGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:TrainDataGen:examples:0\"\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}), exec_properties={'output_file_format': 5, 'output_config': '{\\n  \"split_config\": {\\n    \"splits\": [\\n      {\\n        \"hash_buckets\": 4,\\n        \"name\": \"train\"\\n      },\\n      {\\n        \"hash_buckets\": 1,\\n        \"name\": \"eval\"\\n      }\\n    ]\\n  }\\n}', 'input_config': '{\\n  \"splits\": [\\n    {\\n      \"name\": \"single_split\",\\n      \"pattern\": \"\\\\n    SELECT \\\\n        IF(trip_month IS NULL, -1, trip_month) trip_month,\\\\n        IF(trip_day IS NULL, -1, trip_day) trip_day,\\\\n        IF(trip_day_of_week IS NULL, -1, trip_day_of_week) trip_day_of_week,\\\\n        IF(trip_hour IS NULL, -1, trip_hour) trip_hour,\\\\n        IF(trip_seconds IS NULL, -1, trip_seconds) trip_seconds,\\\\n        IF(trip_miles IS NULL, -1, trip_miles) trip_miles,\\\\n        IF(payment_type IS NULL, \\'NA\\', payment_type) payment_type,\\\\n        IF(pickup_grid IS NULL, \\'NA\\', pickup_grid) pickup_grid,\\\\n        IF(dropoff_grid IS NULL, \\'NA\\', dropoff_grid) dropoff_grid,\\\\n        IF(euclidean IS NULL, -1, euclidean) euclidean,\\\\n        IF(loc_cross IS NULL, \\'NA\\', loc_cross) loc_cross,\\\\n        tip_bin\\\\n    FROM playground_central.chicago_taxitrips_prep \\\\n    WHERE ML_use = \\'UNASSIGNED\\'\\\\n    LIMIT 1000\"\\n    }\\n  ]\\n}', 'output_data_format': 6, 'span': 0, 'version': None, 'input_fingerprint': None}, execution_output_uri='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/TrainDataGen/.system/executor_execution/5/executor_output.pb', stateful_working_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/TrainDataGen/.system/stateful_working_dir/2022-09-10T23:47:00.785303', tmp_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/TrainDataGen/.system/executor_execution/5/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.extensions.google_cloud_big_query.example_gen.component.BigQueryExampleGen\"\n",
      "    base_type: PROCESS\n",
      "  }\n",
      "  id: \"TrainDataGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.TrainDataGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "          base_type: DATASET\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"input_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"\\\\n    SELECT \\\\n        IF(trip_month IS NULL, -1, trip_month) trip_month,\\\\n        IF(trip_day IS NULL, -1, trip_day) trip_day,\\\\n        IF(trip_day_of_week IS NULL, -1, trip_day_of_week) trip_day_of_week,\\\\n        IF(trip_hour IS NULL, -1, trip_hour) trip_hour,\\\\n        IF(trip_seconds IS NULL, -1, trip_seconds) trip_seconds,\\\\n        IF(trip_miles IS NULL, -1, trip_miles) trip_miles,\\\\n        IF(payment_type IS NULL, \\'NA\\', payment_type) payment_type,\\\\n        IF(pickup_grid IS NULL, \\'NA\\', pickup_grid) pickup_grid,\\\\n        IF(dropoff_grid IS NULL, \\'NA\\', dropoff_grid) dropoff_grid,\\\\n        IF(euclidean IS NULL, -1, euclidean) euclidean,\\\\n        IF(loc_cross IS NULL, \\'NA\\', loc_cross) loc_cross,\\\\n        tip_bin\\\\n    FROM playground_central.chicago_taxitrips_prep \\\\n    WHERE ML_use = \\'UNASSIGNED\\'\\\\n    LIMIT 1000\\\"\\n    }\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 4,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_data_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 6\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_file_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 5\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"DataTransformer\"\n",
      "downstream_nodes: \"StatisticsGen\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      ", pipeline_run_id='2022-09-10T23:47:00.785303')\n",
      "Attempting to infer TFX Python dependency for beam\n",
      "Copying all content from install dir /home/jupyter/.local/lib/python3.7/site-packages/tfx to temp dir /tmp/tmpsq6b5ie7/build/tfx\n",
      "Generating a temp setup file at /tmp/tmpsq6b5ie7/build/tfx/setup.py\n",
      "Creating temporary sdist package, logs available at /tmp/tmpsq6b5ie7/build/tfx/setup.log\n",
      "Added --extra_package=/tmp/tmpsq6b5ie7/build/tfx/dist/tfx_ephemeral-1.8.0.tar.gz to beam args\n",
      "Length of label `tfx-extensions-google_cloud_big_query-example_gen-executor-executor` exceeds maximum length(63), trimmed.\n",
      "Generating examples.\n",
      "Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n",
      "Default Python SDK image for environment is apache/beam_python3.7_sdk:2.39.0\n",
      "==================== <function annotate_downstream_side_inputs at 0x7f48d14ee5f0> ====================\n",
      "==================== <function fix_side_input_pcoll_coders at 0x7f48d14ee710> ====================\n",
      "==================== <function pack_combiners at 0x7f48d14eec20> ====================\n",
      "==================== <function lift_combiners at 0x7f48d14eecb0> ====================\n",
      "==================== <function expand_sdf at 0x7f48d14eee60> ====================\n",
      "==================== <function expand_gbk at 0x7f48d14eeef0> ====================\n",
      "==================== <function sink_flattens at 0x7f48d14ef050> ====================\n",
      "==================== <function greedily_fuse at 0x7f48d14ef0e0> ====================\n",
      "==================== <function read_to_impulse at 0x7f48d14ef170> ====================\n",
      "==================== <function impulse_to_input at 0x7f48d14ef200> ====================\n",
      "==================== <function sort_stages at 0x7f48d14ef440> ====================\n",
      "==================== <function add_impulse_to_dangling_transforms at 0x7f48d14ef560> ====================\n",
      "==================== <function setup_timer_mapping at 0x7f48d14ef3b0> ====================\n",
      "==================== <function populate_data_channel_coders at 0x7f48d14ef4d0> ====================\n",
      "Creating state cache with size 100\n",
      "Created Worker handler <apache_beam.runners.portability.fn_api_runner.worker_handlers.EmbeddedWorkerHandler object at 0x7f48cc9c2510> for environment ref_Environment_default_environment_1 (beam:env:embedded_python:v1, b'')\n",
      "Started BigQuery job: <JobReference\n",
      " location: 'us-central1'\n",
      " projectId: 'mwpmltr'>\n",
      " bq show -j --format=prettyjson --project_id=mwpmltr None\n",
      "Using location 'us-central1' from table <TableReference\n",
      " datasetId: 'playground_central'\n",
      " projectId: 'mwpmltr'\n",
      " tableId: 'chicago_taxitrips_prep'> referenced by query \n",
      "    SELECT \n",
      "        IF(trip_month IS NULL, -1, trip_month) trip_month,\n",
      "        IF(trip_day IS NULL, -1, trip_day) trip_day,\n",
      "        IF(trip_day_of_week IS NULL, -1, trip_day_of_week) trip_day_of_week,\n",
      "        IF(trip_hour IS NULL, -1, trip_hour) trip_hour,\n",
      "        IF(trip_seconds IS NULL, -1, trip_seconds) trip_seconds,\n",
      "        IF(trip_miles IS NULL, -1, trip_miles) trip_miles,\n",
      "        IF(payment_type IS NULL, 'NA', payment_type) payment_type,\n",
      "        IF(pickup_grid IS NULL, 'NA', pickup_grid) pickup_grid,\n",
      "        IF(dropoff_grid IS NULL, 'NA', dropoff_grid) dropoff_grid,\n",
      "        IF(euclidean IS NULL, -1, euclidean) euclidean,\n",
      "        IF(loc_cross IS NULL, 'NA', loc_cross) loc_cross,\n",
      "        tip_bin\n",
      "    FROM playground_central.chicago_taxitrips_prep \n",
      "    WHERE ML_use = 'UNASSIGNED'\n",
      "    LIMIT 1000\n",
      "Dataset mwpmltr:beam_temp_dataset_4c776635ac1d4d13a49b5cff9014f045 does not exist so we will create it as temporary with location=us-central1\n",
      "Started BigQuery job: <JobReference\n",
      " jobId: 'beam_bq_job_QUERY_BQ_EXPORT_JOB_3eff58bc-d_1662853648_288'\n",
      " location: 'us-central1'\n",
      " projectId: 'mwpmltr'>\n",
      " bq show -j --format=prettyjson --project_id=mwpmltr beam_bq_job_QUERY_BQ_EXPORT_JOB_3eff58bc-d_1662853648_288\n",
      "Job status: RUNNING\n",
      "Job status: DONE\n",
      "Started BigQuery job: <JobReference\n",
      " jobId: 'beam_bq_job_EXPORT_BQ_EXPORT_JOB_3eff58bc-d_1662853654_587'\n",
      " location: 'us-central1'\n",
      " projectId: 'mwpmltr'>\n",
      " bq show -j --format=prettyjson --project_id=mwpmltr beam_bq_job_EXPORT_BQ_EXPORT_JOB_3eff58bc-d_1662853654_587\n",
      "Job status: RUNNING\n",
      "Job status: DONE\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.04310035705566406 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.04169893264770508 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.036736488342285156 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.030621767044067383 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.042211055755615234 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.041640520095825195 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.20 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.03886723518371582 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.03961682319641113 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.20 seconds.\n",
      "Examples generated.\n",
      "Value type <class 'NoneType'> of key version in exec_properties is not supported, going to drop it\n",
      "Value type <class 'NoneType'> of key input_fingerprint in exec_properties is not supported, going to drop it\n",
      "Value type <class 'list'> of key _beam_pipeline_args in exec_properties is not supported, going to drop it\n",
      "Cleaning up stateless execution info.\n",
      "Execution 5 succeeded.\n",
      "Cleaning up stateful execution info.\n",
      "stateful_working_dir /home/jupyter/mlops-with-vertex-ai/gs:/gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/TrainDataGen/.system/stateful_working_dir is not found, not going to delete it.\n",
      "Publishing output artifacts defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/TrainDataGen/examples/5\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:TrainDataGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:TrainDataGen:examples:0\"\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}) for execution 5\n",
      "MetadataStore with DB connection initialized\n",
      "Component TrainDataGen is finished.\n",
      "Component WarmstartModelResolver is running.\n",
      "Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.dsl.components.common.resolver.Resolver\"\n",
      "  }\n",
      "  id: \"WarmstartModelResolver\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.WarmstartModelResolver\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"latest_model\"\n",
      "    value {\n",
      "      channels {\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  resolver_config {\n",
      "    resolver_steps {\n",
      "      class_path: \"tfx.dsl.input_resolution.strategies.latest_artifact_strategy.LatestArtifactStrategy\"\n",
      "      config_json: \"{}\"\n",
      "      input_keys: \"latest_model\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"ModelTrainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "Running as an resolver node.\n",
      "MetadataStore with DB connection initialized\n",
      "Artifact type Model is not found in MLMD.\n",
      "Component WarmstartModelResolver is finished.\n",
      "Component StatisticsGen is running.\n",
      "Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
      "    base_type: PROCESS\n",
      "  }\n",
      "  id: \"StatisticsGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.StatisticsGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"TrainDataGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.TrainDataGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          base_type: STATISTICS\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"TrainDataGen\"\n",
      "downstream_nodes: \"ExampleValidator\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "MetadataStore with DB connection initialized\n",
      "MetadataStore with DB connection initialized\n",
      "Going to run a new execution 7\n",
      "Going to run a new execution: ExecutionInfo(execution_id=7, input_dict={'examples': [Artifact(artifact: id: 4\n",
      "type_id: 20\n",
      "uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/TrainDataGen/examples/5\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"file_format\"\n",
      "  value {\n",
      "    string_value: \"tfrecords_gzip\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:TrainDataGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:TrainDataGen:examples:0\"\n",
      "create_time_since_epoch: 1662853662190\n",
      "last_update_time_since_epoch: 1662853662190\n",
      ", artifact_type: id: 20\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/StatisticsGen/statistics/7\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:StatisticsGen:statistics:0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:StatisticsGen:statistics:0\"\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")]}), exec_properties={'exclude_splits': '[]'}, execution_output_uri='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/StatisticsGen/.system/executor_execution/7/executor_output.pb', stateful_working_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/StatisticsGen/.system/stateful_working_dir/2022-09-10T23:47:00.785303', tmp_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/StatisticsGen/.system/executor_execution/7/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
      "    base_type: PROCESS\n",
      "  }\n",
      "  id: \"StatisticsGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.StatisticsGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"TrainDataGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.TrainDataGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          base_type: STATISTICS\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"TrainDataGen\"\n",
      "downstream_nodes: \"ExampleValidator\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      ", pipeline_run_id='2022-09-10T23:47:00.785303')\n",
      "Attempting to infer TFX Python dependency for beam\n",
      "Copying all content from install dir /home/jupyter/.local/lib/python3.7/site-packages/tfx to temp dir /tmp/tmps6xvrn4i/build/tfx\n",
      "Generating a temp setup file at /tmp/tmps6xvrn4i/build/tfx/setup.py\n",
      "Creating temporary sdist package, logs available at /tmp/tmps6xvrn4i/build/tfx/setup.log\n",
      "E0910 23:47:44.822322585    2595 fork_posix.cc:76]           Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "Added --extra_package=/tmp/tmps6xvrn4i/build/tfx/dist/tfx_ephemeral-1.8.0.tar.gz to beam args\n",
      "Generating statistics for split train.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.04429793357849121 seconds.\n",
      "Using Any for unsupported type: typing.Mapping[tensorflow_data_validation.types.FeaturePath, ForwardRef('schema_pb2.FeatureType')]\n",
      "Using Any for unsupported type: typing.Mapping[tensorflow_data_validation.types.FeaturePath, ForwardRef('schema_pb2.FeatureType')]\n",
      "Using Any for unsupported type: typing.Mapping[tensorflow_data_validation.types.FeaturePath, ForwardRef('schema_pb2.FeatureType')]\n",
      "Statistics for split train written to gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/StatisticsGen/statistics/7/Split-train.\n",
      "Generating statistics for split eval.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.03654670715332031 seconds.\n",
      "Using Any for unsupported type: typing.Mapping[tensorflow_data_validation.types.FeaturePath, ForwardRef('schema_pb2.FeatureType')]\n",
      "Using Any for unsupported type: typing.Mapping[tensorflow_data_validation.types.FeaturePath, ForwardRef('schema_pb2.FeatureType')]\n",
      "Using Any for unsupported type: typing.Mapping[tensorflow_data_validation.types.FeaturePath, ForwardRef('schema_pb2.FeatureType')]\n",
      "Statistics for split eval written to gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/StatisticsGen/statistics/7/Split-eval.\n",
      "Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n",
      "Default Python SDK image for environment is apache/beam_python3.7_sdk:2.39.0\n",
      "==================== <function annotate_downstream_side_inputs at 0x7f48d14ee5f0> ====================\n",
      "==================== <function fix_side_input_pcoll_coders at 0x7f48d14ee710> ====================\n",
      "==================== <function pack_combiners at 0x7f48d14eec20> ====================\n",
      "==================== <function lift_combiners at 0x7f48d14eecb0> ====================\n",
      "==================== <function expand_sdf at 0x7f48d14eee60> ====================\n",
      "==================== <function expand_gbk at 0x7f48d14eeef0> ====================\n",
      "==================== <function sink_flattens at 0x7f48d14ef050> ====================\n",
      "==================== <function greedily_fuse at 0x7f48d14ef0e0> ====================\n",
      "==================== <function read_to_impulse at 0x7f48d14ef170> ====================\n",
      "==================== <function impulse_to_input at 0x7f48d14ef200> ====================\n",
      "==================== <function sort_stages at 0x7f48d14ef440> ====================\n",
      "==================== <function add_impulse_to_dangling_transforms at 0x7f48d14ef560> ====================\n",
      "==================== <function setup_timer_mapping at 0x7f48d14ef3b0> ====================\n",
      "==================== <function populate_data_channel_coders at 0x7f48d14ef4d0> ====================\n",
      "Creating state cache with size 100\n",
      "Created Worker handler <apache_beam.runners.portability.fn_api_runner.worker_handlers.EmbeddedWorkerHandler object at 0x7f48cce95650> for environment ref_Environment_default_environment_1 (beam:env:embedded_python:v1, b'')\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.03538846969604492 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.028158187866210938 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.03311610221862793 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.029183626174926758 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.038233041763305664 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.20 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.03914237022399902 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.20 seconds.\n",
      "Cleaning up stateless execution info.\n",
      "Execution 7 succeeded.\n",
      "Cleaning up stateful execution info.\n",
      "stateful_working_dir /home/jupyter/mlops-with-vertex-ai/gs:/gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/StatisticsGen/.system/stateful_working_dir is not found, not going to delete it.\n",
      "Publishing output artifacts defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/StatisticsGen/statistics/7\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:StatisticsGen:statistics:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:StatisticsGen:statistics:0\"\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")]}) for execution 7\n",
      "MetadataStore with DB connection initialized\n",
      "Component StatisticsGen is finished.\n",
      "Component ExampleValidator is running.\n",
      "Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.example_validator.component.ExampleValidator\"\n",
      "  }\n",
      "  id: \"ExampleValidator\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.ExampleValidator\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaImporter\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.SchemaImporter\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"result\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"StatisticsGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.StatisticsGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ExampleStatistics\"\n",
      "            base_type: STATISTICS\n",
      "          }\n",
      "        }\n",
      "        output_key: \"statistics\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"anomalies\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleAnomalies\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"SchemaImporter\"\n",
      "upstream_nodes: \"StatisticsGen\"\n",
      "downstream_nodes: \"DataTransformer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "MetadataStore with DB connection initialized\n",
      "MetadataStore with DB connection initialized\n",
      "Going to run a new execution 8\n",
      "Going to run a new execution: ExecutionInfo(execution_id=8, input_dict={'schema': [Artifact(artifact: id: 2\n",
      "type_id: 18\n",
      "uri: \"src/raw_schema\"\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1662853623948\n",
      "last_update_time_since_epoch: 1662853623948\n",
      ", artifact_type: id: 18\n",
      "name: \"Schema\"\n",
      ")], 'statistics': [Artifact(artifact: id: 5\n",
      "type_id: 22\n",
      "uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/StatisticsGen/statistics/7\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:StatisticsGen:statistics:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:StatisticsGen:statistics:0\"\n",
      "create_time_since_epoch: 1662853671441\n",
      "last_update_time_since_epoch: 1662853671441\n",
      ", artifact_type: id: 22\n",
      "name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'anomalies': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ExampleValidator/anomalies/8\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:ExampleValidator:anomalies:0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:ExampleValidator:anomalies:0\"\n",
      ", artifact_type: name: \"ExampleAnomalies\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")]}), exec_properties={'exclude_splits': '[]'}, execution_output_uri='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ExampleValidator/.system/executor_execution/8/executor_output.pb', stateful_working_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ExampleValidator/.system/stateful_working_dir/2022-09-10T23:47:00.785303', tmp_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ExampleValidator/.system/executor_execution/8/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.example_validator.component.ExampleValidator\"\n",
      "  }\n",
      "  id: \"ExampleValidator\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.ExampleValidator\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaImporter\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.SchemaImporter\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"result\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"StatisticsGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.StatisticsGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ExampleStatistics\"\n",
      "            base_type: STATISTICS\n",
      "          }\n",
      "        }\n",
      "        output_key: \"statistics\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"anomalies\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleAnomalies\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"SchemaImporter\"\n",
      "upstream_nodes: \"StatisticsGen\"\n",
      "downstream_nodes: \"DataTransformer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      ", pipeline_run_id='2022-09-10T23:47:00.785303')\n",
      "Validating schema against the computed statistics for split train.\n",
      "Validation complete for split train. Anomalies written to gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ExampleValidator/anomalies/8/Split-train.\n",
      "Validating schema against the computed statistics for split eval.\n",
      "Validation complete for split eval. Anomalies written to gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ExampleValidator/anomalies/8/Split-eval.\n",
      "Cleaning up stateless execution info.\n",
      "Execution 8 succeeded.\n",
      "Cleaning up stateful execution info.\n",
      "stateful_working_dir /home/jupyter/mlops-with-vertex-ai/gs:/gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ExampleValidator/.system/stateful_working_dir is not found, not going to delete it.\n",
      "Publishing output artifacts defaultdict(<class 'list'>, {'anomalies': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ExampleValidator/anomalies/8\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:ExampleValidator:anomalies:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:ExampleValidator:anomalies:0\"\n",
      ", artifact_type: name: \"ExampleAnomalies\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")]}) for execution 8\n",
      "MetadataStore with DB connection initialized\n",
      "Component ExampleValidator is finished.\n",
      "Component DataTransformer is running.\n",
      "Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.transform.component.Transform\"\n",
      "    base_type: TRANSFORM\n",
      "  }\n",
      "  id: \"DataTransformer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.DataTransformer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"TrainDataGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.TrainDataGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaImporter\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.SchemaImporter\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"result\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"post_transform_anomalies\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleAnomalies\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"post_transform_schema\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"post_transform_stats\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          base_type: STATISTICS\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"pre_transform_schema\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"pre_transform_stats\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          base_type: STATISTICS\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"TransformGraph\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"transformed_examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "          base_type: DATASET\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"updated_analyzer_cache\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"TransformCache\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"disable_statistics\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"force_tf_compat_v1\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"transformations@gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/_wheels/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"splits_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"analyze\\\": [\\n    \\\"train\\\"\\n  ],\\n  \\\"transform\\\": [\\n    \\\"train\\\",\\n    \\\"eval\\\"\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"ExampleValidator\"\n",
      "upstream_nodes: \"SchemaImporter\"\n",
      "upstream_nodes: \"TrainDataGen\"\n",
      "downstream_nodes: \"ModelTrainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "MetadataStore with DB connection initialized\n",
      "MetadataStore with DB connection initialized\n",
      "Going to run a new execution 9\n",
      "Going to run a new execution: ExecutionInfo(execution_id=9, input_dict={'schema': [Artifact(artifact: id: 2\n",
      "type_id: 18\n",
      "uri: \"src/raw_schema\"\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1662853623948\n",
      "last_update_time_since_epoch: 1662853623948\n",
      ", artifact_type: id: 18\n",
      "name: \"Schema\"\n",
      ")], 'examples': [Artifact(artifact: id: 4\n",
      "type_id: 20\n",
      "uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/TrainDataGen/examples/5\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"file_format\"\n",
      "  value {\n",
      "    string_value: \"tfrecords_gzip\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:TrainDataGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:TrainDataGen:examples:0\"\n",
      "create_time_since_epoch: 1662853662190\n",
      "last_update_time_since_epoch: 1662853662190\n",
      ", artifact_type: id: 20\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'pre_transform_schema': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/pre_transform_schema/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:pre_transform_schema:0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:pre_transform_schema:0\"\n",
      ", artifact_type: name: \"Schema\"\n",
      ")], 'post_transform_stats': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/post_transform_stats/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:post_transform_stats:0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:post_transform_stats:0\"\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")], 'post_transform_schema': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/post_transform_schema/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:post_transform_schema:0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:post_transform_schema:0\"\n",
      ", artifact_type: name: \"Schema\"\n",
      ")], 'transformed_examples': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transformed_examples/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:transformed_examples:0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:transformed_examples:0\"\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")], 'post_transform_anomalies': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/post_transform_anomalies/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:post_transform_anomalies:0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:post_transform_anomalies:0\"\n",
      ", artifact_type: name: \"ExampleAnomalies\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")], 'updated_analyzer_cache': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/updated_analyzer_cache/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:updated_analyzer_cache:0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:updated_analyzer_cache:0\"\n",
      ", artifact_type: name: \"TransformCache\"\n",
      ")], 'pre_transform_stats': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/pre_transform_stats/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:pre_transform_stats:0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:pre_transform_stats:0\"\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")], 'transform_graph': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transform_graph/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:transform_graph:0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:transform_graph:0\"\n",
      ", artifact_type: name: \"TransformGraph\"\n",
      ")]}), exec_properties={'force_tf_compat_v1': 1, 'custom_config': 'null', 'splits_config': '{\\n  \"analyze\": [\\n    \"train\"\\n  ],\\n  \"transform\": [\\n    \"train\",\\n    \"eval\"\\n  ]\\n}', 'module_path': 'transformations@gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/_wheels/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl', 'disable_statistics': 0}, execution_output_uri='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/.system/executor_execution/9/executor_output.pb', stateful_working_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/.system/stateful_working_dir/2022-09-10T23:47:00.785303', tmp_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/.system/executor_execution/9/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.transform.component.Transform\"\n",
      "    base_type: TRANSFORM\n",
      "  }\n",
      "  id: \"DataTransformer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.DataTransformer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"TrainDataGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.TrainDataGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaImporter\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.SchemaImporter\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"result\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"post_transform_anomalies\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleAnomalies\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"post_transform_schema\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"post_transform_stats\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          base_type: STATISTICS\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"pre_transform_schema\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"pre_transform_stats\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          base_type: STATISTICS\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"TransformGraph\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"transformed_examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "          base_type: DATASET\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"updated_analyzer_cache\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"TransformCache\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"disable_statistics\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"force_tf_compat_v1\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"transformations@gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/_wheels/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"splits_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"analyze\\\": [\\n    \\\"train\\\"\\n  ],\\n  \\\"transform\\\": [\\n    \\\"train\\\",\\n    \\\"eval\\\"\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"ExampleValidator\"\n",
      "upstream_nodes: \"SchemaImporter\"\n",
      "upstream_nodes: \"TrainDataGen\"\n",
      "downstream_nodes: \"ModelTrainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      ", pipeline_run_id='2022-09-10T23:47:00.785303')\n",
      "Attempting to infer TFX Python dependency for beam\n",
      "Copying all content from install dir /home/jupyter/.local/lib/python3.7/site-packages/tfx to temp dir /tmp/tmprlpk3vip/build/tfx\n",
      "Generating a temp setup file at /tmp/tmprlpk3vip/build/tfx/setup.py\n",
      "Creating temporary sdist package, logs available at /tmp/tmprlpk3vip/build/tfx/setup.log\n",
      "E0910 23:48:00.835634469    2595 fork_posix.cc:76]           Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "Added --extra_package=/tmp/tmprlpk3vip/build/tfx/dist/tfx_ephemeral-1.8.0.tar.gz to beam args\n",
      "udf_utils.get_fn {'module_file': None, 'module_path': 'transformations@gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/_wheels/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl', 'preprocessing_fn': None} 'preprocessing_fn'\n",
      "Installing '/tmp/tmpbj7d51az/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl' to a temporary directory.\n",
      "Executing: ['/opt/conda/bin/python', '-m', 'pip', 'install', '--target', '/tmp/tmpeuiwvfza', '/tmp/tmpbj7d51az/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl']\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mProcessing /tmp/tmpbj7d51az/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: tfx-user-code-DataTransformer\n",
      "Successfully installed tfx-user-code-DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Successfully installed '/tmp/tmpbj7d51az/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl'.\n",
      "udf_utils.get_fn {'module_file': None, 'module_path': 'transformations@gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/_wheels/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl', 'stats_options_updater_fn': None} 'stats_options_updater_fn'\n",
      "Installing '/tmp/tmpd0q95g4e/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl' to a temporary directory.\n",
      "Executing: ['/opt/conda/bin/python', '-m', 'pip', 'install', '--target', '/tmp/tmpwig7yys8', '/tmp/tmpd0q95g4e/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl']\n",
      "E0910 23:48:06.050305287    2595 fork_posix.cc:76]           Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mProcessing /tmp/tmpd0q95g4e/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: tfx-user-code-DataTransformer\n",
      "Successfully installed tfx-user-code-DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Successfully installed '/tmp/tmpd0q95g4e/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl'.\n",
      "Installing '/tmp/tmpxvxjvil2/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl' to a temporary directory.\n",
      "Executing: ['/opt/conda/bin/python', '-m', 'pip', 'install', '--target', '/tmp/tmp2jyh_uvw', '/tmp/tmpxvxjvil2/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl']\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mProcessing /tmp/tmpxvxjvil2/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: tfx-user-code-DataTransformer\n",
      "Successfully installed tfx-user-code-DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Successfully installed '/tmp/tmpxvxjvil2/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl'.\n",
      "Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "From /home/jupyter/.local/lib/python3.7/site-packages/tensorflow_transform/tf_utils.py:326: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[str, Union[NoneType, _Dataset]], Union[Dict[str, Dict[str, PCollection]], NoneType], int] instead.\n",
      "This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[str, Union[NoneType, _Dataset]], Union[Dict[str, Dict[str, PCollection]], NoneType], int] instead.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.03173947334289551 seconds.\n",
      "Tensorflow version (2.8.2) found. However Tensorflow Transform is running in tf.compat.v1 mode. This could be either because TF2 was disabled or `Context.force_tf_compat_v1=True`. Features such as tf.function may not work as intended. \n",
      "2022-09-10 23:48:13.636945: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/\n",
      "2022-09-10 23:48:13.637011: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-10 23:48:13.637035: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (python-20220624-164215-bjacob): /proc/driver/nvidia/version does not exist\n",
      "2022-09-10 23:48:13.637497: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "From /opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:204: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "Assets added to graph.\n",
      "No assets to write.\n",
      "Issue encountered when serializing tft_mapper_use.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Counter' object has no attribute 'name'\n",
      "Issue encountered when serializing tft_vocabulary_size_by_name_collection.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'tuple' object has no attribute 'name'\n",
      "SavedModel written to: gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transform_graph/9/.temp_path/tftransform_tmp/6af83b9f3dd949899a38fa2794e28945/saved_model.pb\n",
      "Assets added to graph.\n",
      "No assets to write.\n",
      "Issue encountered when serializing tft_mapper_use.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Counter' object has no attribute 'name'\n",
      "Issue encountered when serializing tft_vocabulary_size_by_name_collection.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'tuple' object has no attribute 'name'\n",
      "SavedModel written to: gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transform_graph/9/.temp_path/tftransform_tmp/abf82edf09df42fcae449e83f04ee853/saved_model.pb\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.03489089012145996 seconds.\n",
      "Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Tensorflow version (2.8.2) found. However Tensorflow Transform is running in tf.compat.v1 mode. This could be either because TF2 was disabled or `Context.force_tf_compat_v1=True`. Features such as tf.function may not work as intended. \n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.043512582778930664 seconds.\n",
      "Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Tensorflow version (2.8.2) found. However Tensorflow Transform is running in tf.compat.v1 mode. This could be either because TF2 was disabled or `Context.force_tf_compat_v1=True`. Features such as tf.function may not work as intended. \n",
      "Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n",
      "Default Python SDK image for environment is apache/beam_python3.7_sdk:2.39.0\n",
      "==================== <function annotate_downstream_side_inputs at 0x7f48d14ee5f0> ====================\n",
      "==================== <function fix_side_input_pcoll_coders at 0x7f48d14ee710> ====================\n",
      "==================== <function pack_combiners at 0x7f48d14eec20> ====================\n",
      "==================== <function lift_combiners at 0x7f48d14eecb0> ====================\n",
      "==================== <function expand_sdf at 0x7f48d14eee60> ====================\n",
      "==================== <function expand_gbk at 0x7f48d14eeef0> ====================\n",
      "==================== <function sink_flattens at 0x7f48d14ef050> ====================\n",
      "==================== <function greedily_fuse at 0x7f48d14ef0e0> ====================\n",
      "==================== <function read_to_impulse at 0x7f48d14ef170> ====================\n",
      "==================== <function impulse_to_input at 0x7f48d14ef200> ====================\n",
      "==================== <function sort_stages at 0x7f48d14ef440> ====================\n",
      "==================== <function add_impulse_to_dangling_transforms at 0x7f48d14ef560> ====================\n",
      "==================== <function setup_timer_mapping at 0x7f48d14ef3b0> ====================\n",
      "==================== <function populate_data_channel_coders at 0x7f48d14ef4d0> ====================\n",
      "Creating state cache with size 100\n",
      "Created Worker handler <apache_beam.runners.portability.fn_api_runner.worker_handlers.EmbeddedWorkerHandler object at 0x7f48ccb29a90> for environment ref_Environment_default_environment_1 (beam:env:embedded_python:v1, b'')\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.036908864974975586 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.03158259391784668 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.039559125900268555 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.03606438636779785 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.03939652442932129 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.039464712142944336 seconds.\n",
      "struct2tensor is not available.\n",
      "tensorflow_decision_forests is not available.\n",
      "tensorflow_text is not available.\n",
      "Saver not created because there are no variables in the graph to restore\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.03729748725891113 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.20 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.04367327690124512 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.20 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.036072492599487305 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.036774396896362305 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.03928351402282715 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.026566743850708008 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.04478764533996582 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.03420543670654297 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.032756805419921875 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.03750157356262207 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.040021419525146484 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.03999185562133789 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.20 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.03941512107849121 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.034501075744628906 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.20 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.03462553024291992 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.04417896270751953 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.20 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.0374302864074707 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.038400888442993164 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.20 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.03315424919128418 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.036769866943359375 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.20 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.03467988967895508 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.04660153388977051 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.20 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.03742170333862305 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.03423714637756348 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.20 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.037746429443359375 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.034739017486572266 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.20 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.030169963836669922 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.20 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.042162179946899414 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.02952265739440918 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.03178215026855469 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.03750443458557129 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.20 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.03923463821411133 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.30 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.03898334503173828 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.20 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.03101325035095215 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.20 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.03961515426635742 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.20 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.0322566032409668 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.20 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.04391908645629883 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.20 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.039785146713256836 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.03528785705566406 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.20 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.034070730209350586 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.03702592849731445 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.20 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.03626680374145508 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.028893470764160156 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.20 seconds.\n",
      "struct2tensor is not available.\n",
      "tensorflow_decision_forests is not available.\n",
      "tensorflow_text is not available.\n",
      "Saver not created because there are no variables in the graph to restore\n",
      "Assets added to graph.\n",
      "Assets written to: gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transform_graph/9/.temp_path/tftransform_tmp/3829c0b4703d4d1bb1e8a520ccf7f44c/assets\n",
      "SavedModel written to: gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transform_graph/9/.temp_path/tftransform_tmp/3829c0b4703d4d1bb1e8a520ccf7f44c/saved_model.pb\n",
      "struct2tensor is not available.\n",
      "tensorflow_decision_forests is not available.\n",
      "tensorflow_text is not available.\n",
      "Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_4:0\\022\\ntrip_month\"\n",
      "\n",
      "Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_7:0\\022\\010trip_day\"\n",
      "\n",
      "Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_10:0\\022\\020trip_day_of_week\"\n",
      "\n",
      "Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_13:0\\022\\ttrip_hour\"\n",
      "\n",
      "Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_16:0\\022\\014payment_type\"\n",
      "\n",
      "Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_19:0\\022\\013pickup_grid\"\n",
      "\n",
      "Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_22:0\\022\\014dropoff_grid\"\n",
      "\n",
      "Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_25:0\\022\\tloc_cross\"\n",
      "\n",
      "Saver not created because there are no variables in the graph to restore\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.03582358360290527 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.20 seconds.\n",
      "struct2tensor is not available.\n",
      "tensorflow_decision_forests is not available.\n",
      "tensorflow_text is not available.\n",
      "Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_4:0\\022\\ntrip_month\"\n",
      "\n",
      "Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_7:0\\022\\010trip_day\"\n",
      "\n",
      "Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_10:0\\022\\020trip_day_of_week\"\n",
      "\n",
      "Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_13:0\\022\\ttrip_hour\"\n",
      "\n",
      "Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_16:0\\022\\014payment_type\"\n",
      "\n",
      "Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_19:0\\022\\013pickup_grid\"\n",
      "\n",
      "Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_22:0\\022\\014dropoff_grid\"\n",
      "\n",
      "Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_25:0\\022\\tloc_cross\"\n",
      "\n",
      "Saver not created because there are no variables in the graph to restore\n",
      "struct2tensor is not available.\n",
      "tensorflow_decision_forests is not available.\n",
      "tensorflow_text is not available.\n",
      "Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_4:0\\022\\ntrip_month\"\n",
      "\n",
      "Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_7:0\\022\\010trip_day\"\n",
      "\n",
      "Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_10:0\\022\\020trip_day_of_week\"\n",
      "\n",
      "Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_13:0\\022\\ttrip_hour\"\n",
      "\n",
      "Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_16:0\\022\\014payment_type\"\n",
      "\n",
      "Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_19:0\\022\\013pickup_grid\"\n",
      "\n",
      "Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_22:0\\022\\014dropoff_grid\"\n",
      "\n",
      "Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_25:0\\022\\tloc_cross\"\n",
      "\n",
      "Saver not created because there are no variables in the graph to restore\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.032745361328125 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.041396379470825195 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.036142826080322266 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.03240799903869629 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.20 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.042412519454956055 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 0 files in 0.04018235206604004 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.20 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.0328981876373291 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.20 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.0379183292388916 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.30 seconds.\n",
      "Cleaning up stateless execution info.\n",
      "Execution 9 succeeded.\n",
      "Cleaning up stateful execution info.\n",
      "stateful_working_dir /home/jupyter/mlops-with-vertex-ai/gs:/gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/.system/stateful_working_dir is not found, not going to delete it.\n",
      "Publishing output artifacts defaultdict(<class 'list'>, {'pre_transform_schema': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/pre_transform_schema/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:pre_transform_schema:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:pre_transform_schema:0\"\n",
      ", artifact_type: name: \"Schema\"\n",
      ")], 'post_transform_stats': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/post_transform_stats/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:post_transform_stats:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:post_transform_stats:0\"\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")], 'post_transform_schema': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/post_transform_schema/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:post_transform_schema:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:post_transform_schema:0\"\n",
      ", artifact_type: name: \"Schema\"\n",
      ")], 'transformed_examples': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transformed_examples/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:transformed_examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:transformed_examples:0\"\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")], 'post_transform_anomalies': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/post_transform_anomalies/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:post_transform_anomalies:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:post_transform_anomalies:0\"\n",
      ", artifact_type: name: \"ExampleAnomalies\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")], 'updated_analyzer_cache': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/updated_analyzer_cache/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:updated_analyzer_cache:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:updated_analyzer_cache:0\"\n",
      ", artifact_type: name: \"TransformCache\"\n",
      ")], 'pre_transform_stats': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/pre_transform_stats/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:pre_transform_stats:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:pre_transform_stats:0\"\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")], 'transform_graph': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transform_graph/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:transform_graph:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:transform_graph:0\"\n",
      ", artifact_type: name: \"TransformGraph\"\n",
      ")]}) for execution 9\n",
      "MetadataStore with DB connection initialized\n",
      "Component DataTransformer is finished.\n",
      "Component ModelTrainer is running.\n",
      "Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.trainer.component.Trainer\"\n",
      "    base_type: TRAIN\n",
      "  }\n",
      "  id: \"ModelTrainer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.ModelTrainer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"base_model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"WarmstartModelResolver\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.WarmstartModelResolver\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"latest_model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"DataTransformer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.DataTransformer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transformed_examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"hyperparameters\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"HyperparamsGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.HyperparamsGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"HyperParameters\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"hyperparameters\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaImporter\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.SchemaImporter\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"result\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"DataTransformer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.DataTransformer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"TransformGraph\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transform_graph\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Model\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"model_run\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelRun\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"eval_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"runner@gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/_wheels/tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"train_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"DataTransformer\"\n",
      "upstream_nodes: \"HyperparamsGen\"\n",
      "upstream_nodes: \"SchemaImporter\"\n",
      "upstream_nodes: \"WarmstartModelResolver\"\n",
      "downstream_nodes: \"ModelEvaluator\"\n",
      "downstream_nodes: \"ModelPusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "MetadataStore with DB connection initialized\n",
      "Artifact type Model is not found in MLMD.\n",
      "MetadataStore with DB connection initialized\n",
      "Going to run a new execution 10\n",
      "Going to run a new execution: ExecutionInfo(execution_id=10, input_dict={'schema': [Artifact(artifact: id: 2\n",
      "type_id: 18\n",
      "uri: \"src/raw_schema\"\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1662853623948\n",
      "last_update_time_since_epoch: 1662853623948\n",
      ", artifact_type: id: 18\n",
      "name: \"Schema\"\n",
      ")], 'transform_graph': [Artifact(artifact: id: 14\n",
      "type_id: 27\n",
      "uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transform_graph/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:transform_graph:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:transform_graph:0\"\n",
      "create_time_since_epoch: 1662853754259\n",
      "last_update_time_since_epoch: 1662853754259\n",
      ", artifact_type: id: 27\n",
      "name: \"TransformGraph\"\n",
      ")], 'examples': [Artifact(artifact: id: 10\n",
      "type_id: 20\n",
      "uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transformed_examples/9\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:transformed_examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:transformed_examples:0\"\n",
      "create_time_since_epoch: 1662853754258\n",
      "last_update_time_since_epoch: 1662853754258\n",
      ", artifact_type: id: 20\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")], 'hyperparameters': [Artifact(artifact: id: 1\n",
      "type_id: 16\n",
      "uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/HyperparamsGen/hyperparameters/2\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:HyperparamsGen:hyperparameters:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:HyperparamsGen:hyperparameters:0\"\n",
      "create_time_since_epoch: 1662853623904\n",
      "last_update_time_since_epoch: 1662853623904\n",
      ", artifact_type: id: 16\n",
      "name: \"HyperParameters\"\n",
      ")], 'base_model': []}, output_dict=defaultdict(<class 'list'>, {'model': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ModelTrainer/model/10\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:ModelTrainer:model:0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:ModelTrainer:model:0\"\n",
      ", artifact_type: name: \"Model\"\n",
      "base_type: MODEL\n",
      ")], 'model_run': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ModelTrainer/model_run/10\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:ModelTrainer:model_run:0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:ModelTrainer:model_run:0\"\n",
      ", artifact_type: name: \"ModelRun\"\n",
      ")]}), exec_properties={'module_path': 'runner@gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/_wheels/tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8-py3-none-any.whl', 'train_args': '{}', 'custom_config': 'null', 'eval_args': '{}'}, execution_output_uri='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ModelTrainer/.system/executor_execution/10/executor_output.pb', stateful_working_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ModelTrainer/.system/stateful_working_dir/2022-09-10T23:47:00.785303', tmp_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ModelTrainer/.system/executor_execution/10/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.trainer.component.Trainer\"\n",
      "    base_type: TRAIN\n",
      "  }\n",
      "  id: \"ModelTrainer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.ModelTrainer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"base_model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"WarmstartModelResolver\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.WarmstartModelResolver\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"latest_model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"DataTransformer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.DataTransformer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transformed_examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"hyperparameters\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"HyperparamsGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.HyperparamsGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"HyperParameters\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"hyperparameters\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaImporter\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.SchemaImporter\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"result\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"DataTransformer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.DataTransformer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"TransformGraph\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transform_graph\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Model\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"model_run\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelRun\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"eval_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"runner@gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/_wheels/tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"train_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"DataTransformer\"\n",
      "upstream_nodes: \"HyperparamsGen\"\n",
      "upstream_nodes: \"SchemaImporter\"\n",
      "upstream_nodes: \"WarmstartModelResolver\"\n",
      "downstream_nodes: \"ModelEvaluator\"\n",
      "downstream_nodes: \"ModelPusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      ", pipeline_run_id='2022-09-10T23:47:00.785303')\n",
      "Train on the 'train' split when train_args.splits is not set.\n",
      "Evaluate on the 'eval' split when eval_args.splits is not set.\n",
      "Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "udf_utils.get_fn {'module_path': 'runner@gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/_wheels/tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8-py3-none-any.whl', 'train_args': '{}', 'custom_config': 'null', 'eval_args': '{}'} 'run_fn'\n",
      "Installing '/tmp/tmpw3m7g_fg/tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8-py3-none-any.whl' to a temporary directory.\n",
      "Executing: ['/opt/conda/bin/python', '-m', 'pip', 'install', '--target', '/tmp/tmp9g2lgp7z', '/tmp/tmpw3m7g_fg/tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8-py3-none-any.whl']\n",
      "E0910 23:49:17.390388545    2595 fork_posix.cc:76]           Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mProcessing /tmp/tmpw3m7g_fg/tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8-py3-none-any.whl\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: tfx-user-code-ModelTrainer\n",
      "Successfully installed tfx-user-code-ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Successfully installed '/tmp/tmpw3m7g_fg/tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8-py3-none-any.whl'.\n",
      "Training model.\n",
      "Runner started...\n",
      "fn_args: FnArgs(working_dir=None, train_files=['gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transformed_examples/9/Split-train/*'], eval_files=['gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transformed_examples/9/Split-eval/*'], train_steps=None, eval_steps=None, schema_path='src/raw_schema/schema.pbtxt', schema_file='src/raw_schema/schema.pbtxt', transform_graph_path='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transform_graph/9', transform_output='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transform_graph/9', data_accessor=DataAccessor(tf_dataset_factory=<function get_tf_dataset_factory_from_artifact.<locals>.dataset_factory at 0x7f48750167a0>, record_batch_factory=<function get_record_batch_factory_from_artifact.<locals>.record_batch_factory at 0x7f487607ef80>, data_view_decode_fn=None), serving_model_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ModelTrainer/model/10/Format-Serving', eval_model_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ModelTrainer/model/10/Format-TFMA', model_run_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ModelTrainer/model_run/10', base_model=None, hyperparameters={'num_epochs': 1, 'batch_size': 512, 'learning_rate': 0.001, 'hidden_units': [128, 128]}, custom_config=None)\n",
      "\n",
      "Hyperparameter:\n",
      "{'num_epochs': 1, 'batch_size': 512, 'learning_rate': 0.001, 'hidden_units': [128, 128]}\n",
      "\n",
      "Runner executing trainer...\n",
      "Loading tft output from gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transform_graph/9\n",
      "Model training started...\n",
      "      1/Unknown - 1s 1s/step - loss: 0.5690 - accuracy: 1.0000Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5690 - accuracy: 1.0000\n",
      "Model training completed.\n",
      "Runner executing exporter...\n",
      "Saver not created because there are no variables in the graph to restore\n",
      "struct2tensor is not available.\n",
      "tensorflow_decision_forests is not available.\n",
      "tensorflow_text is not available.\n",
      "Model export started...\n",
      "2022-09-10 23:49:29.373382: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "Assets written to: gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ModelTrainer/model/10/Format-Serving/assets\n",
      "Model export completed.\n",
      "Runner completed.\n",
      "stateful_working_dir /home/jupyter/mlops-with-vertex-ai/gs:/gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ModelTrainer/.system/stateful_working_dir is not found, not going to delete it.\n",
      "E0910 23:49:41.045329868    2595 fork_posix.cc:76]           Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7f48755fb910> and <keras.engine.input_layer.InputLayer object at 0x7f48c44be7d0>).\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.03341841697692871 seconds.\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.Sequence[typing.MutableMapping[str, typing.Any]]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.Sequence[typing.MutableMapping[str, typing.Any]]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.Sequence[typing.MutableMapping[str, typing.Any]]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.Sequence[typing.MutableMapping[str, typing.Any]]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.Sequence[typing.MutableMapping[str, typing.Any]]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.Sequence[typing.MutableMapping[str, typing.Any]]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.Sequence[typing.MutableMapping[str, typing.Any]]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.Sequence[typing.MutableMapping[str, typing.Any]]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.Sequence[typing.MutableMapping[str, typing.Any]]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7f4875d42110> and <keras.engine.input_layer.InputLayer object at 0x7f4875dcc6d0>).\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.Type[typing.Union[tensorflow_model_analysis.metrics.metric_types.MetricKey, tensorflow_model_analysis.metrics.metric_types.PlotKey, tensorflow_model_analysis.metrics.metric_types.AttributionsKey]]\n",
      "Using Any for unsupported type: typing.Type[typing.Union[tensorflow_model_analysis.metrics.metric_types.MetricKey, tensorflow_model_analysis.metrics.metric_types.PlotKey, tensorflow_model_analysis.metrics.metric_types.AttributionsKey]]\n",
      "Using Any for unsupported type: typing.Type[typing.Union[tensorflow_model_analysis.metrics.metric_types.MetricKey, tensorflow_model_analysis.metrics.metric_types.PlotKey, tensorflow_model_analysis.metrics.metric_types.AttributionsKey]]\n",
      "Using Any for unsupported type: typing.Callable[[typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, typing.Dict[str, typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor]]], typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, typing.Dict[str, typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor]]], typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, typing.Dict[str, typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor]]]], typing.Dict[str, typing.Tuple[typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor], typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor]]]]\n",
      "Using Any for unsupported type: typing.Callable[[typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, typing.Dict[str, typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor]]], typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, typing.Dict[str, typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor]]], typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, typing.Dict[str, typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor]]]], typing.Dict[str, typing.Tuple[typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor], typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor]]]]\n",
      "Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n",
      "Default Python SDK image for environment is apache/beam_python3.7_sdk:2.39.0\n",
      "==================== <function annotate_downstream_side_inputs at 0x7f48d14ee5f0> ====================\n",
      "==================== <function fix_side_input_pcoll_coders at 0x7f48d14ee710> ====================\n",
      "==================== <function pack_combiners at 0x7f48d14eec20> ====================\n",
      "==================== <function lift_combiners at 0x7f48d14eecb0> ====================\n",
      "==================== <function expand_sdf at 0x7f48d14eee60> ====================\n",
      "==================== <function expand_gbk at 0x7f48d14eeef0> ====================\n",
      "==================== <function sink_flattens at 0x7f48d14ef050> ====================\n",
      "==================== <function greedily_fuse at 0x7f48d14ef0e0> ====================\n",
      "==================== <function read_to_impulse at 0x7f48d14ef170> ====================\n",
      "==================== <function impulse_to_input at 0x7f48d14ef200> ====================\n",
      "==================== <function sort_stages at 0x7f48d14ef440> ====================\n",
      "==================== <function add_impulse_to_dangling_transforms at 0x7f48d14ef560> ====================\n",
      "==================== <function setup_timer_mapping at 0x7f48d14ef3b0> ====================\n",
      "==================== <function populate_data_channel_coders at 0x7f48d14ef4d0> ====================\n",
      "Creating state cache with size 100\n",
      "Created Worker handler <apache_beam.runners.portability.fn_api_runner.worker_handlers.EmbeddedWorkerHandler object at 0x7f4875182090> for environment ref_Environment_default_environment_1 (beam:env:embedded_python:v1, b'')\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.03832530975341797 seconds.\n",
      "Starting the file information of the input\n",
      "Finished listing 1 files in 0.04328656196594238 seconds.\n",
      "Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7f487506fe10> and <keras.engine.input_layer.InputLayer object at 0x7f487503eb90>).\n",
      "Large batch_size 36 failed with error Fail to call signature func with signature_name: serving_tf_example.\n",
      "                the inputs are:\n",
      " [b'\\n\\xcc\\x02\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa1\\x1d\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\xd4\\x1a\\x16E\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x85\\xeb\\xd1?\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x04'\n",
      " b'\\n\\xcc\\x02\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00@\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.7 41.9)\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\x94\\x05\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x8b\\xcclE\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x04\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)'\n",
      " b'\\n\\xcc\\x02\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa4\\x03\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x04\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.7 41.9)POINT(-87.7 41.9)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xcc\\xcc>'\n",
      " b'\\n\\xcc\\x02\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.7)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x8b\\x9blE\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xb8\\x1e\\x15@\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x11\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xe2\\x03\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x05\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.7)POINT(-87.6 41.7)\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.7)'\n",
      " b'\\n\\xcc\\x02\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0f\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x05\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\n\\xd7#?\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xd6\\x01\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)'\n",
      " b'\\n\\xc7\\x02\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 42)\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04333?\\n\\x1b\\n\\x0cpayment_type\\x12\\x0b\\n\\t\\n\\x07Dispute\\n/\\n\\tloc_cross\\x12\"\\n \\n\\x1ePOINT(-87.7 42)POINT(-87.7 42)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\xadN\\xcaD\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\"\\n\\x0bpickup_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 42)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa4\\x03'\n",
      " b'\\n\\xc6\\x02\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x1a\\n\\x0cpayment_type\\x12\\n\\n\\x08\\n\\x06Prcard\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa8\\x01\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0f\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n/\\n\\tloc_cross\\x12\"\\n \\n\\x1ePOINT(-87.7 42)POINT(-87.7 42)\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 42)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\"\\n\\x0bpickup_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 42)\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xcc\\x0c?'\n",
      " b'\\n\\xcb\\x02\\n\"\\n\\x0bpickup_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 42)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xa4pqA\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\x8a\\x12\\n\\x1f\\n\\x0cpayment_type\\x12\\x0f\\n\\r\\n\\x0bCredit Card\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\xab\\xa1F\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\n\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.9 42)\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n/\\n\\tloc_cross\\x12\"\\n \\n\\x1ePOINT(-87.7 42)POINT(-87.9 42)'\n",
      " b'\\n\\xc8\\x02\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\xdd7\\xc2F\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\x8d\\x0b\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04ff\\x8aA\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x06\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.9 42)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n1\\n\\tloc_cross\\x12$\\n\"\\n POINT(-87.6 41.9)POINT(-87.9 42)'\n",
      " b'\\n\\xcf\\x02\\n\\x1f\\n\\x0cpayment_type\\x12\\x0f\\n\\r\\n\\x0bCredit Card\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\x98\\x0c\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n1\\n\\tloc_cross\\x12$\\n\"\\n POINT(-87.7 41.9)POINT(-87.7 42)\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 42)\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x9a\\x99\\x19?\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\xf4\\xcf\\x1fF\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x12'\n",
      " b'\\n\\xc8\\x02\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xec\\t\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\xb6J\\x93F\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0b\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n1\\n\\tloc_cross\\x12$\\n\"\\n POINT(-87.7 41.9)POINT(-87.9 42)\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x9a\\x99AA\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.9 42)'\n",
      " b'\\n\\xcf\\x02\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xd1\\x12\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04_C\\xa9F\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\"\\n\\x0bpickup_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.9 42)\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0e\\n1\\n\\tloc_cross\\x12$\\n\"\\n POINT(-87.9 42)POINT(-87.6 41.9)\\n\\x1f\\n\\x0cpayment_type\\x12\\x0f\\n\\r\\n\\x0bCredit Card\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04{\\x14ZA\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02'\n",
      " b'\\n\\xcf\\x02\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xb0\\t\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.8)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x1b\\n\\x0cpayment_type\\x12\\x0b\\n\\t\\n\\x07Unknown\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x17\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x0f-\\xf7E\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.8)\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.8)POINT(-87.7 41.8)\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xcc4A\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02'\n",
      " b'\\n\\xcc\\x02\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.8)POINT(-87.7 41.9)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\x80\\x1e\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04@\\xf4\\x88E\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0c\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.8)\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00?\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)'\n",
      " b'\\n\\xcc\\x02\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0c\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04}\\x13\\xbeE\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xe1\\x03\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xccl@'\n",
      " b'\\n\\xcc\\x02\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04ff\\xc6?\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04:\\xf14E\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa6\\x03\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0f\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00'\n",
      " b'\\n\\xcc\\x02\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0e\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x9a\\x99\\x99?\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xf8\\x03\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01'\n",
      " b'\\n\\xcc\\x02\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x8f\\xc25?\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xc5\\x02\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x14'\n",
      " b'\\n\\xcc\\x02\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\t\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x04\\x13(D\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xccL?\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xac\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00'\n",
      " b'\\n\\xcc\\x02\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x1f\\x85k?\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\x9f\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\'\\xe4\\x8eD\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)'\n",
      " b'\\n\\xcc\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04333?\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x16\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xf0\\x01\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)'\n",
      " b'\\n\\xcc\\x02\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xf6(\\x1c?\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0f\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x1e\\x95RD\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa2\\x02\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01'\n",
      " b'\\n\\xcc\\x02\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04fff?\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa4\\x03\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x15\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00'\n",
      " b'\\n\\xcc\\x02\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xac\\x02\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xcc\\x8c?\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x06\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04:\\xf14E'\n",
      " b'\\n\\xcc\\x02\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xf0\\x01\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xcc\\xcc>\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01'\n",
      " b'\\n\\xcb\\x02\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xecQ8>\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0c\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x15\\n\\x0ctrip_seconds\\x12\\x05\\x1a\\x03\\n\\x018'\n",
      " b'\\n\\xcc\\x02\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xe0\\x03\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x11\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x9a\\x99\\x99?'\n",
      " b'\\n\\xcc\\x02\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.7 41.9)\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\r\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04ff>A\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xc4\\x0e\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x8b\\xcclE\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)'\n",
      " b'\\n\\xcc\\x02\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04ffv@\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x17\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xb0\\t\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.7 41.9)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x8b\\xcclE\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)'\n",
      " b'\\n\\xcc\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x14\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xca\\x03\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x8b\\xcclE\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.7 41.9)POINT(-87.6 41.9)\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x9a\\x99\\xb9?\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)'\n",
      " b'\\n\\xcc\\x02\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.7 41.9)POINT(-87.6 41.9)\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xb2\\x03\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x9c\\x9b\\xacD\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04H\\xe1z?'\n",
      " b'\\n\\xce\\x02\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xcc\\x05\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x8b\\xcclE\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x1a\\n\\x0cpayment_type\\x12\\n\\n\\x08\\n\\x06Mobile\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.7 41.9)POINT(-87.6 41.9)\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0f\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x8f\\xc25@'\n",
      " b'\\n\\xcc\\x02\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0e\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.7 41.9)POINT(-87.6 41.9)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04#\\xca\\xa5E\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xccL>\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\x94\\x05'\n",
      " b'\\n\\xd3\\x02\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.7 41.9)POINT(-87.6 41.9)\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00 @\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x8b\\xcclE\\n\\x1f\\n\\x0cpayment_type\\x12\\x0f\\n\\r\\n\\x0bCredit Card\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x12\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xf9\\x08\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)'\n",
      " b'\\n\\xcc\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.7 41.9)POINT(-87.7 41.9)\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\x8c\\x06\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04^\\xde\\xc0E\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04ff\\xb6@\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x05'\n",
      " b'\\n\\xcc\\x02\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x15\\x11PF\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.8)\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.8 41.8)\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.8 41.8)POINT(-87.6 41.8)\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0f\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\x90\\r\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xcc\\\\A\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07'].\n",
      "                The input_specs are:\n",
      " {'examples': TensorSpec(shape=(None,), dtype=tf.string, name='examples')}.. Attempting to run batch through serially. Note that this will significantly affect the performance.\n",
      "Execution 11 failed.\n",
      "\u001b[31mF\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m______________________________ test_e2e_pipeline _______________________________\u001b[0m\n",
      "\n",
      "self = <ConcreteFunction signature_wrapper(*, examples) at 0x7F4875969ED0>\n",
      "args = (<tf.Tensor: shape=(36,), dtype=string, numpy=\n",
      "array([b'\\n\\xcc\\x02\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x13\\..._miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xcc\\\\A\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07'],\n",
      "      dtype=object)>,)\n",
      "kwargs = {}, cancellation_manager = None\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m_call_impl\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, args, kwargs, cancellation_manager=\u001b[94mNone\u001b[39;49;00m):\n",
      "      \u001b[33m\"\"\"See `__call__` for details.\"\"\"\u001b[39;49;00m\n",
      "      \u001b[94mwith\u001b[39;49;00m trace.Trace(\u001b[96mself\u001b[39;49;00m._func_graph.name, tf_function_call=\u001b[33m\"\u001b[39;49;00m\u001b[33mconcrete\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\n",
      "        \u001b[90m# Construct the list of input tensors: check if the structured signature\u001b[39;49;00m\n",
      "        \u001b[90m# applies first; and if not, then use the flat signature.\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._function_spec \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\n",
      "          \u001b[94mtry\u001b[39;49;00m:\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._call_with_structured_signature(args, kwargs,\n",
      ">                                                       cancellation_manager)\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m:1611: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <ConcreteFunction signature_wrapper(*, examples) at 0x7F4875969ED0>\n",
      "args = (<tf.Tensor: shape=(36,), dtype=string, numpy=\n",
      "array([b'\\n\\xcc\\x02\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x13\\..._miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xcc\\\\A\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07'],\n",
      "      dtype=object)>,)\n",
      "kwargs = {'examples': <object object at 0x7f491141de40>}\n",
      "cancellation_manager = None\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m_call_with_structured_signature\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, args, kwargs, cancellation_manager):\n",
      "      \u001b[33m\"\"\"Executes the wrapped function with the structured signature.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Args:\u001b[39;49;00m\n",
      "    \u001b[33m    args: Positional arguments to the concrete function.\u001b[39;49;00m\n",
      "    \u001b[33m    kwargs: Keyword arguments to the concrete function.\u001b[39;49;00m\n",
      "    \u001b[33m    cancellation_manager: A `CancellationManager` that can be used to cancel\u001b[39;49;00m\n",
      "    \u001b[33m      function invocation.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Returns:\u001b[39;49;00m\n",
      "    \u001b[33m    The result of applying the function on the Tensors/Variables contained in\u001b[39;49;00m\n",
      "    \u001b[33m    `args` and `kwargs`.\u001b[39;49;00m\n",
      "    \u001b[33m  Raises:\u001b[39;49;00m\n",
      "    \u001b[33m    TypeError: if `args` and `kwargs` do not match the structured signature\u001b[39;49;00m\n",
      "    \u001b[33m      of this `ConcreteFunction`.\u001b[39;49;00m\n",
      "    \u001b[33m  \"\"\"\u001b[39;49;00m\n",
      "      args, kwargs, _, filtered_flat_args = \\\n",
      "          \u001b[96mself\u001b[39;49;00m._function_spec.canonicalize_function_inputs(*args, **kwargs)\n",
      ">     \u001b[96mself\u001b[39;49;00m._structured_signature_check_missing_args(args, kwargs)\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m:1688: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <ConcreteFunction signature_wrapper(*, examples) at 0x7F4875969ED0>\n",
      "args = (<tf.Tensor: shape=(36,), dtype=string, numpy=\n",
      "array([b'\\n\\xcc\\x02\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x13\\..._miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xcc\\\\A\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07'],\n",
      "      dtype=object)>,)\n",
      "kwargs = {'examples': <object object at 0x7f491141de40>}\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m_structured_signature_check_missing_args\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, args, kwargs):\n",
      "      \u001b[33m\"\"\"Raises a TypeError if any args are missing.\"\"\"\u001b[39;49;00m\n",
      "      arg_specs, kwarg_specs = \u001b[96mself\u001b[39;49;00m.structured_input_signature\n",
      "      missing_arguments = []\n",
      "      \u001b[94mfor\u001b[39;49;00m i, (arg, spec) \u001b[95min\u001b[39;49;00m \u001b[96menumerate\u001b[39;49;00m(\u001b[96mzip\u001b[39;49;00m(args, arg_specs)):\n",
      "        \u001b[94mif\u001b[39;49;00m arg \u001b[95mis\u001b[39;49;00m _BOUND_VALUE \u001b[95mand\u001b[39;49;00m _contains_type_spec(spec):\n",
      "          missing_arguments.append(\u001b[96mself\u001b[39;49;00m._function_spec.arg_names[i])\n",
      "      \u001b[94mfor\u001b[39;49;00m (name, arg) \u001b[95min\u001b[39;49;00m kwargs.items():\n",
      "        \u001b[94mif\u001b[39;49;00m arg \u001b[95mis\u001b[39;49;00m _BOUND_VALUE \u001b[95mand\u001b[39;49;00m _contains_type_spec(kwarg_specs[name]):\n",
      "          missing_arguments.append(name)\n",
      "      \u001b[94mif\u001b[39;49;00m missing_arguments:\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mTypeError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mself\u001b[39;49;00m._structured_signature_summary()\u001b[33m}\u001b[39;49;00m\u001b[33m missing \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "                        \u001b[33m\"\u001b[39;49;00m\u001b[33mrequired arguments: \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "                        \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m, \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.join(\u001b[96msorted\u001b[39;49;00m(missing_arguments))\u001b[33m}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\u001b[1m\u001b[31mE       TypeError: signature_wrapper(*, examples) missing required arguments: examples.\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m:1707: TypeError\n",
      "\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\n",
      "self = <tensorflow_model_analysis.utils.model_util.ModelSignaturesDoFn object at 0x7f487515be50>\n",
      "batched_extract = {'features': {'dropoff_grid': array([[b'POINT(-87.6 41.9)'],\n",
      "       [b'POINT(-87.7 41.9)'],\n",
      "       [b'POINT(-87.7 41.9...0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0]]), 'transformed_features': None}\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m_batch_reducible_process\u001b[39;49;00m(\n",
      "        \u001b[96mself\u001b[39;49;00m, batched_extract: types.Extracts) -> List[types.Extracts]:\n",
      "    \n",
      "      \u001b[94mdef\u001b[39;49;00m \u001b[92mmaybe_expand_dims\u001b[39;49;00m(arr):\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96mhasattr\u001b[39;49;00m(arr, \u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[95mor\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m arr.shape:\n",
      "          \u001b[94mreturn\u001b[39;49;00m np.expand_dims(arr, axis=\u001b[94m0\u001b[39;49;00m)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "          \u001b[94mreturn\u001b[39;49;00m arr\n",
      "    \n",
      "      \u001b[94mdef\u001b[39;49;00m \u001b[92mto_dense\u001b[39;49;00m(t):\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(t, tf.SparseTensor):\n",
      "          \u001b[94mreturn\u001b[39;49;00m tf.sparse.to_dense(t)\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(t, tf.RaggedTensor):\n",
      "          \u001b[94mreturn\u001b[39;49;00m t.to_tensor()\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "          \u001b[94mreturn\u001b[39;49;00m t\n",
      "    \n",
      "      \u001b[94mdef\u001b[39;49;00m \u001b[92mcheck_shape\u001b[39;49;00m(t, batch_size, key=\u001b[94mNone\u001b[39;49;00m):\n",
      "        \u001b[94mif\u001b[39;49;00m t.shape[\u001b[94m0\u001b[39;49;00m] != batch_size:\n",
      "          \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\n",
      "              \u001b[33m'\u001b[39;49;00m\u001b[33mFirst dimension does not correspond with batch size. \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "              \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mBatch size: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mbatch_size\u001b[33m}\u001b[39;49;00m\u001b[33m, Dimensions: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mt.shape\u001b[33m}\u001b[39;49;00m\u001b[33m, Key: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mkey\u001b[33m}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \n",
      "      result = copy.copy(batched_extract)\n",
      "      batch_size = util.batch_size(batched_extract)\n",
      "      features = util.get_features_from_extracts(batched_extract)\n",
      "      serialized_examples = batched_extract[constants.INPUT_KEY]\n",
      "      \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(serialized_examples, np.ndarray):\n",
      "        \u001b[90m# Most models only accept serialized examples as a 1-d tensor\u001b[39;49;00m\n",
      "        serialized_examples = serialized_examples.flatten()\n",
      "      \u001b[94mfor\u001b[39;49;00m extracts_key \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._signature_names.keys():\n",
      "        \u001b[94mif\u001b[39;49;00m extracts_key \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m result:\n",
      "          result[extracts_key] = \u001b[94mNone\u001b[39;49;00m\n",
      "      \u001b[94mfor\u001b[39;49;00m model_name, model \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._loaded_models.items():\n",
      "        \u001b[94mfor\u001b[39;49;00m extracts_key, signature_names \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._signature_names.items():\n",
      "          \u001b[94mfor\u001b[39;49;00m signature_name \u001b[95min\u001b[39;49;00m (signature_names[model_name] \u001b[95mor\u001b[39;49;00m\n",
      "                                 \u001b[96mself\u001b[39;49;00m._default_signature_names):\n",
      "            signature = \u001b[94mNone\u001b[39;49;00m\n",
      "            input_specs = \u001b[94mNone\u001b[39;49;00m\n",
      "            inputs = \u001b[94mNone\u001b[39;49;00m\n",
      "            positional_inputs = \u001b[94mFalse\u001b[39;49;00m\n",
      "            required = \u001b[96mbool\u001b[39;49;00m(signature_names[model_name])\n",
      "            \u001b[94mif\u001b[39;49;00m signature_name \u001b[95mand\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33m@\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[95min\u001b[39;49;00m signature_name:\n",
      "              \u001b[94mtry\u001b[39;49;00m:\n",
      "                signature_name, input_names = get_preprocessing_signature(\n",
      "                    signature_name)\n",
      "                signature = \u001b[96mgetattr\u001b[39;49;00m(preprocessing_functions, signature_name)\n",
      "                input_specs = {\n",
      "                    input_name: type_spec \u001b[94mfor\u001b[39;49;00m input_name, type_spec \u001b[95min\u001b[39;49;00m \u001b[96mzip\u001b[39;49;00m(\n",
      "                        input_names, signature.input_signature)\n",
      "                }\n",
      "                inputs = get_inputs(features, input_specs)\n",
      "                positional_inputs = \u001b[94mTrue\u001b[39;49;00m\n",
      "              \u001b[94mexcept\u001b[39;49;00m \u001b[96mAttributeError\u001b[39;49;00m \u001b[94mas\u001b[39;49;00m e:\n",
      "                logging.warning(\n",
      "                    \u001b[33m\"\"\"Failed to get signature of %s or as TFMA\u001b[39;49;00m\n",
      "    \u001b[33m                preprocessing function. Trying in-graph preprocessing\u001b[39;49;00m\n",
      "    \u001b[33m                function.\"\"\"\u001b[39;49;00m, signature_name)\n",
      "    \n",
      "            \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m input_specs:\n",
      "              input_specs = get_input_specs(model, signature_name, required) \u001b[95mor\u001b[39;49;00m {}\n",
      "              \u001b[90m# If input_specs exist then try to filter the inputs by the input\u001b[39;49;00m\n",
      "              \u001b[90m# names (unlike estimators, keras does not accept unknown inputs).\u001b[39;49;00m\n",
      "              \u001b[94mif\u001b[39;49;00m input_specs:\n",
      "                inputs = get_inputs(features, input_specs)\n",
      "            \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m inputs:\n",
      "              \u001b[90m# Assume serialized examples\u001b[39;49;00m\n",
      "              \u001b[94massert\u001b[39;49;00m serialized_examples \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mRaw examples not found.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "              inputs = serialized_examples\n",
      "              \u001b[90m# If a signature name was not provided, default to using the serving\u001b[39;49;00m\n",
      "              \u001b[90m# signature since parsing normally will be done outside model.\u001b[39;49;00m\n",
      "              \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m signature_name:\n",
      "                signature_name = get_default_signature_name(model)\n",
      "    \n",
      "            signature = signature \u001b[95mor\u001b[39;49;00m get_callable(model, signature_name, required)\n",
      "            \u001b[94mif\u001b[39;49;00m signature \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\n",
      "              \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m required:\n",
      "                \u001b[94mcontinue\u001b[39;49;00m\n",
      "              \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mUnable to find \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m function needed to update \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m %\n",
      "                               (signature_name, extracts_key))\n",
      "            \u001b[94mtry\u001b[39;49;00m:\n",
      "              \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(inputs, \u001b[96mdict\u001b[39;49;00m):\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96mhasattr\u001b[39;49;00m(signature, \u001b[33m'\u001b[39;49;00m\u001b[33mstructured_input_signature\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\n",
      "                  outputs = signature(**inputs)\n",
      "                \u001b[94melif\u001b[39;49;00m positional_inputs:\n",
      "                  outputs = signature(*inputs.values())\n",
      "                \u001b[94melse\u001b[39;49;00m:\n",
      "                  outputs = signature(inputs)\n",
      "              \u001b[94melse\u001b[39;49;00m:\n",
      ">               outputs = signature(tf.constant(inputs, dtype=tf.string))\n",
      "\n",
      "\u001b[1m\u001b[31m../.local/lib/python3.7/site-packages/tensorflow_model_analysis/utils/model_util.py\u001b[0m:934: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <ConcreteFunction signature_wrapper(*, examples) at 0x7F4875969ED0>\n",
      "args = (<tf.Tensor: shape=(36,), dtype=string, numpy=\n",
      "array([b'\\n\\xcc\\x02\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x13\\..._miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xcc\\\\A\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07'],\n",
      "      dtype=object)>,)\n",
      "kwargs = {}\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__call__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, *args, **kwargs):\n",
      "      \u001b[33m\"\"\"Executes the wrapped function.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  ConcreteFunctions have two signatures:\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  * The signature of the original function wrapped by this ConcreteFunction.\u001b[39;49;00m\n",
      "    \u001b[33m  * A flat signature, where each argument accepts a single Tensor.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  The original function signature is generally preferred, but the flat input\u001b[39;49;00m\n",
      "    \u001b[33m  signature is supported for backward compatibility.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  ### Original Function Signature\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  When calling a ConcreteFunction with the signature of the original function,\u001b[39;49;00m\n",
      "    \u001b[33m  each argument must match the type or value that was used when the\u001b[39;49;00m\n",
      "    \u001b[33m  ConcreteFunction's graph was traced.  In particular:\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  * Tensor arguments (including CompositeTensors, such as RaggedTensor) must\u001b[39;49;00m\n",
      "    \u001b[33m    have matching `TypeSpec`s.\u001b[39;49;00m\n",
      "    \u001b[33m  * Non-Tensor arguments (such as booleans or ints) must have equal values.\u001b[39;49;00m\n",
      "    \u001b[33m  * Nested arguments (such as lists, tuples, or dictionaries) must have the\u001b[39;49;00m\n",
      "    \u001b[33m    same nesting structure; and each nested value must have a matching type\u001b[39;49;00m\n",
      "    \u001b[33m    or value.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  The default value for any arguments that were traced with non-Tensor values\u001b[39;49;00m\n",
      "    \u001b[33m  is the value that was used in the trace.  Arguments that were traced with\u001b[39;49;00m\n",
      "    \u001b[33m  tensor arguments do not have a default value (even if the original function\u001b[39;49;00m\n",
      "    \u001b[33m  had a default value for that argument).\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  ### Flat Signature\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  When calling a ConcreteFunction with the flat signature, the arguments\u001b[39;49;00m\n",
      "    \u001b[33m  correspond to the flattened component tensors of the arguments that were\u001b[39;49;00m\n",
      "    \u001b[33m  used to construct the ConcreteFunction.  Parameter names are assigned based\u001b[39;49;00m\n",
      "    \u001b[33m  on `TensorSpec.name` (when specified) or the original argument names (with\u001b[39;49;00m\n",
      "    \u001b[33m  suffixes automatically added for nested arguments or composite tensors with\u001b[39;49;00m\n",
      "    \u001b[33m  multiple components).\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Args:\u001b[39;49;00m\n",
      "    \u001b[33m    *args: Positional arguments to the concrete function.\u001b[39;49;00m\n",
      "    \u001b[33m    **kwargs: Keyword arguments to the concrete function.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Returns:\u001b[39;49;00m\n",
      "    \u001b[33m    The result of applying the TF function on the given Tensors.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Raises:\u001b[39;49;00m\n",
      "    \u001b[33m    AssertionError: If this `ConcreteFunction` was not created through\u001b[39;49;00m\n",
      "    \u001b[33m      `get_concrete_function`.\u001b[39;49;00m\n",
      "    \u001b[33m    TypeError: If the arguments do not match the function's signature.\u001b[39;49;00m\n",
      "    \u001b[33m  \"\"\"\u001b[39;49;00m\n",
      ">     \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._call_impl(args, kwargs)\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m:1601: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <ConcreteFunction signature_wrapper(*, examples) at 0x7F4875969ED0>\n",
      "args = (<tf.Tensor: shape=(36,), dtype=string, numpy=\n",
      "array([b'\\n\\xcc\\x02\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x13\\..._miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xcc\\\\A\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07'],\n",
      "      dtype=object)>,)\n",
      "kwargs = {}, cancellation_manager = None\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m_call_impl\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, args, kwargs, cancellation_manager=\u001b[94mNone\u001b[39;49;00m):\n",
      "      \u001b[33m\"\"\"See `__call__` for details.\"\"\"\u001b[39;49;00m\n",
      "      \u001b[94mwith\u001b[39;49;00m trace.Trace(\u001b[96mself\u001b[39;49;00m._func_graph.name, tf_function_call=\u001b[33m\"\u001b[39;49;00m\u001b[33mconcrete\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\n",
      "        \u001b[90m# Construct the list of input tensors: check if the structured signature\u001b[39;49;00m\n",
      "        \u001b[90m# applies first; and if not, then use the flat signature.\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._function_spec \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\n",
      "          \u001b[94mtry\u001b[39;49;00m:\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._call_with_structured_signature(args, kwargs,\n",
      "                                                        cancellation_manager)\n",
      "          \u001b[94mexcept\u001b[39;49;00m \u001b[96mTypeError\u001b[39;49;00m \u001b[94mas\u001b[39;49;00m structured_err:\n",
      "            \u001b[94mtry\u001b[39;49;00m:\n",
      "              \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._call_with_flat_signature(args, kwargs,\n",
      ">                                                   cancellation_manager)\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m:1615: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <ConcreteFunction signature_wrapper(*, examples) at 0x7F4875969ED0>\n",
      "args = [<tf.Tensor: shape=(36,), dtype=string, numpy=\n",
      "array([b'\\n\\xcc\\x02\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x13\\...p_miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xcc\\\\A\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07'],\n",
      "      dtype=object)>]\n",
      "kwargs = {}, cancellation_manager = None\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m_call_with_flat_signature\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, args, kwargs, cancellation_manager):\n",
      "      \u001b[33m\"\"\"Executes the wrapped function with the flat signature.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Args:\u001b[39;49;00m\n",
      "    \u001b[33m    args: Positional arguments to the concrete function.\u001b[39;49;00m\n",
      "    \u001b[33m    kwargs: Keyword arguments to the concrete function.\u001b[39;49;00m\n",
      "    \u001b[33m    cancellation_manager: A `CancellationManager` that can be used to cancel\u001b[39;49;00m\n",
      "    \u001b[33m      function invocation.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Returns:\u001b[39;49;00m\n",
      "    \u001b[33m    The result of applying the function on the Tensors/Variables contained in\u001b[39;49;00m\n",
      "    \u001b[33m    `args` and `kwargs`.\u001b[39;49;00m\n",
      "    \u001b[33m  Raises:\u001b[39;49;00m\n",
      "    \u001b[33m    TypeError: if `args` and `kwargs` do not match the flat signature of this\u001b[39;49;00m\n",
      "    \u001b[33m      `ConcreteFunction`.\u001b[39;49;00m\n",
      "    \u001b[33m  \"\"\"\u001b[39;49;00m\n",
      "      \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(args) > \u001b[96mself\u001b[39;49;00m._num_positional_args:\n",
      "        \u001b[94mraise\u001b[39;49;00m \u001b[96mTypeError\u001b[39;49;00m(\n",
      "            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mself\u001b[39;49;00m._flat_signature_summary()\u001b[33m}\u001b[39;49;00m\u001b[33m takes \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mself\u001b[39;49;00m._num_positional_args\u001b[33m}\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mpositional arguments, got \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mlen\u001b[39;49;00m(args)\u001b[33m}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "      args = \u001b[96mlist\u001b[39;49;00m(args)\n",
      "      kwargs = \u001b[96mdict\u001b[39;49;00m(kwargs)\n",
      "      \u001b[94mfor\u001b[39;49;00m keyword \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._arg_keywords[\u001b[96mlen\u001b[39;49;00m(args):]:\n",
      "        \u001b[94mtry\u001b[39;49;00m:\n",
      "          args.append(kwargs.pop(compat.as_str(keyword)))\n",
      "        \u001b[94mexcept\u001b[39;49;00m \u001b[96mKeyError\u001b[39;49;00m:\n",
      "          specified_keywords = (\n",
      "              \u001b[96mlist\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m._arg_keywords[:\u001b[96mlen\u001b[39;49;00m(args)]) + \u001b[96mlist\u001b[39;49;00m(kwargs.keys()))\n",
      "          missing_required_args = \u001b[96msorted\u001b[39;49;00m(\n",
      "              \u001b[96mset\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m._arg_keywords) - \u001b[96mset\u001b[39;49;00m(specified_keywords))\n",
      "          \u001b[94mraise\u001b[39;49;00m \u001b[96mTypeError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mself\u001b[39;49;00m._flat_signature_summary()\u001b[33m}\u001b[39;49;00m\u001b[33m missing required \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "                          \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33marguments: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m, \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.join(missing_required_args)\u001b[33m}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "      \u001b[94mif\u001b[39;49;00m kwargs:\n",
      "        positional_arg_keywords = \u001b[96mset\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m._arg_keywords[:\u001b[96mlen\u001b[39;49;00m(args)])\n",
      "        \u001b[94mfor\u001b[39;49;00m unused_key \u001b[95min\u001b[39;49;00m kwargs:\n",
      "          \u001b[94mif\u001b[39;49;00m unused_key \u001b[95min\u001b[39;49;00m positional_arg_keywords:\n",
      "            \u001b[94mraise\u001b[39;49;00m \u001b[96mTypeError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mself\u001b[39;49;00m._flat_signature_summary()\u001b[33m}\u001b[39;49;00m\u001b[33m got two values \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mfor \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00munused_key\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \u001b[94mraise\u001b[39;49;00m \u001b[96mTypeError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mself\u001b[39;49;00m._flat_signature_summary()\u001b[33m}\u001b[39;49;00m\u001b[33m got unexpected \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "                        \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mkeyword arguments: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m, \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.join(\u001b[96msorted\u001b[39;49;00m(kwargs))\u001b[33m}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "      \u001b[94mfor\u001b[39;49;00m i, arg \u001b[95min\u001b[39;49;00m \u001b[96menumerate\u001b[39;49;00m(args):\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(\n",
      "            arg, (ops.Tensor, resource_variable_ops.BaseResourceVariable)):\n",
      "          \u001b[94mraise\u001b[39;49;00m \u001b[96mTypeError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mself\u001b[39;49;00m._flat_signature_summary()\u001b[33m}\u001b[39;49;00m\u001b[33m: expected argument \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "                          \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m#\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mi\u001b[33m}\u001b[39;49;00m\u001b[33m(zero-based) to be a Tensor; \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "                          \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mgot \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mtype\u001b[39;49;00m(arg).\u001b[91m__name__\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m (\u001b[39;49;00m\u001b[33m{\u001b[39;49;00marg\u001b[33m}\u001b[39;49;00m\u001b[33m).\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      ">     \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._call_flat(args, \u001b[96mself\u001b[39;49;00m.captured_inputs, cancellation_manager)\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m:1668: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <ConcreteFunction signature_wrapper(*, examples) at 0x7F4875969ED0>\n",
      "args = [<tf.Tensor: shape=(36,), dtype=string, numpy=\n",
      "array([b'\\n\\xcc\\x02\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x13\\...p_miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xcc\\\\A\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07'],\n",
      "      dtype=object)>]\n",
      "captured_inputs = [<tf.Tensor: shape=(), dtype=resource, value=<Resource Tensor>>, <tf.Tensor: shape=(), dtype=resource, value=<Resource...hape=(), dtype=resource, value=<Resource Tensor>>, <tf.Tensor: shape=(), dtype=resource, value=<Resource Tensor>>, ...]\n",
      "cancellation_manager = None\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m_call_flat\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, args, captured_inputs, cancellation_manager=\u001b[94mNone\u001b[39;49;00m):\n",
      "    \n",
      "      \u001b[94mdef\u001b[39;49;00m \u001b[92mget_handle\u001b[39;49;00m(x):\n",
      "        \u001b[94mreturn\u001b[39;49;00m x.handle \u001b[94mif\u001b[39;49;00m distribute_utils.is_distributed_variable(x) \u001b[94melse\u001b[39;49;00m x\n",
      "    \n",
      "      \u001b[94mdef\u001b[39;49;00m \u001b[92mget_unused_handle\u001b[39;49;00m(x):\n",
      "        \u001b[94mreturn\u001b[39;49;00m _unused_handle() \u001b[94mif\u001b[39;49;00m distribute_utils.is_distributed_variable(x)   \\\n",
      "            \u001b[94melse\u001b[39;49;00m x\n",
      "    \n",
      "      \u001b[94mif\u001b[39;49;00m (ds_context.get_replica_context() \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[95mor\u001b[39;49;00m\n",
      "          values_util.is_saving_non_distributed()):\n",
      "        \u001b[90m# If we're in the replica context or are saving a non-distributed version\u001b[39;49;00m\n",
      "        \u001b[90m# of the model, we resolve the captured variables to the corresponding\u001b[39;49;00m\n",
      "        \u001b[90m# resource handle. In both situation we call var.handle, but it has\u001b[39;49;00m\n",
      "        \u001b[90m# different behavior. In the replica context, var.handle resolves the\u001b[39;49;00m\n",
      "        \u001b[90m# replica local variable handle if the variable is replicated. When saving\u001b[39;49;00m\n",
      "        \u001b[90m# a non-distributed version of the model, var.handle resolves to the\u001b[39;49;00m\n",
      "        \u001b[90m# primary variable handle, since we only save one copy of a replicated\u001b[39;49;00m\n",
      "        \u001b[90m# variable.\u001b[39;49;00m\n",
      "        captured_inputs = \u001b[96mlist\u001b[39;49;00m(\u001b[96mmap\u001b[39;49;00m(get_handle, captured_inputs))\n",
      "      \u001b[94melse\u001b[39;49;00m:  \u001b[90m# cross-replica context\u001b[39;49;00m\n",
      "        captured_inputs = \u001b[96mlist\u001b[39;49;00m(\u001b[96mmap\u001b[39;49;00m(get_unused_handle, captured_inputs))\n",
      "      \u001b[94mreturn\u001b[39;49;00m \u001b[96msuper\u001b[39;49;00m(_WrapperFunction, \u001b[96mself\u001b[39;49;00m)._call_flat(args, captured_inputs,\n",
      ">                                                     cancellation_manager)\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\u001b[0m:134: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <ConcreteFunction signature_wrapper(*, examples) at 0x7F4875969ED0>\n",
      "args = [<tf.Tensor: shape=(36,), dtype=string, numpy=\n",
      "array([b'\\n\\xcc\\x02\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x13\\...hape=(), dtype=resource, value=<Resource Tensor>>, <tf.Tensor: shape=(), dtype=resource, value=<Resource Tensor>>, ...]\n",
      "captured_inputs = [<tf.Tensor: shape=(), dtype=resource, value=<Resource Tensor>>, <tf.Tensor: shape=(), dtype=resource, value=<Resource...hape=(), dtype=resource, value=<Resource Tensor>>, <tf.Tensor: shape=(), dtype=resource, value=<Resource Tensor>>, ...]\n",
      "cancellation_manager = None\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m_call_flat\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, args, captured_inputs, cancellation_manager=\u001b[94mNone\u001b[39;49;00m):\n",
      "      \u001b[33m\"\"\"Executes the wrapped function.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Args:\u001b[39;49;00m\n",
      "    \u001b[33m    args: a list of Tensors or Variables. Arguments from the Python function\u001b[39;49;00m\n",
      "    \u001b[33m      should be filtered before calling this method: objects aside from\u001b[39;49;00m\n",
      "    \u001b[33m      Tensors, CompositeTensors, and Variables are ignored. Any\u001b[39;49;00m\n",
      "    \u001b[33m      CompositeTensors should be expanded before calling this method.\u001b[39;49;00m\n",
      "    \u001b[33m    captured_inputs: the captured inputs that are also part of the input args\u001b[39;49;00m\n",
      "    \u001b[33m      to the actual execution. By default, it should be self._captured_inputs.\u001b[39;49;00m\n",
      "    \u001b[33m    cancellation_manager: (Optional.) A `CancellationManager` that can be\u001b[39;49;00m\n",
      "    \u001b[33m      used to cancel function invocation.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Returns:\u001b[39;49;00m\n",
      "    \u001b[33m    The result of applying the TF function to `args`.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Raises:\u001b[39;49;00m\n",
      "    \u001b[33m    ValueError: If `args` contains anything other than Tensors or Variables.\u001b[39;49;00m\n",
      "    \u001b[33m  \"\"\"\u001b[39;49;00m\n",
      "      ctx = context.context()\n",
      "      executing_eagerly = ctx.executing_eagerly()\n",
      "    \n",
      "      \u001b[90m# Copy saveable status of function's graph to current FuncGraph.\u001b[39;49;00m\n",
      "      default_graph = ops.get_default_graph()\n",
      "      \u001b[94mif\u001b[39;49;00m default_graph.building_function \u001b[95mand\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._func_graph.saveable:\n",
      "        default_graph.mark_as_unsaveable(\u001b[96mself\u001b[39;49;00m._func_graph.saving_errors)\n",
      "    \n",
      "      \u001b[94mif\u001b[39;49;00m (tape.could_possibly_record() \u001b[95mor\u001b[39;49;00m\n",
      "          \u001b[96mhasattr\u001b[39;49;00m(default_graph, \u001b[33m\"\u001b[39;49;00m\u001b[33mwatch_variable\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)):\n",
      "        \u001b[94mfor\u001b[39;49;00m v \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._func_graph.variables:\n",
      "          resource_variable_ops.variable_accessed(v)\n",
      "    \n",
      "      tensor_inputs = []\n",
      "      variables_used = \u001b[96mset\u001b[39;49;00m([])\n",
      "      \u001b[94mfor\u001b[39;49;00m i, arg \u001b[95min\u001b[39;49;00m \u001b[96menumerate\u001b[39;49;00m(args):\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(arg, resource_variable_ops.BaseResourceVariable):\n",
      "          \u001b[90m# We can pass a variable more than once, and in this case we need to\u001b[39;49;00m\n",
      "          \u001b[90m# pass its handle only once.\u001b[39;49;00m\n",
      "          \u001b[94mif\u001b[39;49;00m \u001b[96mid\u001b[39;49;00m(arg.handle) \u001b[95min\u001b[39;49;00m variables_used:\n",
      "            \u001b[94mcontinue\u001b[39;49;00m\n",
      "          resource_variable_ops.variable_accessed(arg)\n",
      "          tensor_inputs.append(arg.handle)\n",
      "          variables_used.add(\u001b[96mid\u001b[39;49;00m(arg.handle))\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(arg, ops.Tensor):\n",
      "          tensor_inputs.append(arg)\n",
      "          \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m executing_eagerly:\n",
      "            \u001b[90m# If we're graph building, shape inference is on. We check for input\u001b[39;49;00m\n",
      "            \u001b[90m# compatibility up front to avoid hard to debug incompatibilities\u001b[39;49;00m\n",
      "            \u001b[90m# later.\u001b[39;49;00m\n",
      "            graph_input_shape = tensor_shape.TensorShape(\n",
      "                \u001b[96mself\u001b[39;49;00m._func_graph.inputs[i].shape)\n",
      "            \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m graph_input_shape.is_compatible_with(arg.shape):\n",
      "              \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._arg_keywords:\n",
      "                arg_name = \u001b[33m\"\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\u001b[96mself\u001b[39;49;00m._arg_keywords[i])\n",
      "              \u001b[94melse\u001b[39;49;00m:\n",
      "                arg_name = \u001b[33m\"\u001b[39;49;00m\u001b[33mwith index \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(i)\n",
      "              \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\n",
      "                  \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mThe argument \u001b[39;49;00m\u001b[33m{\u001b[39;49;00marg_name\u001b[33m}\u001b[39;49;00m\u001b[33m (value \u001b[39;49;00m\u001b[33m{\u001b[39;49;00marg\u001b[33m}\u001b[39;49;00m\u001b[33m) is not compatible with \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "                  \u001b[33m\"\u001b[39;49;00m\u001b[33mthe shape this function was traced with. Expected shape \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "                  \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mself\u001b[39;49;00m._func_graph.inputs[i].shape\u001b[33m}\u001b[39;49;00m\u001b[33m, but got shape \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "                  \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00marg.shape\u001b[33m}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mIf you called get_concrete_function, you may \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "                  \u001b[33m\"\u001b[39;49;00m\u001b[33mneed to pass a tf.TensorSpec(..., shape=...) with a less \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "                  \u001b[33m\"\u001b[39;49;00m\u001b[33mspecific shape, having None on axes which can vary.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "          \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mi\u001b[33m:\u001b[39;49;00m\u001b[33md\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m-th input \u001b[39;49;00m\u001b[33m{\u001b[39;49;00marg\u001b[33m}\u001b[39;49;00m\u001b[33m must be a Tensor, got \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "                           \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mtype\u001b[39;49;00m(arg)\u001b[33m}\u001b[39;49;00m\u001b[33m when calling \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mself\u001b[39;49;00m._func_graph.name\u001b[33m}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "      args = tensor_inputs + captured_inputs\n",
      "      possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n",
      "      \u001b[94mif\u001b[39;49;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n",
      "          \u001b[95mand\u001b[39;49;00m executing_eagerly):\n",
      "        \u001b[90m# No tape is watching; skip to running the function.\u001b[39;49;00m\n",
      "        \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._build_call_outputs(\u001b[96mself\u001b[39;49;00m._inference_function.call(\n",
      ">           ctx, args, cancellation_manager=cancellation_manager))\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m:1854: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <tensorflow.python.eager.function._EagerDefinedFunction object at 0x7f4875969f10>\n",
      "ctx = <tensorflow.python.eager.context.Context object at 0x7f48cca58390>\n",
      "args = [<tf.Tensor: shape=(36,), dtype=string, numpy=\n",
      "array([b'\\n\\xcc\\x02\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x13\\...hape=(), dtype=resource, value=<Resource Tensor>>, <tf.Tensor: shape=(), dtype=resource, value=<Resource Tensor>>, ...]\n",
      "cancellation_manager = None\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mcall\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, ctx, args, cancellation_manager=\u001b[94mNone\u001b[39;49;00m):\n",
      "      \u001b[33m\"\"\"Calls this function with `args` as inputs.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  `ConcreteFunction` execution respects device annotations only if the\u001b[39;49;00m\n",
      "    \u001b[33m  function won't be compiled with xla.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Args:\u001b[39;49;00m\n",
      "    \u001b[33m    ctx: a Context object\u001b[39;49;00m\n",
      "    \u001b[33m    args: a list of arguments to supply this function with.\u001b[39;49;00m\n",
      "    \u001b[33m    cancellation_manager: a `CancellationManager` object that can be used to\u001b[39;49;00m\n",
      "    \u001b[33m      cancel function execution.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Returns:\u001b[39;49;00m\n",
      "    \u001b[33m    The outputs of the function call.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Raises:\u001b[39;49;00m\n",
      "    \u001b[33m    ValueError: if the number of arguments is incorrect.\u001b[39;49;00m\n",
      "    \u001b[33m    FunctionAlreadyGarbageCollectedError: if the function is no longer\u001b[39;49;00m\n",
      "    \u001b[33m      available to be called because it has been garbage collected.\u001b[39;49;00m\n",
      "    \u001b[33m  \"\"\"\u001b[39;49;00m\n",
      "      \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(args) != \u001b[96mlen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.signature.input_arg):\n",
      "        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\n",
      "            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mSignature specifies \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mlen\u001b[39;49;00m(\u001b[96mlist\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.signature.input_arg))\u001b[33m}\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33marguments, got: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mlen\u001b[39;49;00m(args)\u001b[33m}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "      \u001b[90m# If the `ScopedTFFunction` (accessed via `_c_func`) has already been\u001b[39;49;00m\n",
      "      \u001b[90m# cleaned up as a part of garbage collection, this `_EagerDefinedFunction`\u001b[39;49;00m\n",
      "      \u001b[90m# should also be garbage and is likely being called as part of a `__del__`\u001b[39;49;00m\n",
      "      \u001b[90m# elsewhere. In that case, there's nothing we can do, so we raise an\u001b[39;49;00m\n",
      "      \u001b[90m# exception for the caller to handle.\u001b[39;49;00m\n",
      "      \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._c_func.has_been_garbage_collected:\n",
      "        \u001b[94mraise\u001b[39;49;00m FunctionAlreadyGarbageCollectedError(\u001b[96mself\u001b[39;49;00m.name)\n",
      "    \n",
      "      function_call_options = ctx.function_call_options\n",
      "      \u001b[94mif\u001b[39;49;00m function_call_options.config_proto_serialized \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\n",
      "        config = function_utils.get_disabled_rewriter_config()\n",
      "      \u001b[94melse\u001b[39;49;00m:\n",
      "        config = function_call_options.config_proto_serialized\n",
      "      executor_type = function_call_options.executor_type \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "    \n",
      "      executing_eagerly = ctx.executing_eagerly()\n",
      "      attrs = (\u001b[33m\"\u001b[39;49;00m\u001b[33mexecutor_type\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, executor_type, \u001b[33m\"\u001b[39;49;00m\u001b[33mconfig_proto\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, config)\n",
      "      \u001b[94mif\u001b[39;49;00m executing_eagerly:\n",
      "        \u001b[94mwith\u001b[39;49;00m _InterpolateFunctionError(\u001b[96mself\u001b[39;49;00m):\n",
      "          \u001b[94mif\u001b[39;49;00m cancellation_manager \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\n",
      "            outputs = execute.execute(\n",
      "                \u001b[96mstr\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.signature.name),\n",
      "                num_outputs=\u001b[96mself\u001b[39;49;00m._num_outputs,\n",
      "                inputs=args,\n",
      "                attrs=attrs,\n",
      ">               ctx=ctx)\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m:504: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "op_name = '__inference_signature_wrapper_16698', num_outputs = 1\n",
      "inputs = [<tf.Tensor: shape=(36,), dtype=string, numpy=\n",
      "array([b'\\n\\xcc\\x02\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x13\\...hape=(), dtype=resource, value=<Resource Tensor>>, <tf.Tensor: shape=(), dtype=resource, value=<Resource Tensor>>, ...]\n",
      "attrs = ('executor_type', '', 'config_proto', b'\\n\\x07\\n\\x03CPU\\x10\\x01\\n\\x07\\n\\x03GPU\\x10\\x002\\x02J\\x008\\x01\\x82\\x01\\x00')\n",
      "ctx = <tensorflow.python.eager.context.Context object at 0x7f48cca58390>\n",
      "name = None\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mquick_execute\u001b[39;49;00m(op_name, num_outputs, inputs, attrs, ctx, name=\u001b[94mNone\u001b[39;49;00m):\n",
      "      \u001b[33m\"\"\"Execute a TensorFlow operation.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Args:\u001b[39;49;00m\n",
      "    \u001b[33m    op_name: Name of the TensorFlow operation (see REGISTER_OP in C++ code) to\u001b[39;49;00m\n",
      "    \u001b[33m      execute.\u001b[39;49;00m\n",
      "    \u001b[33m    num_outputs: The number of outputs of the operation to fetch. (Explicitly\u001b[39;49;00m\n",
      "    \u001b[33m      provided instead of being inferred for performance reasons).\u001b[39;49;00m\n",
      "    \u001b[33m    inputs: A list of inputs to the operation. Each entry should be a Tensor, or\u001b[39;49;00m\n",
      "    \u001b[33m      a value which can be passed to the Tensor constructor to create one.\u001b[39;49;00m\n",
      "    \u001b[33m    attrs: A tuple with alternating string attr names and attr values for this\u001b[39;49;00m\n",
      "    \u001b[33m      operation.\u001b[39;49;00m\n",
      "    \u001b[33m    ctx: The value of context.context().\u001b[39;49;00m\n",
      "    \u001b[33m    name: Customized name for the operation.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Returns:\u001b[39;49;00m\n",
      "    \u001b[33m    List of output Tensor objects. The list is empty if there are no outputs\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Raises:\u001b[39;49;00m\n",
      "    \u001b[33m    An exception on error.\u001b[39;49;00m\n",
      "    \u001b[33m  \"\"\"\u001b[39;49;00m\n",
      "      device_name = ctx.device_name\n",
      "      \u001b[90m# pylint: disable=protected-access\u001b[39;49;00m\n",
      "      \u001b[94mtry\u001b[39;49;00m:\n",
      "        ctx.ensure_initialized()\n",
      "        tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      ">                                           inputs, attrs, num_outputs)\n",
      "\u001b[1m\u001b[31mE                                           tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                           \u001b[0m\n",
      "\u001b[1m\u001b[31mE                                           Detected at node 'model/payment_type_xf_onehot/Assert/Assert' defined at (most recent call last):\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/bin/pytest\", line 8, in <module>\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 sys.exit(console_main())\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/config/__init__.py\", line 187, in console_main\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 code = main()\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/config/__init__.py\", line 165, in main\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 config=config\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_hooks.py\", line 265, in __call__\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._hookexec(self.name, self.get_hookimpls(), kwargs, firstresult)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_manager.py\", line 80, in _hookexec\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_callers.py\", line 39, in _multicall\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 res = hook_impl.function(*args)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/main.py\", line 315, in pytest_cmdline_main\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return wrap_session(config, _main)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/main.py\", line 268, in wrap_session\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 session.exitstatus = doit(config, session) or 0\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/main.py\", line 322, in _main\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 config.hook.pytest_runtestloop(session=session)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_hooks.py\", line 265, in __call__\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._hookexec(self.name, self.get_hookimpls(), kwargs, firstresult)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_manager.py\", line 80, in _hookexec\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_callers.py\", line 39, in _multicall\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 res = hook_impl.function(*args)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/main.py\", line 347, in pytest_runtestloop\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 item.config.hook.pytest_runtest_protocol(item=item, nextitem=nextitem)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_hooks.py\", line 265, in __call__\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._hookexec(self.name, self.get_hookimpls(), kwargs, firstresult)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_manager.py\", line 80, in _hookexec\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_callers.py\", line 39, in _multicall\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 res = hook_impl.function(*args)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/runner.py\", line 111, in pytest_runtest_protocol\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 runtestprotocol(item, nextitem=nextitem)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/runner.py\", line 130, in runtestprotocol\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 reports.append(call_and_report(item, \"call\", log))\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/runner.py\", line 219, in call_and_report\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 call = call_runtest_hook(item, when, **kwds)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/runner.py\", line 259, in call_runtest_hook\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 lambda: ihook(item=item, **kwds), when=when, reraise=reraise\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/runner.py\", line 338, in from_call\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 result: Optional[TResult] = func()\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/runner.py\", line 259, in <lambda>\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 lambda: ihook(item=item, **kwds), when=when, reraise=reraise\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_hooks.py\", line 265, in __call__\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._hookexec(self.name, self.get_hookimpls(), kwargs, firstresult)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_manager.py\", line 80, in _hookexec\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_callers.py\", line 39, in _multicall\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 res = hook_impl.function(*args)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/runner.py\", line 166, in pytest_runtest_call\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 item.runtest()\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/python.py\", line 1761, in runtest\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 self.ihook.pytest_pyfunc_call(pyfuncitem=self)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_hooks.py\", line 265, in __call__\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._hookexec(self.name, self.get_hookimpls(), kwargs, firstresult)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_manager.py\", line 80, in _hookexec\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_callers.py\", line 39, in _multicall\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 res = hook_impl.function(*args)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/python.py\", line 192, in pytest_pyfunc_call\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 result = testfunction(**testargs)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/mlops-with-vertex-ai/src/tests/pipeline_deployment_tests.py\", line 85, in test_e2e_pipeline\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 runner.run(pipeline)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/.local/lib/python3.7/site-packages/tfx/orchestration/portable/tfx_runner.py\", line 124, in run\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self.run_with_ir(pipeline_pb, run_options=run_options_pb, **kwargs)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/.local/lib/python3.7/site-packages/tfx/orchestration/local/local_dag_runner.py\", line 109, in run_with_ir\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 component_launcher.launch()\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/.local/lib/python3.7/site-packages/tfx/orchestration/portable/launcher.py\", line 549, in launch\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 executor_output = self._run_executor(execution_info)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/.local/lib/python3.7/site-packages/tfx/orchestration/portable/launcher.py\", line 424, in _run_executor\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 executor_output = self._executor_operator.run_executor(execution_info)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/.local/lib/python3.7/site-packages/tfx/orchestration/portable/beam_executor_operator.py\", line 98, in run_executor\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return python_executor_operator.run_with_executor(execution_info, executor)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/.local/lib/python3.7/site-packages/tfx/orchestration/portable/python_executor_operator.py\", line 59, in run_with_executor\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 execution_info.exec_properties)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/.local/lib/python3.7/site-packages/tfx/components/evaluator/executor.py\", line 300, in Do\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 tensor_adapter_config=tensor_adapter_config)))\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pvalue.py\", line 137, in __or__\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self.pipeline.apply(ptransform, self)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pipeline.py\", line 652, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 transform.transform, pvalueish, label or transform.label)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pipeline.py\", line 662, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self.apply(transform, pvalueish)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pipeline.py\", line 708, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 pvalueish_result = self.runner.apply(transform, pvalueish, self._options)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/runners/runner.py\", line 185, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return m(transform, input, options)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/runners/runner.py\", line 215, in apply_PTransform\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return transform.expand(input)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/transforms/ptransform.py\", line 996, in expand\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._fn(pcoll, *args, **kwargs)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/.local/lib/python3.7/site-packages/tensorflow_model_analysis/api/model_eval_lib.py\", line 1163, in ExtractEvaluateAndWriteResults\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 | 'WriteResults' >> WriteResults(writers=writers))\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pvalue.py\", line 137, in __or__\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self.pipeline.apply(ptransform, self)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pipeline.py\", line 652, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 transform.transform, pvalueish, label or transform.label)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pipeline.py\", line 662, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self.apply(transform, pvalueish)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pipeline.py\", line 708, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 pvalueish_result = self.runner.apply(transform, pvalueish, self._options)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/runners/runner.py\", line 185, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return m(transform, input, options)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/runners/runner.py\", line 215, in apply_PTransform\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return transform.expand(input)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/transforms/ptransform.py\", line 996, in expand\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._fn(pcoll, *args, **kwargs)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/.local/lib/python3.7/site-packages/tensorflow_model_analysis/api/model_eval_lib.py\", line 870, in ExtractAndEvaluate\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 update(evaluation, extracts | v.stage_name >> v.ptransform)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pvalue.py\", line 137, in __or__\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self.pipeline.apply(ptransform, self)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pipeline.py\", line 652, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 transform.transform, pvalueish, label or transform.label)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pipeline.py\", line 662, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self.apply(transform, pvalueish)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pipeline.py\", line 708, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 pvalueish_result = self.runner.apply(transform, pvalueish, self._options)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/runners/runner.py\", line 185, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return m(transform, input, options)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/runners/runner.py\", line 215, in apply_PTransform\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return transform.expand(input)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/transforms/ptransform.py\", line 996, in expand\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._fn(pcoll, *args, **kwargs)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/.local/lib/python3.7/site-packages/tensorflow_model_analysis/evaluators/metrics_plots_and_validations_evaluator.py\", line 921, in _EvaluateMetricsPlotsAndValidations\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 random_seed_for_testing=random_seed_for_testing))\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pvalue.py\", line 137, in __or__\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self.pipeline.apply(ptransform, self)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pipeline.py\", line 652, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 transform.transform, pvalueish, label or transform.label)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pipeline.py\", line 662, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self.apply(transform, pvalueish)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pipeline.py\", line 708, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 pvalueish_result = self.runner.apply(transform, pvalueish, self._options)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/runners/runner.py\", line 185, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return m(transform, input, options)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/runners/runner.py\", line 215, in apply_PTransform\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return transform.expand(input)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/transforms/ptransform.py\", line 996, in expand\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._fn(pcoll, *args, **kwargs)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/.local/lib/python3.7/site-packages/tensorflow_model_analysis/evaluators/metrics_plots_and_validations_evaluator.py\", line 702, in _ComputeMetricsAndPlots\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 model_name, eval_shared_model.model_loader, eval_config))\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/.local/lib/python3.7/site-packages/tensorflow_model_analysis/evaluators/keras_util.py\", line 48, in metric_computations_using_keras_saved_model\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 model = model_loader.load()\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/.local/lib/python3.7/site-packages/tensorflow_model_analysis/types.py\", line 419, in load\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._shared_handle.acquire(construct_fn)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/utils/shared.py\", line 305, in acquire\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return _shared_map.acquire(self._key, constructor_fn, tag)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/utils/shared.py\", line 246, in acquire\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 result = control_block.acquire(constructor_fn, tag)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/utils/shared.py\", line 139, in acquire\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 result = constructor_fn()\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/.local/lib/python3.7/site-packages/tensorflow_model_analysis/utils/model_util.py\", line 606, in construct_fn\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 model = tf.keras.models.load_model(eval_saved_model_path)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return fn(*args, **kwargs)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/keras/saving/save.py\", line 207, in load_model\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return saved_model_load.load(filepath_str, compile, options)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/keras/saving/saved_model/load.py\", line 142, in load\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 path, nodes_to_load, options=options)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                           Node: 'model/payment_type_xf_onehot/Assert/Assert'\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                           assertion failed: [Input values must be in the range 0 <= values < num_tokens with num_tokens=6]\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                           \t [[{{node model/payment_type_xf_onehot/Assert/Assert}}]] [Op:__inference_signature_wrapper_16698]\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m:55: InvalidArgumentError\n",
      "\n",
      "\u001b[33mThe above exception was the direct cause of the following exception:\u001b[0m\n",
      "\n",
      "self = <tensorflow_model_analysis.utils.model_util.ModelSignaturesDoFn object at 0x7f487515be50>\n",
      "element = {'features': {'dropoff_grid': array([[b'POINT(-87.6 41.9)'],\n",
      "       [b'POINT(-87.7 41.9)'],\n",
      "       [b'POINT(-87.7 41.9...0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0]]), 'transformed_features': None}\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mprocess\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, element: types.Extracts) -> Sequence[types.Extracts]:\n",
      "      batch_size = util.batch_size(element)\n",
      "      \u001b[94mtry\u001b[39;49;00m:\n",
      ">       result = \u001b[96mself\u001b[39;49;00m._batch_reducible_process(element)\n",
      "\n",
      "\u001b[1m\u001b[31m../.local/lib/python3.7/site-packages/tensorflow_model_analysis/utils/model_util.py\u001b[0m:747: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <tensorflow_model_analysis.utils.model_util.ModelSignaturesDoFn object at 0x7f487515be50>\n",
      "batched_extract = {'features': {'dropoff_grid': array([[b'POINT(-87.6 41.9)'],\n",
      "       [b'POINT(-87.7 41.9)'],\n",
      "       [b'POINT(-87.7 41.9...0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0]]), 'transformed_features': None}\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m_batch_reducible_process\u001b[39;49;00m(\n",
      "        \u001b[96mself\u001b[39;49;00m, batched_extract: types.Extracts) -> List[types.Extracts]:\n",
      "    \n",
      "      \u001b[94mdef\u001b[39;49;00m \u001b[92mmaybe_expand_dims\u001b[39;49;00m(arr):\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96mhasattr\u001b[39;49;00m(arr, \u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[95mor\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m arr.shape:\n",
      "          \u001b[94mreturn\u001b[39;49;00m np.expand_dims(arr, axis=\u001b[94m0\u001b[39;49;00m)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "          \u001b[94mreturn\u001b[39;49;00m arr\n",
      "    \n",
      "      \u001b[94mdef\u001b[39;49;00m \u001b[92mto_dense\u001b[39;49;00m(t):\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(t, tf.SparseTensor):\n",
      "          \u001b[94mreturn\u001b[39;49;00m tf.sparse.to_dense(t)\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(t, tf.RaggedTensor):\n",
      "          \u001b[94mreturn\u001b[39;49;00m t.to_tensor()\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "          \u001b[94mreturn\u001b[39;49;00m t\n",
      "    \n",
      "      \u001b[94mdef\u001b[39;49;00m \u001b[92mcheck_shape\u001b[39;49;00m(t, batch_size, key=\u001b[94mNone\u001b[39;49;00m):\n",
      "        \u001b[94mif\u001b[39;49;00m t.shape[\u001b[94m0\u001b[39;49;00m] != batch_size:\n",
      "          \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\n",
      "              \u001b[33m'\u001b[39;49;00m\u001b[33mFirst dimension does not correspond with batch size. \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "              \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mBatch size: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mbatch_size\u001b[33m}\u001b[39;49;00m\u001b[33m, Dimensions: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mt.shape\u001b[33m}\u001b[39;49;00m\u001b[33m, Key: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mkey\u001b[33m}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \n",
      "      result = copy.copy(batched_extract)\n",
      "      batch_size = util.batch_size(batched_extract)\n",
      "      features = util.get_features_from_extracts(batched_extract)\n",
      "      serialized_examples = batched_extract[constants.INPUT_KEY]\n",
      "      \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(serialized_examples, np.ndarray):\n",
      "        \u001b[90m# Most models only accept serialized examples as a 1-d tensor\u001b[39;49;00m\n",
      "        serialized_examples = serialized_examples.flatten()\n",
      "      \u001b[94mfor\u001b[39;49;00m extracts_key \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._signature_names.keys():\n",
      "        \u001b[94mif\u001b[39;49;00m extracts_key \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m result:\n",
      "          result[extracts_key] = \u001b[94mNone\u001b[39;49;00m\n",
      "      \u001b[94mfor\u001b[39;49;00m model_name, model \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._loaded_models.items():\n",
      "        \u001b[94mfor\u001b[39;49;00m extracts_key, signature_names \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._signature_names.items():\n",
      "          \u001b[94mfor\u001b[39;49;00m signature_name \u001b[95min\u001b[39;49;00m (signature_names[model_name] \u001b[95mor\u001b[39;49;00m\n",
      "                                 \u001b[96mself\u001b[39;49;00m._default_signature_names):\n",
      "            signature = \u001b[94mNone\u001b[39;49;00m\n",
      "            input_specs = \u001b[94mNone\u001b[39;49;00m\n",
      "            inputs = \u001b[94mNone\u001b[39;49;00m\n",
      "            positional_inputs = \u001b[94mFalse\u001b[39;49;00m\n",
      "            required = \u001b[96mbool\u001b[39;49;00m(signature_names[model_name])\n",
      "            \u001b[94mif\u001b[39;49;00m signature_name \u001b[95mand\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33m@\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[95min\u001b[39;49;00m signature_name:\n",
      "              \u001b[94mtry\u001b[39;49;00m:\n",
      "                signature_name, input_names = get_preprocessing_signature(\n",
      "                    signature_name)\n",
      "                signature = \u001b[96mgetattr\u001b[39;49;00m(preprocessing_functions, signature_name)\n",
      "                input_specs = {\n",
      "                    input_name: type_spec \u001b[94mfor\u001b[39;49;00m input_name, type_spec \u001b[95min\u001b[39;49;00m \u001b[96mzip\u001b[39;49;00m(\n",
      "                        input_names, signature.input_signature)\n",
      "                }\n",
      "                inputs = get_inputs(features, input_specs)\n",
      "                positional_inputs = \u001b[94mTrue\u001b[39;49;00m\n",
      "              \u001b[94mexcept\u001b[39;49;00m \u001b[96mAttributeError\u001b[39;49;00m \u001b[94mas\u001b[39;49;00m e:\n",
      "                logging.warning(\n",
      "                    \u001b[33m\"\"\"Failed to get signature of %s or as TFMA\u001b[39;49;00m\n",
      "    \u001b[33m                preprocessing function. Trying in-graph preprocessing\u001b[39;49;00m\n",
      "    \u001b[33m                function.\"\"\"\u001b[39;49;00m, signature_name)\n",
      "    \n",
      "            \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m input_specs:\n",
      "              input_specs = get_input_specs(model, signature_name, required) \u001b[95mor\u001b[39;49;00m {}\n",
      "              \u001b[90m# If input_specs exist then try to filter the inputs by the input\u001b[39;49;00m\n",
      "              \u001b[90m# names (unlike estimators, keras does not accept unknown inputs).\u001b[39;49;00m\n",
      "              \u001b[94mif\u001b[39;49;00m input_specs:\n",
      "                inputs = get_inputs(features, input_specs)\n",
      "            \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m inputs:\n",
      "              \u001b[90m# Assume serialized examples\u001b[39;49;00m\n",
      "              \u001b[94massert\u001b[39;49;00m serialized_examples \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mRaw examples not found.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "              inputs = serialized_examples\n",
      "              \u001b[90m# If a signature name was not provided, default to using the serving\u001b[39;49;00m\n",
      "              \u001b[90m# signature since parsing normally will be done outside model.\u001b[39;49;00m\n",
      "              \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m signature_name:\n",
      "                signature_name = get_default_signature_name(model)\n",
      "    \n",
      "            signature = signature \u001b[95mor\u001b[39;49;00m get_callable(model, signature_name, required)\n",
      "            \u001b[94mif\u001b[39;49;00m signature \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\n",
      "              \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m required:\n",
      "                \u001b[94mcontinue\u001b[39;49;00m\n",
      "              \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mUnable to find \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m function needed to update \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m %\n",
      "                               (signature_name, extracts_key))\n",
      "            \u001b[94mtry\u001b[39;49;00m:\n",
      "              \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(inputs, \u001b[96mdict\u001b[39;49;00m):\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96mhasattr\u001b[39;49;00m(signature, \u001b[33m'\u001b[39;49;00m\u001b[33mstructured_input_signature\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\n",
      "                  outputs = signature(**inputs)\n",
      "                \u001b[94melif\u001b[39;49;00m positional_inputs:\n",
      "                  outputs = signature(*inputs.values())\n",
      "                \u001b[94melse\u001b[39;49;00m:\n",
      "                  outputs = signature(inputs)\n",
      "              \u001b[94melse\u001b[39;49;00m:\n",
      "                outputs = signature(tf.constant(inputs, dtype=tf.string))\n",
      "            \u001b[94mexcept\u001b[39;49;00m (\u001b[96mTypeError\u001b[39;49;00m, tf.errors.InvalidArgumentError) \u001b[94mas\u001b[39;49;00m e:\n",
      "              \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\n",
      "                  \u001b[33m\"\"\"Fail to call signature func with signature_name: {}.\u001b[39;49;00m\n",
      "    \u001b[33m              the inputs are:\\n {}.\u001b[39;49;00m\n",
      "    \u001b[33m              The input_specs are:\\n {}.\"\"\"\u001b[39;49;00m.format(signature_name, inputs,\n",
      ">                                                      input_specs)) \u001b[94mfrom\u001b[39;49;00m \u001b[04m\u001b[96me\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE             ValueError: Fail to call signature func with signature_name: serving_tf_example.\u001b[0m\n",
      "\u001b[1m\u001b[31mE                             the inputs are:\u001b[0m\n",
      "\u001b[1m\u001b[31mE              [b'\\n\\xcc\\x02\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa1\\x1d\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\xd4\\x1a\\x16E\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x85\\xeb\\xd1?\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x04'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xcc\\x02\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00@\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.7 41.9)\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\x94\\x05\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x8b\\xcclE\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x04\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xcc\\x02\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa4\\x03\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x04\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.7 41.9)POINT(-87.7 41.9)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xcc\\xcc>'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xcc\\x02\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.7)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x8b\\x9blE\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xb8\\x1e\\x15@\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x11\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xe2\\x03\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x05\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.7)POINT(-87.6 41.7)\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.7)'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xcc\\x02\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0f\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x05\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\n\\xd7#?\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xd6\\x01\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xc7\\x02\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 42)\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04333?\\n\\x1b\\n\\x0cpayment_type\\x12\\x0b\\n\\t\\n\\x07Dispute\\n/\\n\\tloc_cross\\x12\"\\n \\n\\x1ePOINT(-87.7 42)POINT(-87.7 42)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\xadN\\xcaD\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\"\\n\\x0bpickup_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 42)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa4\\x03'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xc6\\x02\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x1a\\n\\x0cpayment_type\\x12\\n\\n\\x08\\n\\x06Prcard\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa8\\x01\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0f\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n/\\n\\tloc_cross\\x12\"\\n \\n\\x1ePOINT(-87.7 42)POINT(-87.7 42)\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 42)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\"\\n\\x0bpickup_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 42)\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xcc\\x0c?'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xcb\\x02\\n\"\\n\\x0bpickup_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 42)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xa4pqA\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\x8a\\x12\\n\\x1f\\n\\x0cpayment_type\\x12\\x0f\\n\\r\\n\\x0bCredit Card\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\xab\\xa1F\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\n\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.9 42)\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n/\\n\\tloc_cross\\x12\"\\n \\n\\x1ePOINT(-87.7 42)POINT(-87.9 42)'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xc8\\x02\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\xdd7\\xc2F\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\x8d\\x0b\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04ff\\x8aA\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x06\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.9 42)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n1\\n\\tloc_cross\\x12$\\n\"\\n POINT(-87.6 41.9)POINT(-87.9 42)'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xcf\\x02\\n\\x1f\\n\\x0cpayment_type\\x12\\x0f\\n\\r\\n\\x0bCredit Card\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\x98\\x0c\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n1\\n\\tloc_cross\\x12$\\n\"\\n POINT(-87.7 41.9)POINT(-87.7 42)\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 42)\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x9a\\x99\\x19?\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\xf4\\xcf\\x1fF\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x12'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xc8\\x02\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xec\\t\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\xb6J\\x93F\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0b\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n1\\n\\tloc_cross\\x12$\\n\"\\n POINT(-87.7 41.9)POINT(-87.9 42)\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x9a\\x99AA\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.9 42)'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xcf\\x02\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xd1\\x12\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04_C\\xa9F\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\"\\n\\x0bpickup_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.9 42)\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0e\\n1\\n\\tloc_cross\\x12$\\n\"\\n POINT(-87.9 42)POINT(-87.6 41.9)\\n\\x1f\\n\\x0cpayment_type\\x12\\x0f\\n\\r\\n\\x0bCredit Card\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04{\\x14ZA\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xcf\\x02\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xb0\\t\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.8)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x1b\\n\\x0cpayment_type\\x12\\x0b\\n\\t\\n\\x07Unknown\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x17\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x0f-\\xf7E\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.8)\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.8)POINT(-87.7 41.8)\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xcc4A\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xcc\\x02\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.8)POINT(-87.7 41.9)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\x80\\x1e\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04@\\xf4\\x88E\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0c\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.8)\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00?\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xcc\\x02\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0c\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04}\\x13\\xbeE\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xe1\\x03\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xccl@'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xcc\\x02\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04ff\\xc6?\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04:\\xf14E\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa6\\x03\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0f\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xcc\\x02\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0e\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x9a\\x99\\x99?\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xf8\\x03\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xcc\\x02\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x8f\\xc25?\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xc5\\x02\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x14'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xcc\\x02\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\t\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x04\\x13(D\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xccL?\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xac\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xcc\\x02\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x1f\\x85k?\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\x9f\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\'\\xe4\\x8eD\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xcc\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04333?\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x16\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xf0\\x01\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xcc\\x02\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xf6(\\x1c?\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0f\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x1e\\x95RD\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa2\\x02\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xcc\\x02\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04fff?\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa4\\x03\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x15\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xcc\\x02\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xac\\x02\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xcc\\x8c?\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x06\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04:\\xf14E'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xcc\\x02\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xf0\\x01\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xcc\\xcc>\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xcb\\x02\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xecQ8>\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0c\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x15\\n\\x0ctrip_seconds\\x12\\x05\\x1a\\x03\\n\\x018'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xcc\\x02\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xe0\\x03\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x11\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x9a\\x99\\x99?'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xcc\\x02\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.7 41.9)\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\r\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04ff>A\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xc4\\x0e\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x8b\\xcclE\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xcc\\x02\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04ffv@\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x17\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xb0\\t\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.7 41.9)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x8b\\xcclE\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xcc\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x14\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xca\\x03\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x8b\\xcclE\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.7 41.9)POINT(-87.6 41.9)\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x9a\\x99\\xb9?\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xcc\\x02\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.7 41.9)POINT(-87.6 41.9)\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xb2\\x03\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x9c\\x9b\\xacD\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04H\\xe1z?'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xce\\x02\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xcc\\x05\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x8b\\xcclE\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x1a\\n\\x0cpayment_type\\x12\\n\\n\\x08\\n\\x06Mobile\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.7 41.9)POINT(-87.6 41.9)\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0f\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x8f\\xc25@'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xcc\\x02\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0e\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.7 41.9)POINT(-87.6 41.9)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04#\\xca\\xa5E\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xccL>\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\x94\\x05'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xd3\\x02\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.7 41.9)POINT(-87.6 41.9)\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00 @\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x8b\\xcclE\\n\\x1f\\n\\x0cpayment_type\\x12\\x0f\\n\\r\\n\\x0bCredit Card\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x12\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xf9\\x08\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xcc\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.7 41.9)POINT(-87.7 41.9)\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\x8c\\x06\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04^\\xde\\xc0E\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04ff\\xb6@\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x05'\u001b[0m\n",
      "\u001b[1m\u001b[31mE              b'\\n\\xcc\\x02\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x15\\x11PF\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.8)\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.8 41.8)\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.8 41.8)POINT(-87.6 41.8)\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0f\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\x90\\r\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xcc\\\\A\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07'].\u001b[0m\n",
      "\u001b[1m\u001b[31mE                             The input_specs are:\u001b[0m\n",
      "\u001b[1m\u001b[31mE              {'examples': TensorSpec(shape=(None,), dtype=tf.string, name='examples')}.\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m../.local/lib/python3.7/site-packages/tensorflow_model_analysis/utils/model_util.py\u001b[0m:940: ValueError\n",
      "\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\n",
      "self = <ConcreteFunction signature_wrapper(*, examples) at 0x7F4875969ED0>\n",
      "args = (<tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'\\n\\xc7\\x02\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 ...grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 42)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa4\\x03'],\n",
      "      dtype=object)>,)\n",
      "kwargs = {}, cancellation_manager = None\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m_call_impl\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, args, kwargs, cancellation_manager=\u001b[94mNone\u001b[39;49;00m):\n",
      "      \u001b[33m\"\"\"See `__call__` for details.\"\"\"\u001b[39;49;00m\n",
      "      \u001b[94mwith\u001b[39;49;00m trace.Trace(\u001b[96mself\u001b[39;49;00m._func_graph.name, tf_function_call=\u001b[33m\"\u001b[39;49;00m\u001b[33mconcrete\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\n",
      "        \u001b[90m# Construct the list of input tensors: check if the structured signature\u001b[39;49;00m\n",
      "        \u001b[90m# applies first; and if not, then use the flat signature.\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._function_spec \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\n",
      "          \u001b[94mtry\u001b[39;49;00m:\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._call_with_structured_signature(args, kwargs,\n",
      ">                                                       cancellation_manager)\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m:1611: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <ConcreteFunction signature_wrapper(*, examples) at 0x7F4875969ED0>\n",
      "args = (<tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'\\n\\xc7\\x02\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 ...grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 42)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa4\\x03'],\n",
      "      dtype=object)>,)\n",
      "kwargs = {'examples': <object object at 0x7f491141de40>}\n",
      "cancellation_manager = None\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m_call_with_structured_signature\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, args, kwargs, cancellation_manager):\n",
      "      \u001b[33m\"\"\"Executes the wrapped function with the structured signature.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Args:\u001b[39;49;00m\n",
      "    \u001b[33m    args: Positional arguments to the concrete function.\u001b[39;49;00m\n",
      "    \u001b[33m    kwargs: Keyword arguments to the concrete function.\u001b[39;49;00m\n",
      "    \u001b[33m    cancellation_manager: A `CancellationManager` that can be used to cancel\u001b[39;49;00m\n",
      "    \u001b[33m      function invocation.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Returns:\u001b[39;49;00m\n",
      "    \u001b[33m    The result of applying the function on the Tensors/Variables contained in\u001b[39;49;00m\n",
      "    \u001b[33m    `args` and `kwargs`.\u001b[39;49;00m\n",
      "    \u001b[33m  Raises:\u001b[39;49;00m\n",
      "    \u001b[33m    TypeError: if `args` and `kwargs` do not match the structured signature\u001b[39;49;00m\n",
      "    \u001b[33m      of this `ConcreteFunction`.\u001b[39;49;00m\n",
      "    \u001b[33m  \"\"\"\u001b[39;49;00m\n",
      "      args, kwargs, _, filtered_flat_args = \\\n",
      "          \u001b[96mself\u001b[39;49;00m._function_spec.canonicalize_function_inputs(*args, **kwargs)\n",
      ">     \u001b[96mself\u001b[39;49;00m._structured_signature_check_missing_args(args, kwargs)\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m:1688: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <ConcreteFunction signature_wrapper(*, examples) at 0x7F4875969ED0>\n",
      "args = (<tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'\\n\\xc7\\x02\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 ...grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 42)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa4\\x03'],\n",
      "      dtype=object)>,)\n",
      "kwargs = {'examples': <object object at 0x7f491141de40>}\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m_structured_signature_check_missing_args\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, args, kwargs):\n",
      "      \u001b[33m\"\"\"Raises a TypeError if any args are missing.\"\"\"\u001b[39;49;00m\n",
      "      arg_specs, kwarg_specs = \u001b[96mself\u001b[39;49;00m.structured_input_signature\n",
      "      missing_arguments = []\n",
      "      \u001b[94mfor\u001b[39;49;00m i, (arg, spec) \u001b[95min\u001b[39;49;00m \u001b[96menumerate\u001b[39;49;00m(\u001b[96mzip\u001b[39;49;00m(args, arg_specs)):\n",
      "        \u001b[94mif\u001b[39;49;00m arg \u001b[95mis\u001b[39;49;00m _BOUND_VALUE \u001b[95mand\u001b[39;49;00m _contains_type_spec(spec):\n",
      "          missing_arguments.append(\u001b[96mself\u001b[39;49;00m._function_spec.arg_names[i])\n",
      "      \u001b[94mfor\u001b[39;49;00m (name, arg) \u001b[95min\u001b[39;49;00m kwargs.items():\n",
      "        \u001b[94mif\u001b[39;49;00m arg \u001b[95mis\u001b[39;49;00m _BOUND_VALUE \u001b[95mand\u001b[39;49;00m _contains_type_spec(kwarg_specs[name]):\n",
      "          missing_arguments.append(name)\n",
      "      \u001b[94mif\u001b[39;49;00m missing_arguments:\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mTypeError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mself\u001b[39;49;00m._structured_signature_summary()\u001b[33m}\u001b[39;49;00m\u001b[33m missing \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "                        \u001b[33m\"\u001b[39;49;00m\u001b[33mrequired arguments: \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "                        \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m, \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.join(\u001b[96msorted\u001b[39;49;00m(missing_arguments))\u001b[33m}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\u001b[1m\u001b[31mE       TypeError: signature_wrapper(*, examples) missing required arguments: examples.\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m:1707: TypeError\n",
      "\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\n",
      "self = <tensorflow_model_analysis.utils.model_util.ModelSignaturesDoFn object at 0x7f487515be50>\n",
      "batched_extract = {'features': {'dropoff_grid': array([[b'POINT(-87.7 42)']], dtype=object), 'euclidean': array([[1618.4586]], dtype=flo...ip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa4\\x03']],\n",
      "      dtype=object), 'labels': array([[0]]), 'transformed_features': None}\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m_batch_reducible_process\u001b[39;49;00m(\n",
      "        \u001b[96mself\u001b[39;49;00m, batched_extract: types.Extracts) -> List[types.Extracts]:\n",
      "    \n",
      "      \u001b[94mdef\u001b[39;49;00m \u001b[92mmaybe_expand_dims\u001b[39;49;00m(arr):\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96mhasattr\u001b[39;49;00m(arr, \u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[95mor\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m arr.shape:\n",
      "          \u001b[94mreturn\u001b[39;49;00m np.expand_dims(arr, axis=\u001b[94m0\u001b[39;49;00m)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "          \u001b[94mreturn\u001b[39;49;00m arr\n",
      "    \n",
      "      \u001b[94mdef\u001b[39;49;00m \u001b[92mto_dense\u001b[39;49;00m(t):\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(t, tf.SparseTensor):\n",
      "          \u001b[94mreturn\u001b[39;49;00m tf.sparse.to_dense(t)\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(t, tf.RaggedTensor):\n",
      "          \u001b[94mreturn\u001b[39;49;00m t.to_tensor()\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "          \u001b[94mreturn\u001b[39;49;00m t\n",
      "    \n",
      "      \u001b[94mdef\u001b[39;49;00m \u001b[92mcheck_shape\u001b[39;49;00m(t, batch_size, key=\u001b[94mNone\u001b[39;49;00m):\n",
      "        \u001b[94mif\u001b[39;49;00m t.shape[\u001b[94m0\u001b[39;49;00m] != batch_size:\n",
      "          \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\n",
      "              \u001b[33m'\u001b[39;49;00m\u001b[33mFirst dimension does not correspond with batch size. \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "              \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mBatch size: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mbatch_size\u001b[33m}\u001b[39;49;00m\u001b[33m, Dimensions: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mt.shape\u001b[33m}\u001b[39;49;00m\u001b[33m, Key: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mkey\u001b[33m}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \n",
      "      result = copy.copy(batched_extract)\n",
      "      batch_size = util.batch_size(batched_extract)\n",
      "      features = util.get_features_from_extracts(batched_extract)\n",
      "      serialized_examples = batched_extract[constants.INPUT_KEY]\n",
      "      \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(serialized_examples, np.ndarray):\n",
      "        \u001b[90m# Most models only accept serialized examples as a 1-d tensor\u001b[39;49;00m\n",
      "        serialized_examples = serialized_examples.flatten()\n",
      "      \u001b[94mfor\u001b[39;49;00m extracts_key \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._signature_names.keys():\n",
      "        \u001b[94mif\u001b[39;49;00m extracts_key \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m result:\n",
      "          result[extracts_key] = \u001b[94mNone\u001b[39;49;00m\n",
      "      \u001b[94mfor\u001b[39;49;00m model_name, model \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._loaded_models.items():\n",
      "        \u001b[94mfor\u001b[39;49;00m extracts_key, signature_names \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._signature_names.items():\n",
      "          \u001b[94mfor\u001b[39;49;00m signature_name \u001b[95min\u001b[39;49;00m (signature_names[model_name] \u001b[95mor\u001b[39;49;00m\n",
      "                                 \u001b[96mself\u001b[39;49;00m._default_signature_names):\n",
      "            signature = \u001b[94mNone\u001b[39;49;00m\n",
      "            input_specs = \u001b[94mNone\u001b[39;49;00m\n",
      "            inputs = \u001b[94mNone\u001b[39;49;00m\n",
      "            positional_inputs = \u001b[94mFalse\u001b[39;49;00m\n",
      "            required = \u001b[96mbool\u001b[39;49;00m(signature_names[model_name])\n",
      "            \u001b[94mif\u001b[39;49;00m signature_name \u001b[95mand\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33m@\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[95min\u001b[39;49;00m signature_name:\n",
      "              \u001b[94mtry\u001b[39;49;00m:\n",
      "                signature_name, input_names = get_preprocessing_signature(\n",
      "                    signature_name)\n",
      "                signature = \u001b[96mgetattr\u001b[39;49;00m(preprocessing_functions, signature_name)\n",
      "                input_specs = {\n",
      "                    input_name: type_spec \u001b[94mfor\u001b[39;49;00m input_name, type_spec \u001b[95min\u001b[39;49;00m \u001b[96mzip\u001b[39;49;00m(\n",
      "                        input_names, signature.input_signature)\n",
      "                }\n",
      "                inputs = get_inputs(features, input_specs)\n",
      "                positional_inputs = \u001b[94mTrue\u001b[39;49;00m\n",
      "              \u001b[94mexcept\u001b[39;49;00m \u001b[96mAttributeError\u001b[39;49;00m \u001b[94mas\u001b[39;49;00m e:\n",
      "                logging.warning(\n",
      "                    \u001b[33m\"\"\"Failed to get signature of %s or as TFMA\u001b[39;49;00m\n",
      "    \u001b[33m                preprocessing function. Trying in-graph preprocessing\u001b[39;49;00m\n",
      "    \u001b[33m                function.\"\"\"\u001b[39;49;00m, signature_name)\n",
      "    \n",
      "            \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m input_specs:\n",
      "              input_specs = get_input_specs(model, signature_name, required) \u001b[95mor\u001b[39;49;00m {}\n",
      "              \u001b[90m# If input_specs exist then try to filter the inputs by the input\u001b[39;49;00m\n",
      "              \u001b[90m# names (unlike estimators, keras does not accept unknown inputs).\u001b[39;49;00m\n",
      "              \u001b[94mif\u001b[39;49;00m input_specs:\n",
      "                inputs = get_inputs(features, input_specs)\n",
      "            \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m inputs:\n",
      "              \u001b[90m# Assume serialized examples\u001b[39;49;00m\n",
      "              \u001b[94massert\u001b[39;49;00m serialized_examples \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mRaw examples not found.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "              inputs = serialized_examples\n",
      "              \u001b[90m# If a signature name was not provided, default to using the serving\u001b[39;49;00m\n",
      "              \u001b[90m# signature since parsing normally will be done outside model.\u001b[39;49;00m\n",
      "              \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m signature_name:\n",
      "                signature_name = get_default_signature_name(model)\n",
      "    \n",
      "            signature = signature \u001b[95mor\u001b[39;49;00m get_callable(model, signature_name, required)\n",
      "            \u001b[94mif\u001b[39;49;00m signature \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\n",
      "              \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m required:\n",
      "                \u001b[94mcontinue\u001b[39;49;00m\n",
      "              \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mUnable to find \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m function needed to update \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m %\n",
      "                               (signature_name, extracts_key))\n",
      "            \u001b[94mtry\u001b[39;49;00m:\n",
      "              \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(inputs, \u001b[96mdict\u001b[39;49;00m):\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96mhasattr\u001b[39;49;00m(signature, \u001b[33m'\u001b[39;49;00m\u001b[33mstructured_input_signature\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\n",
      "                  outputs = signature(**inputs)\n",
      "                \u001b[94melif\u001b[39;49;00m positional_inputs:\n",
      "                  outputs = signature(*inputs.values())\n",
      "                \u001b[94melse\u001b[39;49;00m:\n",
      "                  outputs = signature(inputs)\n",
      "              \u001b[94melse\u001b[39;49;00m:\n",
      ">               outputs = signature(tf.constant(inputs, dtype=tf.string))\n",
      "\n",
      "\u001b[1m\u001b[31m../.local/lib/python3.7/site-packages/tensorflow_model_analysis/utils/model_util.py\u001b[0m:934: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <ConcreteFunction signature_wrapper(*, examples) at 0x7F4875969ED0>\n",
      "args = (<tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'\\n\\xc7\\x02\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 ...grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 42)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa4\\x03'],\n",
      "      dtype=object)>,)\n",
      "kwargs = {}\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__call__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, *args, **kwargs):\n",
      "      \u001b[33m\"\"\"Executes the wrapped function.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  ConcreteFunctions have two signatures:\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  * The signature of the original function wrapped by this ConcreteFunction.\u001b[39;49;00m\n",
      "    \u001b[33m  * A flat signature, where each argument accepts a single Tensor.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  The original function signature is generally preferred, but the flat input\u001b[39;49;00m\n",
      "    \u001b[33m  signature is supported for backward compatibility.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  ### Original Function Signature\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  When calling a ConcreteFunction with the signature of the original function,\u001b[39;49;00m\n",
      "    \u001b[33m  each argument must match the type or value that was used when the\u001b[39;49;00m\n",
      "    \u001b[33m  ConcreteFunction's graph was traced.  In particular:\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  * Tensor arguments (including CompositeTensors, such as RaggedTensor) must\u001b[39;49;00m\n",
      "    \u001b[33m    have matching `TypeSpec`s.\u001b[39;49;00m\n",
      "    \u001b[33m  * Non-Tensor arguments (such as booleans or ints) must have equal values.\u001b[39;49;00m\n",
      "    \u001b[33m  * Nested arguments (such as lists, tuples, or dictionaries) must have the\u001b[39;49;00m\n",
      "    \u001b[33m    same nesting structure; and each nested value must have a matching type\u001b[39;49;00m\n",
      "    \u001b[33m    or value.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  The default value for any arguments that were traced with non-Tensor values\u001b[39;49;00m\n",
      "    \u001b[33m  is the value that was used in the trace.  Arguments that were traced with\u001b[39;49;00m\n",
      "    \u001b[33m  tensor arguments do not have a default value (even if the original function\u001b[39;49;00m\n",
      "    \u001b[33m  had a default value for that argument).\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  ### Flat Signature\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  When calling a ConcreteFunction with the flat signature, the arguments\u001b[39;49;00m\n",
      "    \u001b[33m  correspond to the flattened component tensors of the arguments that were\u001b[39;49;00m\n",
      "    \u001b[33m  used to construct the ConcreteFunction.  Parameter names are assigned based\u001b[39;49;00m\n",
      "    \u001b[33m  on `TensorSpec.name` (when specified) or the original argument names (with\u001b[39;49;00m\n",
      "    \u001b[33m  suffixes automatically added for nested arguments or composite tensors with\u001b[39;49;00m\n",
      "    \u001b[33m  multiple components).\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Args:\u001b[39;49;00m\n",
      "    \u001b[33m    *args: Positional arguments to the concrete function.\u001b[39;49;00m\n",
      "    \u001b[33m    **kwargs: Keyword arguments to the concrete function.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Returns:\u001b[39;49;00m\n",
      "    \u001b[33m    The result of applying the TF function on the given Tensors.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Raises:\u001b[39;49;00m\n",
      "    \u001b[33m    AssertionError: If this `ConcreteFunction` was not created through\u001b[39;49;00m\n",
      "    \u001b[33m      `get_concrete_function`.\u001b[39;49;00m\n",
      "    \u001b[33m    TypeError: If the arguments do not match the function's signature.\u001b[39;49;00m\n",
      "    \u001b[33m  \"\"\"\u001b[39;49;00m\n",
      ">     \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._call_impl(args, kwargs)\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m:1601: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <ConcreteFunction signature_wrapper(*, examples) at 0x7F4875969ED0>\n",
      "args = (<tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'\\n\\xc7\\x02\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 ...grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 42)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa4\\x03'],\n",
      "      dtype=object)>,)\n",
      "kwargs = {}, cancellation_manager = None\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m_call_impl\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, args, kwargs, cancellation_manager=\u001b[94mNone\u001b[39;49;00m):\n",
      "      \u001b[33m\"\"\"See `__call__` for details.\"\"\"\u001b[39;49;00m\n",
      "      \u001b[94mwith\u001b[39;49;00m trace.Trace(\u001b[96mself\u001b[39;49;00m._func_graph.name, tf_function_call=\u001b[33m\"\u001b[39;49;00m\u001b[33mconcrete\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\n",
      "        \u001b[90m# Construct the list of input tensors: check if the structured signature\u001b[39;49;00m\n",
      "        \u001b[90m# applies first; and if not, then use the flat signature.\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._function_spec \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\n",
      "          \u001b[94mtry\u001b[39;49;00m:\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._call_with_structured_signature(args, kwargs,\n",
      "                                                        cancellation_manager)\n",
      "          \u001b[94mexcept\u001b[39;49;00m \u001b[96mTypeError\u001b[39;49;00m \u001b[94mas\u001b[39;49;00m structured_err:\n",
      "            \u001b[94mtry\u001b[39;49;00m:\n",
      "              \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._call_with_flat_signature(args, kwargs,\n",
      ">                                                   cancellation_manager)\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m:1615: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <ConcreteFunction signature_wrapper(*, examples) at 0x7F4875969ED0>\n",
      "args = [<tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'\\n\\xc7\\x02\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 ..._grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 42)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa4\\x03'],\n",
      "      dtype=object)>]\n",
      "kwargs = {}, cancellation_manager = None\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m_call_with_flat_signature\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, args, kwargs, cancellation_manager):\n",
      "      \u001b[33m\"\"\"Executes the wrapped function with the flat signature.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Args:\u001b[39;49;00m\n",
      "    \u001b[33m    args: Positional arguments to the concrete function.\u001b[39;49;00m\n",
      "    \u001b[33m    kwargs: Keyword arguments to the concrete function.\u001b[39;49;00m\n",
      "    \u001b[33m    cancellation_manager: A `CancellationManager` that can be used to cancel\u001b[39;49;00m\n",
      "    \u001b[33m      function invocation.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Returns:\u001b[39;49;00m\n",
      "    \u001b[33m    The result of applying the function on the Tensors/Variables contained in\u001b[39;49;00m\n",
      "    \u001b[33m    `args` and `kwargs`.\u001b[39;49;00m\n",
      "    \u001b[33m  Raises:\u001b[39;49;00m\n",
      "    \u001b[33m    TypeError: if `args` and `kwargs` do not match the flat signature of this\u001b[39;49;00m\n",
      "    \u001b[33m      `ConcreteFunction`.\u001b[39;49;00m\n",
      "    \u001b[33m  \"\"\"\u001b[39;49;00m\n",
      "      \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(args) > \u001b[96mself\u001b[39;49;00m._num_positional_args:\n",
      "        \u001b[94mraise\u001b[39;49;00m \u001b[96mTypeError\u001b[39;49;00m(\n",
      "            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mself\u001b[39;49;00m._flat_signature_summary()\u001b[33m}\u001b[39;49;00m\u001b[33m takes \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mself\u001b[39;49;00m._num_positional_args\u001b[33m}\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mpositional arguments, got \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mlen\u001b[39;49;00m(args)\u001b[33m}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "      args = \u001b[96mlist\u001b[39;49;00m(args)\n",
      "      kwargs = \u001b[96mdict\u001b[39;49;00m(kwargs)\n",
      "      \u001b[94mfor\u001b[39;49;00m keyword \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._arg_keywords[\u001b[96mlen\u001b[39;49;00m(args):]:\n",
      "        \u001b[94mtry\u001b[39;49;00m:\n",
      "          args.append(kwargs.pop(compat.as_str(keyword)))\n",
      "        \u001b[94mexcept\u001b[39;49;00m \u001b[96mKeyError\u001b[39;49;00m:\n",
      "          specified_keywords = (\n",
      "              \u001b[96mlist\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m._arg_keywords[:\u001b[96mlen\u001b[39;49;00m(args)]) + \u001b[96mlist\u001b[39;49;00m(kwargs.keys()))\n",
      "          missing_required_args = \u001b[96msorted\u001b[39;49;00m(\n",
      "              \u001b[96mset\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m._arg_keywords) - \u001b[96mset\u001b[39;49;00m(specified_keywords))\n",
      "          \u001b[94mraise\u001b[39;49;00m \u001b[96mTypeError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mself\u001b[39;49;00m._flat_signature_summary()\u001b[33m}\u001b[39;49;00m\u001b[33m missing required \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "                          \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33marguments: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m, \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.join(missing_required_args)\u001b[33m}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "      \u001b[94mif\u001b[39;49;00m kwargs:\n",
      "        positional_arg_keywords = \u001b[96mset\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m._arg_keywords[:\u001b[96mlen\u001b[39;49;00m(args)])\n",
      "        \u001b[94mfor\u001b[39;49;00m unused_key \u001b[95min\u001b[39;49;00m kwargs:\n",
      "          \u001b[94mif\u001b[39;49;00m unused_key \u001b[95min\u001b[39;49;00m positional_arg_keywords:\n",
      "            \u001b[94mraise\u001b[39;49;00m \u001b[96mTypeError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mself\u001b[39;49;00m._flat_signature_summary()\u001b[33m}\u001b[39;49;00m\u001b[33m got two values \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mfor \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00munused_key\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \u001b[94mraise\u001b[39;49;00m \u001b[96mTypeError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mself\u001b[39;49;00m._flat_signature_summary()\u001b[33m}\u001b[39;49;00m\u001b[33m got unexpected \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "                        \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mkeyword arguments: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m, \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.join(\u001b[96msorted\u001b[39;49;00m(kwargs))\u001b[33m}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "      \u001b[94mfor\u001b[39;49;00m i, arg \u001b[95min\u001b[39;49;00m \u001b[96menumerate\u001b[39;49;00m(args):\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(\n",
      "            arg, (ops.Tensor, resource_variable_ops.BaseResourceVariable)):\n",
      "          \u001b[94mraise\u001b[39;49;00m \u001b[96mTypeError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mself\u001b[39;49;00m._flat_signature_summary()\u001b[33m}\u001b[39;49;00m\u001b[33m: expected argument \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "                          \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m#\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mi\u001b[33m}\u001b[39;49;00m\u001b[33m(zero-based) to be a Tensor; \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "                          \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mgot \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mtype\u001b[39;49;00m(arg).\u001b[91m__name__\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m (\u001b[39;49;00m\u001b[33m{\u001b[39;49;00marg\u001b[33m}\u001b[39;49;00m\u001b[33m).\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      ">     \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._call_flat(args, \u001b[96mself\u001b[39;49;00m.captured_inputs, cancellation_manager)\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m:1668: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <ConcreteFunction signature_wrapper(*, examples) at 0x7F4875969ED0>\n",
      "args = [<tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'\\n\\xc7\\x02\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 ..._grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 42)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa4\\x03'],\n",
      "      dtype=object)>]\n",
      "captured_inputs = [<tf.Tensor: shape=(), dtype=resource, value=<Resource Tensor>>, <tf.Tensor: shape=(), dtype=resource, value=<Resource...hape=(), dtype=resource, value=<Resource Tensor>>, <tf.Tensor: shape=(), dtype=resource, value=<Resource Tensor>>, ...]\n",
      "cancellation_manager = None\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m_call_flat\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, args, captured_inputs, cancellation_manager=\u001b[94mNone\u001b[39;49;00m):\n",
      "    \n",
      "      \u001b[94mdef\u001b[39;49;00m \u001b[92mget_handle\u001b[39;49;00m(x):\n",
      "        \u001b[94mreturn\u001b[39;49;00m x.handle \u001b[94mif\u001b[39;49;00m distribute_utils.is_distributed_variable(x) \u001b[94melse\u001b[39;49;00m x\n",
      "    \n",
      "      \u001b[94mdef\u001b[39;49;00m \u001b[92mget_unused_handle\u001b[39;49;00m(x):\n",
      "        \u001b[94mreturn\u001b[39;49;00m _unused_handle() \u001b[94mif\u001b[39;49;00m distribute_utils.is_distributed_variable(x)   \\\n",
      "            \u001b[94melse\u001b[39;49;00m x\n",
      "    \n",
      "      \u001b[94mif\u001b[39;49;00m (ds_context.get_replica_context() \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[95mor\u001b[39;49;00m\n",
      "          values_util.is_saving_non_distributed()):\n",
      "        \u001b[90m# If we're in the replica context or are saving a non-distributed version\u001b[39;49;00m\n",
      "        \u001b[90m# of the model, we resolve the captured variables to the corresponding\u001b[39;49;00m\n",
      "        \u001b[90m# resource handle. In both situation we call var.handle, but it has\u001b[39;49;00m\n",
      "        \u001b[90m# different behavior. In the replica context, var.handle resolves the\u001b[39;49;00m\n",
      "        \u001b[90m# replica local variable handle if the variable is replicated. When saving\u001b[39;49;00m\n",
      "        \u001b[90m# a non-distributed version of the model, var.handle resolves to the\u001b[39;49;00m\n",
      "        \u001b[90m# primary variable handle, since we only save one copy of a replicated\u001b[39;49;00m\n",
      "        \u001b[90m# variable.\u001b[39;49;00m\n",
      "        captured_inputs = \u001b[96mlist\u001b[39;49;00m(\u001b[96mmap\u001b[39;49;00m(get_handle, captured_inputs))\n",
      "      \u001b[94melse\u001b[39;49;00m:  \u001b[90m# cross-replica context\u001b[39;49;00m\n",
      "        captured_inputs = \u001b[96mlist\u001b[39;49;00m(\u001b[96mmap\u001b[39;49;00m(get_unused_handle, captured_inputs))\n",
      "      \u001b[94mreturn\u001b[39;49;00m \u001b[96msuper\u001b[39;49;00m(_WrapperFunction, \u001b[96mself\u001b[39;49;00m)._call_flat(args, captured_inputs,\n",
      ">                                                     cancellation_manager)\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\u001b[0m:134: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <ConcreteFunction signature_wrapper(*, examples) at 0x7F4875969ED0>\n",
      "args = [<tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'\\n\\xc7\\x02\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 ...hape=(), dtype=resource, value=<Resource Tensor>>, <tf.Tensor: shape=(), dtype=resource, value=<Resource Tensor>>, ...]\n",
      "captured_inputs = [<tf.Tensor: shape=(), dtype=resource, value=<Resource Tensor>>, <tf.Tensor: shape=(), dtype=resource, value=<Resource...hape=(), dtype=resource, value=<Resource Tensor>>, <tf.Tensor: shape=(), dtype=resource, value=<Resource Tensor>>, ...]\n",
      "cancellation_manager = None\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m_call_flat\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, args, captured_inputs, cancellation_manager=\u001b[94mNone\u001b[39;49;00m):\n",
      "      \u001b[33m\"\"\"Executes the wrapped function.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Args:\u001b[39;49;00m\n",
      "    \u001b[33m    args: a list of Tensors or Variables. Arguments from the Python function\u001b[39;49;00m\n",
      "    \u001b[33m      should be filtered before calling this method: objects aside from\u001b[39;49;00m\n",
      "    \u001b[33m      Tensors, CompositeTensors, and Variables are ignored. Any\u001b[39;49;00m\n",
      "    \u001b[33m      CompositeTensors should be expanded before calling this method.\u001b[39;49;00m\n",
      "    \u001b[33m    captured_inputs: the captured inputs that are also part of the input args\u001b[39;49;00m\n",
      "    \u001b[33m      to the actual execution. By default, it should be self._captured_inputs.\u001b[39;49;00m\n",
      "    \u001b[33m    cancellation_manager: (Optional.) A `CancellationManager` that can be\u001b[39;49;00m\n",
      "    \u001b[33m      used to cancel function invocation.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Returns:\u001b[39;49;00m\n",
      "    \u001b[33m    The result of applying the TF function to `args`.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Raises:\u001b[39;49;00m\n",
      "    \u001b[33m    ValueError: If `args` contains anything other than Tensors or Variables.\u001b[39;49;00m\n",
      "    \u001b[33m  \"\"\"\u001b[39;49;00m\n",
      "      ctx = context.context()\n",
      "      executing_eagerly = ctx.executing_eagerly()\n",
      "    \n",
      "      \u001b[90m# Copy saveable status of function's graph to current FuncGraph.\u001b[39;49;00m\n",
      "      default_graph = ops.get_default_graph()\n",
      "      \u001b[94mif\u001b[39;49;00m default_graph.building_function \u001b[95mand\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._func_graph.saveable:\n",
      "        default_graph.mark_as_unsaveable(\u001b[96mself\u001b[39;49;00m._func_graph.saving_errors)\n",
      "    \n",
      "      \u001b[94mif\u001b[39;49;00m (tape.could_possibly_record() \u001b[95mor\u001b[39;49;00m\n",
      "          \u001b[96mhasattr\u001b[39;49;00m(default_graph, \u001b[33m\"\u001b[39;49;00m\u001b[33mwatch_variable\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)):\n",
      "        \u001b[94mfor\u001b[39;49;00m v \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._func_graph.variables:\n",
      "          resource_variable_ops.variable_accessed(v)\n",
      "    \n",
      "      tensor_inputs = []\n",
      "      variables_used = \u001b[96mset\u001b[39;49;00m([])\n",
      "      \u001b[94mfor\u001b[39;49;00m i, arg \u001b[95min\u001b[39;49;00m \u001b[96menumerate\u001b[39;49;00m(args):\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(arg, resource_variable_ops.BaseResourceVariable):\n",
      "          \u001b[90m# We can pass a variable more than once, and in this case we need to\u001b[39;49;00m\n",
      "          \u001b[90m# pass its handle only once.\u001b[39;49;00m\n",
      "          \u001b[94mif\u001b[39;49;00m \u001b[96mid\u001b[39;49;00m(arg.handle) \u001b[95min\u001b[39;49;00m variables_used:\n",
      "            \u001b[94mcontinue\u001b[39;49;00m\n",
      "          resource_variable_ops.variable_accessed(arg)\n",
      "          tensor_inputs.append(arg.handle)\n",
      "          variables_used.add(\u001b[96mid\u001b[39;49;00m(arg.handle))\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(arg, ops.Tensor):\n",
      "          tensor_inputs.append(arg)\n",
      "          \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m executing_eagerly:\n",
      "            \u001b[90m# If we're graph building, shape inference is on. We check for input\u001b[39;49;00m\n",
      "            \u001b[90m# compatibility up front to avoid hard to debug incompatibilities\u001b[39;49;00m\n",
      "            \u001b[90m# later.\u001b[39;49;00m\n",
      "            graph_input_shape = tensor_shape.TensorShape(\n",
      "                \u001b[96mself\u001b[39;49;00m._func_graph.inputs[i].shape)\n",
      "            \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m graph_input_shape.is_compatible_with(arg.shape):\n",
      "              \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._arg_keywords:\n",
      "                arg_name = \u001b[33m\"\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\u001b[96mself\u001b[39;49;00m._arg_keywords[i])\n",
      "              \u001b[94melse\u001b[39;49;00m:\n",
      "                arg_name = \u001b[33m\"\u001b[39;49;00m\u001b[33mwith index \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(i)\n",
      "              \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\n",
      "                  \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mThe argument \u001b[39;49;00m\u001b[33m{\u001b[39;49;00marg_name\u001b[33m}\u001b[39;49;00m\u001b[33m (value \u001b[39;49;00m\u001b[33m{\u001b[39;49;00marg\u001b[33m}\u001b[39;49;00m\u001b[33m) is not compatible with \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "                  \u001b[33m\"\u001b[39;49;00m\u001b[33mthe shape this function was traced with. Expected shape \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "                  \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mself\u001b[39;49;00m._func_graph.inputs[i].shape\u001b[33m}\u001b[39;49;00m\u001b[33m, but got shape \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "                  \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00marg.shape\u001b[33m}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mIf you called get_concrete_function, you may \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "                  \u001b[33m\"\u001b[39;49;00m\u001b[33mneed to pass a tf.TensorSpec(..., shape=...) with a less \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "                  \u001b[33m\"\u001b[39;49;00m\u001b[33mspecific shape, having None on axes which can vary.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "          \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mi\u001b[33m:\u001b[39;49;00m\u001b[33md\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m-th input \u001b[39;49;00m\u001b[33m{\u001b[39;49;00marg\u001b[33m}\u001b[39;49;00m\u001b[33m must be a Tensor, got \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "                           \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mtype\u001b[39;49;00m(arg)\u001b[33m}\u001b[39;49;00m\u001b[33m when calling \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mself\u001b[39;49;00m._func_graph.name\u001b[33m}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "      args = tensor_inputs + captured_inputs\n",
      "      possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n",
      "      \u001b[94mif\u001b[39;49;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n",
      "          \u001b[95mand\u001b[39;49;00m executing_eagerly):\n",
      "        \u001b[90m# No tape is watching; skip to running the function.\u001b[39;49;00m\n",
      "        \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._build_call_outputs(\u001b[96mself\u001b[39;49;00m._inference_function.call(\n",
      ">           ctx, args, cancellation_manager=cancellation_manager))\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m:1854: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <tensorflow.python.eager.function._EagerDefinedFunction object at 0x7f4875969f10>\n",
      "ctx = <tensorflow.python.eager.context.Context object at 0x7f48cca58390>\n",
      "args = [<tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'\\n\\xc7\\x02\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 ...hape=(), dtype=resource, value=<Resource Tensor>>, <tf.Tensor: shape=(), dtype=resource, value=<Resource Tensor>>, ...]\n",
      "cancellation_manager = None\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mcall\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, ctx, args, cancellation_manager=\u001b[94mNone\u001b[39;49;00m):\n",
      "      \u001b[33m\"\"\"Calls this function with `args` as inputs.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  `ConcreteFunction` execution respects device annotations only if the\u001b[39;49;00m\n",
      "    \u001b[33m  function won't be compiled with xla.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Args:\u001b[39;49;00m\n",
      "    \u001b[33m    ctx: a Context object\u001b[39;49;00m\n",
      "    \u001b[33m    args: a list of arguments to supply this function with.\u001b[39;49;00m\n",
      "    \u001b[33m    cancellation_manager: a `CancellationManager` object that can be used to\u001b[39;49;00m\n",
      "    \u001b[33m      cancel function execution.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Returns:\u001b[39;49;00m\n",
      "    \u001b[33m    The outputs of the function call.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Raises:\u001b[39;49;00m\n",
      "    \u001b[33m    ValueError: if the number of arguments is incorrect.\u001b[39;49;00m\n",
      "    \u001b[33m    FunctionAlreadyGarbageCollectedError: if the function is no longer\u001b[39;49;00m\n",
      "    \u001b[33m      available to be called because it has been garbage collected.\u001b[39;49;00m\n",
      "    \u001b[33m  \"\"\"\u001b[39;49;00m\n",
      "      \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(args) != \u001b[96mlen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.signature.input_arg):\n",
      "        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\n",
      "            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mSignature specifies \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mlen\u001b[39;49;00m(\u001b[96mlist\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.signature.input_arg))\u001b[33m}\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33marguments, got: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mlen\u001b[39;49;00m(args)\u001b[33m}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "      \u001b[90m# If the `ScopedTFFunction` (accessed via `_c_func`) has already been\u001b[39;49;00m\n",
      "      \u001b[90m# cleaned up as a part of garbage collection, this `_EagerDefinedFunction`\u001b[39;49;00m\n",
      "      \u001b[90m# should also be garbage and is likely being called as part of a `__del__`\u001b[39;49;00m\n",
      "      \u001b[90m# elsewhere. In that case, there's nothing we can do, so we raise an\u001b[39;49;00m\n",
      "      \u001b[90m# exception for the caller to handle.\u001b[39;49;00m\n",
      "      \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._c_func.has_been_garbage_collected:\n",
      "        \u001b[94mraise\u001b[39;49;00m FunctionAlreadyGarbageCollectedError(\u001b[96mself\u001b[39;49;00m.name)\n",
      "    \n",
      "      function_call_options = ctx.function_call_options\n",
      "      \u001b[94mif\u001b[39;49;00m function_call_options.config_proto_serialized \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\n",
      "        config = function_utils.get_disabled_rewriter_config()\n",
      "      \u001b[94melse\u001b[39;49;00m:\n",
      "        config = function_call_options.config_proto_serialized\n",
      "      executor_type = function_call_options.executor_type \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "    \n",
      "      executing_eagerly = ctx.executing_eagerly()\n",
      "      attrs = (\u001b[33m\"\u001b[39;49;00m\u001b[33mexecutor_type\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, executor_type, \u001b[33m\"\u001b[39;49;00m\u001b[33mconfig_proto\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, config)\n",
      "      \u001b[94mif\u001b[39;49;00m executing_eagerly:\n",
      "        \u001b[94mwith\u001b[39;49;00m _InterpolateFunctionError(\u001b[96mself\u001b[39;49;00m):\n",
      "          \u001b[94mif\u001b[39;49;00m cancellation_manager \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\n",
      "            outputs = execute.execute(\n",
      "                \u001b[96mstr\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.signature.name),\n",
      "                num_outputs=\u001b[96mself\u001b[39;49;00m._num_outputs,\n",
      "                inputs=args,\n",
      "                attrs=attrs,\n",
      ">               ctx=ctx)\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m:504: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "op_name = '__inference_signature_wrapper_16698', num_outputs = 1\n",
      "inputs = [<tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'\\n\\xc7\\x02\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 ...hape=(), dtype=resource, value=<Resource Tensor>>, <tf.Tensor: shape=(), dtype=resource, value=<Resource Tensor>>, ...]\n",
      "attrs = ('executor_type', '', 'config_proto', b'\\n\\x07\\n\\x03CPU\\x10\\x01\\n\\x07\\n\\x03GPU\\x10\\x002\\x02J\\x008\\x01\\x82\\x01\\x00')\n",
      "ctx = <tensorflow.python.eager.context.Context object at 0x7f48cca58390>\n",
      "name = None\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mquick_execute\u001b[39;49;00m(op_name, num_outputs, inputs, attrs, ctx, name=\u001b[94mNone\u001b[39;49;00m):\n",
      "      \u001b[33m\"\"\"Execute a TensorFlow operation.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Args:\u001b[39;49;00m\n",
      "    \u001b[33m    op_name: Name of the TensorFlow operation (see REGISTER_OP in C++ code) to\u001b[39;49;00m\n",
      "    \u001b[33m      execute.\u001b[39;49;00m\n",
      "    \u001b[33m    num_outputs: The number of outputs of the operation to fetch. (Explicitly\u001b[39;49;00m\n",
      "    \u001b[33m      provided instead of being inferred for performance reasons).\u001b[39;49;00m\n",
      "    \u001b[33m    inputs: A list of inputs to the operation. Each entry should be a Tensor, or\u001b[39;49;00m\n",
      "    \u001b[33m      a value which can be passed to the Tensor constructor to create one.\u001b[39;49;00m\n",
      "    \u001b[33m    attrs: A tuple with alternating string attr names and attr values for this\u001b[39;49;00m\n",
      "    \u001b[33m      operation.\u001b[39;49;00m\n",
      "    \u001b[33m    ctx: The value of context.context().\u001b[39;49;00m\n",
      "    \u001b[33m    name: Customized name for the operation.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Returns:\u001b[39;49;00m\n",
      "    \u001b[33m    List of output Tensor objects. The list is empty if there are no outputs\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m  Raises:\u001b[39;49;00m\n",
      "    \u001b[33m    An exception on error.\u001b[39;49;00m\n",
      "    \u001b[33m  \"\"\"\u001b[39;49;00m\n",
      "      device_name = ctx.device_name\n",
      "      \u001b[90m# pylint: disable=protected-access\u001b[39;49;00m\n",
      "      \u001b[94mtry\u001b[39;49;00m:\n",
      "        ctx.ensure_initialized()\n",
      "        tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      ">                                           inputs, attrs, num_outputs)\n",
      "\u001b[1m\u001b[31mE                                           tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                           \u001b[0m\n",
      "\u001b[1m\u001b[31mE                                           Detected at node 'model/payment_type_xf_onehot/Assert/Assert' defined at (most recent call last):\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/bin/pytest\", line 8, in <module>\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 sys.exit(console_main())\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/config/__init__.py\", line 187, in console_main\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 code = main()\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/config/__init__.py\", line 165, in main\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 config=config\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_hooks.py\", line 265, in __call__\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._hookexec(self.name, self.get_hookimpls(), kwargs, firstresult)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_manager.py\", line 80, in _hookexec\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_callers.py\", line 39, in _multicall\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 res = hook_impl.function(*args)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/main.py\", line 315, in pytest_cmdline_main\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return wrap_session(config, _main)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/main.py\", line 268, in wrap_session\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 session.exitstatus = doit(config, session) or 0\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/main.py\", line 322, in _main\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 config.hook.pytest_runtestloop(session=session)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_hooks.py\", line 265, in __call__\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._hookexec(self.name, self.get_hookimpls(), kwargs, firstresult)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_manager.py\", line 80, in _hookexec\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_callers.py\", line 39, in _multicall\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 res = hook_impl.function(*args)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/main.py\", line 347, in pytest_runtestloop\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 item.config.hook.pytest_runtest_protocol(item=item, nextitem=nextitem)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_hooks.py\", line 265, in __call__\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._hookexec(self.name, self.get_hookimpls(), kwargs, firstresult)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_manager.py\", line 80, in _hookexec\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_callers.py\", line 39, in _multicall\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 res = hook_impl.function(*args)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/runner.py\", line 111, in pytest_runtest_protocol\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 runtestprotocol(item, nextitem=nextitem)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/runner.py\", line 130, in runtestprotocol\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 reports.append(call_and_report(item, \"call\", log))\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/runner.py\", line 219, in call_and_report\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 call = call_runtest_hook(item, when, **kwds)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/runner.py\", line 259, in call_runtest_hook\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 lambda: ihook(item=item, **kwds), when=when, reraise=reraise\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/runner.py\", line 338, in from_call\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 result: Optional[TResult] = func()\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/runner.py\", line 259, in <lambda>\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 lambda: ihook(item=item, **kwds), when=when, reraise=reraise\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_hooks.py\", line 265, in __call__\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._hookexec(self.name, self.get_hookimpls(), kwargs, firstresult)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_manager.py\", line 80, in _hookexec\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_callers.py\", line 39, in _multicall\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 res = hook_impl.function(*args)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/runner.py\", line 166, in pytest_runtest_call\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 item.runtest()\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/python.py\", line 1761, in runtest\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 self.ihook.pytest_pyfunc_call(pyfuncitem=self)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_hooks.py\", line 265, in __call__\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._hookexec(self.name, self.get_hookimpls(), kwargs, firstresult)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_manager.py\", line 80, in _hookexec\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/pluggy/_callers.py\", line 39, in _multicall\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 res = hook_impl.function(*args)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/_pytest/python.py\", line 192, in pytest_pyfunc_call\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 result = testfunction(**testargs)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/mlops-with-vertex-ai/src/tests/pipeline_deployment_tests.py\", line 85, in test_e2e_pipeline\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 runner.run(pipeline)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/.local/lib/python3.7/site-packages/tfx/orchestration/portable/tfx_runner.py\", line 124, in run\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self.run_with_ir(pipeline_pb, run_options=run_options_pb, **kwargs)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/.local/lib/python3.7/site-packages/tfx/orchestration/local/local_dag_runner.py\", line 109, in run_with_ir\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 component_launcher.launch()\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/.local/lib/python3.7/site-packages/tfx/orchestration/portable/launcher.py\", line 549, in launch\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 executor_output = self._run_executor(execution_info)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/.local/lib/python3.7/site-packages/tfx/orchestration/portable/launcher.py\", line 424, in _run_executor\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 executor_output = self._executor_operator.run_executor(execution_info)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/.local/lib/python3.7/site-packages/tfx/orchestration/portable/beam_executor_operator.py\", line 98, in run_executor\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return python_executor_operator.run_with_executor(execution_info, executor)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/.local/lib/python3.7/site-packages/tfx/orchestration/portable/python_executor_operator.py\", line 59, in run_with_executor\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 execution_info.exec_properties)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/.local/lib/python3.7/site-packages/tfx/components/evaluator/executor.py\", line 300, in Do\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 tensor_adapter_config=tensor_adapter_config)))\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pvalue.py\", line 137, in __or__\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self.pipeline.apply(ptransform, self)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pipeline.py\", line 652, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 transform.transform, pvalueish, label or transform.label)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pipeline.py\", line 662, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self.apply(transform, pvalueish)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pipeline.py\", line 708, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 pvalueish_result = self.runner.apply(transform, pvalueish, self._options)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/runners/runner.py\", line 185, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return m(transform, input, options)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/runners/runner.py\", line 215, in apply_PTransform\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return transform.expand(input)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/transforms/ptransform.py\", line 996, in expand\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._fn(pcoll, *args, **kwargs)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/.local/lib/python3.7/site-packages/tensorflow_model_analysis/api/model_eval_lib.py\", line 1163, in ExtractEvaluateAndWriteResults\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 | 'WriteResults' >> WriteResults(writers=writers))\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pvalue.py\", line 137, in __or__\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self.pipeline.apply(ptransform, self)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pipeline.py\", line 652, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 transform.transform, pvalueish, label or transform.label)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pipeline.py\", line 662, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self.apply(transform, pvalueish)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pipeline.py\", line 708, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 pvalueish_result = self.runner.apply(transform, pvalueish, self._options)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/runners/runner.py\", line 185, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return m(transform, input, options)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/runners/runner.py\", line 215, in apply_PTransform\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return transform.expand(input)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/transforms/ptransform.py\", line 996, in expand\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._fn(pcoll, *args, **kwargs)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/.local/lib/python3.7/site-packages/tensorflow_model_analysis/api/model_eval_lib.py\", line 870, in ExtractAndEvaluate\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 update(evaluation, extracts | v.stage_name >> v.ptransform)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pvalue.py\", line 137, in __or__\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self.pipeline.apply(ptransform, self)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pipeline.py\", line 652, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 transform.transform, pvalueish, label or transform.label)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pipeline.py\", line 662, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self.apply(transform, pvalueish)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pipeline.py\", line 708, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 pvalueish_result = self.runner.apply(transform, pvalueish, self._options)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/runners/runner.py\", line 185, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return m(transform, input, options)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/runners/runner.py\", line 215, in apply_PTransform\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return transform.expand(input)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/transforms/ptransform.py\", line 996, in expand\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._fn(pcoll, *args, **kwargs)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/.local/lib/python3.7/site-packages/tensorflow_model_analysis/evaluators/metrics_plots_and_validations_evaluator.py\", line 921, in _EvaluateMetricsPlotsAndValidations\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 random_seed_for_testing=random_seed_for_testing))\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pvalue.py\", line 137, in __or__\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self.pipeline.apply(ptransform, self)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pipeline.py\", line 652, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 transform.transform, pvalueish, label or transform.label)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pipeline.py\", line 662, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self.apply(transform, pvalueish)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/pipeline.py\", line 708, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 pvalueish_result = self.runner.apply(transform, pvalueish, self._options)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/runners/runner.py\", line 185, in apply\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return m(transform, input, options)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/runners/runner.py\", line 215, in apply_PTransform\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return transform.expand(input)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/transforms/ptransform.py\", line 996, in expand\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._fn(pcoll, *args, **kwargs)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/.local/lib/python3.7/site-packages/tensorflow_model_analysis/evaluators/metrics_plots_and_validations_evaluator.py\", line 702, in _ComputeMetricsAndPlots\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 model_name, eval_shared_model.model_loader, eval_config))\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/.local/lib/python3.7/site-packages/tensorflow_model_analysis/evaluators/keras_util.py\", line 48, in metric_computations_using_keras_saved_model\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 model = model_loader.load()\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/.local/lib/python3.7/site-packages/tensorflow_model_analysis/types.py\", line 419, in load\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return self._shared_handle.acquire(construct_fn)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/utils/shared.py\", line 305, in acquire\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return _shared_map.acquire(self._key, constructor_fn, tag)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/utils/shared.py\", line 246, in acquire\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 result = control_block.acquire(constructor_fn, tag)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/apache_beam/utils/shared.py\", line 139, in acquire\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 result = constructor_fn()\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/home/jupyter/.local/lib/python3.7/site-packages/tensorflow_model_analysis/utils/model_util.py\", line 606, in construct_fn\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 model = tf.keras.models.load_model(eval_saved_model_path)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return fn(*args, **kwargs)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/keras/saving/save.py\", line 207, in load_model\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 return saved_model_load.load(filepath_str, compile, options)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                               File \"/opt/conda/lib/python3.7/site-packages/keras/saving/saved_model/load.py\", line 142, in load\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                                 path, nodes_to_load, options=options)\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                           Node: 'model/payment_type_xf_onehot/Assert/Assert'\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                           assertion failed: [Input values must be in the range 0 <= values < num_tokens with num_tokens=6]\u001b[0m\n",
      "\u001b[1m\u001b[31mE                                           \t [[{{node model/payment_type_xf_onehot/Assert/Assert}}]] [Op:__inference_signature_wrapper_16698]\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m:55: InvalidArgumentError\n",
      "\n",
      "\u001b[33mThe above exception was the direct cause of the following exception:\u001b[0m\n",
      "\n",
      ">   \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1198: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ">   \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:537: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <tensorflow_model_analysis.utils.model_util.ModelSignaturesDoFn object at 0x7f487515be50>\n",
      "element = {'features': {'dropoff_grid': array([[b'POINT(-87.6 41.9)'],\n",
      "       [b'POINT(-87.7 41.9)'],\n",
      "       [b'POINT(-87.7 41.9...0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0]]), 'transformed_features': None}\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mprocess\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, element: types.Extracts) -> Sequence[types.Extracts]:\n",
      "      batch_size = util.batch_size(element)\n",
      "      \u001b[94mtry\u001b[39;49;00m:\n",
      "        result = \u001b[96mself\u001b[39;49;00m._batch_reducible_process(element)\n",
      "        \u001b[96mself\u001b[39;49;00m._batch_size.update(batch_size)\n",
      "        \u001b[96mself\u001b[39;49;00m._num_instances.inc(batch_size)\n",
      "        \u001b[94mreturn\u001b[39;49;00m result\n",
      "      \u001b[94mexcept\u001b[39;49;00m (\u001b[96mValueError\u001b[39;49;00m, tf.errors.InvalidArgumentError,\n",
      "              tf.errors.ResourceExhaustedError, \u001b[96mRuntimeError\u001b[39;49;00m) \u001b[94mas\u001b[39;49;00m e:\n",
      "        logging.warning(\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mLarge batch_size \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m failed with error \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m. \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mAttempting to run batch through serially. Note that this will \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33msignificantly affect the performance.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, batch_size, e)\n",
      "        \u001b[96mself\u001b[39;49;00m._batch_size_failed.update(batch_size)\n",
      "        result = []\n",
      "        \u001b[94mfor\u001b[39;49;00m unbatched_element \u001b[95min\u001b[39;49;00m util.split_extracts(\n",
      "            element, keep_batch_dim=\u001b[94mTrue\u001b[39;49;00m):\n",
      "          \u001b[96mself\u001b[39;49;00m._batch_size.update(\u001b[94m1\u001b[39;49;00m)\n",
      ">         result.extend(\u001b[96mself\u001b[39;49;00m._batch_reducible_process(unbatched_element))\n",
      "\n",
      "\u001b[1m\u001b[31m../.local/lib/python3.7/site-packages/tensorflow_model_analysis/utils/model_util.py\u001b[0m:762: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <tensorflow_model_analysis.utils.model_util.ModelSignaturesDoFn object at 0x7f487515be50>\n",
      "batched_extract = {'features': {'dropoff_grid': array([[b'POINT(-87.7 42)']], dtype=object), 'euclidean': array([[1618.4586]], dtype=flo...ip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa4\\x03']],\n",
      "      dtype=object), 'labels': array([[0]]), 'transformed_features': None}\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m_batch_reducible_process\u001b[39;49;00m(\n",
      "        \u001b[96mself\u001b[39;49;00m, batched_extract: types.Extracts) -> List[types.Extracts]:\n",
      "    \n",
      "      \u001b[94mdef\u001b[39;49;00m \u001b[92mmaybe_expand_dims\u001b[39;49;00m(arr):\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96mhasattr\u001b[39;49;00m(arr, \u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[95mor\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m arr.shape:\n",
      "          \u001b[94mreturn\u001b[39;49;00m np.expand_dims(arr, axis=\u001b[94m0\u001b[39;49;00m)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "          \u001b[94mreturn\u001b[39;49;00m arr\n",
      "    \n",
      "      \u001b[94mdef\u001b[39;49;00m \u001b[92mto_dense\u001b[39;49;00m(t):\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(t, tf.SparseTensor):\n",
      "          \u001b[94mreturn\u001b[39;49;00m tf.sparse.to_dense(t)\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(t, tf.RaggedTensor):\n",
      "          \u001b[94mreturn\u001b[39;49;00m t.to_tensor()\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "          \u001b[94mreturn\u001b[39;49;00m t\n",
      "    \n",
      "      \u001b[94mdef\u001b[39;49;00m \u001b[92mcheck_shape\u001b[39;49;00m(t, batch_size, key=\u001b[94mNone\u001b[39;49;00m):\n",
      "        \u001b[94mif\u001b[39;49;00m t.shape[\u001b[94m0\u001b[39;49;00m] != batch_size:\n",
      "          \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\n",
      "              \u001b[33m'\u001b[39;49;00m\u001b[33mFirst dimension does not correspond with batch size. \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "              \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mBatch size: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mbatch_size\u001b[33m}\u001b[39;49;00m\u001b[33m, Dimensions: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mt.shape\u001b[33m}\u001b[39;49;00m\u001b[33m, Key: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mkey\u001b[33m}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \n",
      "      result = copy.copy(batched_extract)\n",
      "      batch_size = util.batch_size(batched_extract)\n",
      "      features = util.get_features_from_extracts(batched_extract)\n",
      "      serialized_examples = batched_extract[constants.INPUT_KEY]\n",
      "      \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(serialized_examples, np.ndarray):\n",
      "        \u001b[90m# Most models only accept serialized examples as a 1-d tensor\u001b[39;49;00m\n",
      "        serialized_examples = serialized_examples.flatten()\n",
      "      \u001b[94mfor\u001b[39;49;00m extracts_key \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._signature_names.keys():\n",
      "        \u001b[94mif\u001b[39;49;00m extracts_key \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m result:\n",
      "          result[extracts_key] = \u001b[94mNone\u001b[39;49;00m\n",
      "      \u001b[94mfor\u001b[39;49;00m model_name, model \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._loaded_models.items():\n",
      "        \u001b[94mfor\u001b[39;49;00m extracts_key, signature_names \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._signature_names.items():\n",
      "          \u001b[94mfor\u001b[39;49;00m signature_name \u001b[95min\u001b[39;49;00m (signature_names[model_name] \u001b[95mor\u001b[39;49;00m\n",
      "                                 \u001b[96mself\u001b[39;49;00m._default_signature_names):\n",
      "            signature = \u001b[94mNone\u001b[39;49;00m\n",
      "            input_specs = \u001b[94mNone\u001b[39;49;00m\n",
      "            inputs = \u001b[94mNone\u001b[39;49;00m\n",
      "            positional_inputs = \u001b[94mFalse\u001b[39;49;00m\n",
      "            required = \u001b[96mbool\u001b[39;49;00m(signature_names[model_name])\n",
      "            \u001b[94mif\u001b[39;49;00m signature_name \u001b[95mand\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33m@\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[95min\u001b[39;49;00m signature_name:\n",
      "              \u001b[94mtry\u001b[39;49;00m:\n",
      "                signature_name, input_names = get_preprocessing_signature(\n",
      "                    signature_name)\n",
      "                signature = \u001b[96mgetattr\u001b[39;49;00m(preprocessing_functions, signature_name)\n",
      "                input_specs = {\n",
      "                    input_name: type_spec \u001b[94mfor\u001b[39;49;00m input_name, type_spec \u001b[95min\u001b[39;49;00m \u001b[96mzip\u001b[39;49;00m(\n",
      "                        input_names, signature.input_signature)\n",
      "                }\n",
      "                inputs = get_inputs(features, input_specs)\n",
      "                positional_inputs = \u001b[94mTrue\u001b[39;49;00m\n",
      "              \u001b[94mexcept\u001b[39;49;00m \u001b[96mAttributeError\u001b[39;49;00m \u001b[94mas\u001b[39;49;00m e:\n",
      "                logging.warning(\n",
      "                    \u001b[33m\"\"\"Failed to get signature of %s or as TFMA\u001b[39;49;00m\n",
      "    \u001b[33m                preprocessing function. Trying in-graph preprocessing\u001b[39;49;00m\n",
      "    \u001b[33m                function.\"\"\"\u001b[39;49;00m, signature_name)\n",
      "    \n",
      "            \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m input_specs:\n",
      "              input_specs = get_input_specs(model, signature_name, required) \u001b[95mor\u001b[39;49;00m {}\n",
      "              \u001b[90m# If input_specs exist then try to filter the inputs by the input\u001b[39;49;00m\n",
      "              \u001b[90m# names (unlike estimators, keras does not accept unknown inputs).\u001b[39;49;00m\n",
      "              \u001b[94mif\u001b[39;49;00m input_specs:\n",
      "                inputs = get_inputs(features, input_specs)\n",
      "            \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m inputs:\n",
      "              \u001b[90m# Assume serialized examples\u001b[39;49;00m\n",
      "              \u001b[94massert\u001b[39;49;00m serialized_examples \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mRaw examples not found.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "              inputs = serialized_examples\n",
      "              \u001b[90m# If a signature name was not provided, default to using the serving\u001b[39;49;00m\n",
      "              \u001b[90m# signature since parsing normally will be done outside model.\u001b[39;49;00m\n",
      "              \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m signature_name:\n",
      "                signature_name = get_default_signature_name(model)\n",
      "    \n",
      "            signature = signature \u001b[95mor\u001b[39;49;00m get_callable(model, signature_name, required)\n",
      "            \u001b[94mif\u001b[39;49;00m signature \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\n",
      "              \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m required:\n",
      "                \u001b[94mcontinue\u001b[39;49;00m\n",
      "              \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mUnable to find \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m function needed to update \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m %\n",
      "                               (signature_name, extracts_key))\n",
      "            \u001b[94mtry\u001b[39;49;00m:\n",
      "              \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(inputs, \u001b[96mdict\u001b[39;49;00m):\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96mhasattr\u001b[39;49;00m(signature, \u001b[33m'\u001b[39;49;00m\u001b[33mstructured_input_signature\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\n",
      "                  outputs = signature(**inputs)\n",
      "                \u001b[94melif\u001b[39;49;00m positional_inputs:\n",
      "                  outputs = signature(*inputs.values())\n",
      "                \u001b[94melse\u001b[39;49;00m:\n",
      "                  outputs = signature(inputs)\n",
      "              \u001b[94melse\u001b[39;49;00m:\n",
      "                outputs = signature(tf.constant(inputs, dtype=tf.string))\n",
      "            \u001b[94mexcept\u001b[39;49;00m (\u001b[96mTypeError\u001b[39;49;00m, tf.errors.InvalidArgumentError) \u001b[94mas\u001b[39;49;00m e:\n",
      "              \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\n",
      "                  \u001b[33m\"\"\"Fail to call signature func with signature_name: {}.\u001b[39;49;00m\n",
      "    \u001b[33m              the inputs are:\\n {}.\u001b[39;49;00m\n",
      "    \u001b[33m              The input_specs are:\\n {}.\"\"\"\u001b[39;49;00m.format(signature_name, inputs,\n",
      ">                                                      input_specs)) \u001b[94mfrom\u001b[39;49;00m \u001b[04m\u001b[96me\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE             ValueError: Fail to call signature func with signature_name: serving_tf_example.\u001b[0m\n",
      "\u001b[1m\u001b[31mE                             the inputs are:\u001b[0m\n",
      "\u001b[1m\u001b[31mE              [b'\\n\\xc7\\x02\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 42)\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04333?\\n\\x1b\\n\\x0cpayment_type\\x12\\x0b\\n\\t\\n\\x07Dispute\\n/\\n\\tloc_cross\\x12\"\\n \\n\\x1ePOINT(-87.7 42)POINT(-87.7 42)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\xadN\\xcaD\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\"\\n\\x0bpickup_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 42)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa4\\x03'].\u001b[0m\n",
      "\u001b[1m\u001b[31mE                             The input_specs are:\u001b[0m\n",
      "\u001b[1m\u001b[31mE              {'examples': TensorSpec(shape=(None,), dtype=tf.string, name='examples')}.\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m../.local/lib/python3.7/site-packages/tensorflow_model_analysis/utils/model_util.py\u001b[0m:940: ValueError\n",
      "\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_e2e_pipeline\u001b[39;49;00m():\n",
      "    \n",
      "        project = os.getenv(\u001b[33m\"\u001b[39;49;00m\u001b[33mPROJECT\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        region = os.getenv(\u001b[33m\"\u001b[39;49;00m\u001b[33mREGION\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        model_display_name = os.getenv(\u001b[33m\"\u001b[39;49;00m\u001b[33mMODEL_DISPLAY_NAME\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        dataset_display_name = os.getenv(\u001b[33m\"\u001b[39;49;00m\u001b[33mDATASET_DISPLAY_NAME\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        gcs_location = os.getenv(\u001b[33m\"\u001b[39;49;00m\u001b[33mGCS_LOCATION\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        model_registry = os.getenv(\u001b[33m\"\u001b[39;49;00m\u001b[33mMODEL_REGISTRY_URI\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        upload_model = os.getenv(\u001b[33m\"\u001b[39;49;00m\u001b[33mUPLOAD_MODEL\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94massert\u001b[39;49;00m project, \u001b[33m\"\u001b[39;49;00m\u001b[33mEnvironment variable PROJECT is None!\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m region, \u001b[33m\"\u001b[39;49;00m\u001b[33mEnvironment variable REGION is None!\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m dataset_display_name, \u001b[33m\"\u001b[39;49;00m\u001b[33mEnvironment variable DATASET_DISPLAY_NAME is None!\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m model_display_name, \u001b[33m\"\u001b[39;49;00m\u001b[33mEnvironment variable MODEL_DISPLAY_NAME is None!\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m gcs_location, \u001b[33m\"\u001b[39;49;00m\u001b[33mEnvironment variable GCS_LOCATION is None!\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m model_registry, \u001b[33m\"\u001b[39;49;00m\u001b[33mEnvironment variable MODEL_REGISTRY_URI is None!\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "    \n",
      "        logging.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mupload_model: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mupload_model\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \u001b[94mif\u001b[39;49;00m tf.io.gfile.exists(gcs_location):\n",
      "            tf.io.gfile.rmtree(gcs_location)\n",
      "        logging.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mPipeline e2e test artifacts stored in: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mgcs_location\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m tf.io.gfile.exists(MLMD_SQLLITE):\n",
      "            tf.io.gfile.remove(MLMD_SQLLITE)\n",
      "    \n",
      "        metadata_connection_config = metadata_store_pb2.ConnectionConfig()\n",
      "        metadata_connection_config.sqlite.filename_uri = MLMD_SQLLITE\n",
      "        metadata_connection_config.sqlite.connection_mode = \u001b[94m3\u001b[39;49;00m\n",
      "        logging.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mML metadata store is ready.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "        pipeline_root = os.path.join(\n",
      "            config.ARTIFACT_STORE_URI,\n",
      "            config.PIPELINE_NAME,\n",
      "        )\n",
      "    \n",
      "        runner = LocalDagRunner()\n",
      "    \n",
      "        pipeline = training_pipeline.create_pipeline(\n",
      "            pipeline_root=pipeline_root,\n",
      "            num_epochs=NUM_EPOCHS,\n",
      "            batch_size=BATCH_SIZE,\n",
      "            learning_rate=LEARNING_RATE,\n",
      "            hidden_units=HIDDEN_UNITS,\n",
      "            metadata_connection_config=metadata_connection_config,\n",
      "        )\n",
      "    \n",
      ">       runner.run(pipeline)\n",
      "\n",
      "\u001b[1m\u001b[31msrc/tests/pipeline_deployment_tests.py\u001b[0m:85: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31m../.local/lib/python3.7/site-packages/tfx/orchestration/portable/tfx_runner.py\u001b[0m:124: in run\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.run_with_ir(pipeline_pb, run_options=run_options_pb, **kwargs)\n",
      "\u001b[1m\u001b[31m../.local/lib/python3.7/site-packages/tfx/orchestration/local/local_dag_runner.py\u001b[0m:109: in run_with_ir\n",
      "    component_launcher.launch()\n",
      "\u001b[1m\u001b[31m../.local/lib/python3.7/site-packages/tfx/orchestration/portable/launcher.py\u001b[0m:549: in launch\n",
      "    executor_output = \u001b[96mself\u001b[39;49;00m._run_executor(execution_info)\n",
      "\u001b[1m\u001b[31m../.local/lib/python3.7/site-packages/tfx/orchestration/portable/launcher.py\u001b[0m:424: in _run_executor\n",
      "    executor_output = \u001b[96mself\u001b[39;49;00m._executor_operator.run_executor(execution_info)\n",
      "\u001b[1m\u001b[31m../.local/lib/python3.7/site-packages/tfx/orchestration/portable/beam_executor_operator.py\u001b[0m:98: in run_executor\n",
      "    \u001b[94mreturn\u001b[39;49;00m python_executor_operator.run_with_executor(execution_info, executor)\n",
      "\u001b[1m\u001b[31m../.local/lib/python3.7/site-packages/tfx/orchestration/portable/python_executor_operator.py\u001b[0m:59: in run_with_executor\n",
      "    execution_info.exec_properties)\n",
      "\u001b[1m\u001b[31m../.local/lib/python3.7/site-packages/tfx/components/evaluator/executor.py\u001b[0m:300: in Do\n",
      "    tensor_adapter_config=tensor_adapter_config)))\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/apache_beam/pipeline.py\u001b[0m:596: in __exit__\n",
      "    \u001b[96mself\u001b[39;49;00m.result = \u001b[96mself\u001b[39;49;00m.run()\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/apache_beam/pipeline.py\u001b[0m:573: in run\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.runner.run_pipeline(\u001b[96mself\u001b[39;49;00m, \u001b[96mself\u001b[39;49;00m._options)\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/direct/direct_runner.py\u001b[0m:131: in run_pipeline\n",
      "    \u001b[94mreturn\u001b[39;49;00m runner.run_pipeline(pipeline, options)\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m:200: in run_pipeline\n",
      "    pipeline.to_runner_api(default_environment=\u001b[96mself\u001b[39;49;00m._default_environment))\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m:208: in run_via_runner_api\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.run_stages(stage_context, stages)\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m:409: in run_stages\n",
      "    runner_execution_context, bundle_context_manager, bundle_input)\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m:742: in _execute_bundle\n",
      "    bundle_manager))\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m:966: in _run_bundle\n",
      "    data_input, data_output, input_timers, expected_timer_output)\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m:1275: in process_bundle\n",
      "    result_future = \u001b[96mself\u001b[39;49;00m._worker_handler.control_conn.push(process_bundle_req)\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/portability/fn_api_runner/worker_handlers.py\u001b[0m:378: in push\n",
      "    response = \u001b[96mself\u001b[39;49;00m.worker.do_instruction(request)\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py\u001b[0m:581: in do_instruction\n",
      "    \u001b[96mgetattr\u001b[39;49;00m(request, request_type), request.instruction_id)\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py\u001b[0m:618: in process_bundle\n",
      "    bundle_processor.process_bundle(instruction_id))\n",
      "\u001b[1m\u001b[31m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/worker/bundle_processor.py\u001b[0m:1001: in process_bundle\n",
      "    op.finish()\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:736: in apache_beam.runners.worker.operations.DoOperation.finish\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:738: in apache_beam.runners.worker.operations.DoOperation.finish\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:739: in apache_beam.runners.worker.operations.DoOperation.finish\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1253: in apache_beam.runners.common.DoFnRunner.finish\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1234: in apache_beam.runners.common.DoFnRunner._invoke_bundle_method\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1265: in apache_beam.runners.common.DoFnRunner._reraise_augmented\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1232: in apache_beam.runners.common.DoFnRunner._invoke_bundle_method\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:475: in apache_beam.runners.common.DoFnInvoker.invoke_finish_bundle\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:480: in apache_beam.runners.common.DoFnInvoker.invoke_finish_bundle\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1401: in apache_beam.runners.common._OutputProcessor.finish_bundle_outputs\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:215: in apache_beam.runners.worker.operations.SingletonConsumerSet.receive\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:707: in apache_beam.runners.worker.operations.DoOperation.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:708: in apache_beam.runners.worker.operations.DoOperation.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1200: in apache_beam.runners.common.DoFnRunner.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1265: in apache_beam.runners.common.DoFnRunner._reraise_augmented\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1198: in apache_beam.runners.common.DoFnRunner.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:536: in apache_beam.runners.common.SimpleInvoker.invoke_process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1361: in apache_beam.runners.common._OutputProcessor.process_outputs\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:215: in apache_beam.runners.worker.operations.SingletonConsumerSet.receive\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:707: in apache_beam.runners.worker.operations.DoOperation.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:708: in apache_beam.runners.worker.operations.DoOperation.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1200: in apache_beam.runners.common.DoFnRunner.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1265: in apache_beam.runners.common.DoFnRunner._reraise_augmented\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1198: in apache_beam.runners.common.DoFnRunner.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:536: in apache_beam.runners.common.SimpleInvoker.invoke_process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1361: in apache_beam.runners.common._OutputProcessor.process_outputs\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:215: in apache_beam.runners.worker.operations.SingletonConsumerSet.receive\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:1102: in apache_beam.runners.worker.operations.FlattenOperation.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:1105: in apache_beam.runners.worker.operations.FlattenOperation.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:348: in apache_beam.runners.worker.operations.Operation.output\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:215: in apache_beam.runners.worker.operations.SingletonConsumerSet.receive\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:707: in apache_beam.runners.worker.operations.DoOperation.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:708: in apache_beam.runners.worker.operations.DoOperation.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1200: in apache_beam.runners.common.DoFnRunner.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1265: in apache_beam.runners.common.DoFnRunner._reraise_augmented\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1198: in apache_beam.runners.common.DoFnRunner.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:536: in apache_beam.runners.common.SimpleInvoker.invoke_process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1361: in apache_beam.runners.common._OutputProcessor.process_outputs\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:152: in apache_beam.runners.worker.operations.ConsumerSet.receive\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:707: in apache_beam.runners.worker.operations.DoOperation.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:708: in apache_beam.runners.worker.operations.DoOperation.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1200: in apache_beam.runners.common.DoFnRunner.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1265: in apache_beam.runners.common.DoFnRunner._reraise_augmented\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1198: in apache_beam.runners.common.DoFnRunner.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:536: in apache_beam.runners.common.SimpleInvoker.invoke_process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1361: in apache_beam.runners.common._OutputProcessor.process_outputs\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:215: in apache_beam.runners.worker.operations.SingletonConsumerSet.receive\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:707: in apache_beam.runners.worker.operations.DoOperation.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:708: in apache_beam.runners.worker.operations.DoOperation.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1200: in apache_beam.runners.common.DoFnRunner.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1265: in apache_beam.runners.common.DoFnRunner._reraise_augmented\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1198: in apache_beam.runners.common.DoFnRunner.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:536: in apache_beam.runners.common.SimpleInvoker.invoke_process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1361: in apache_beam.runners.common._OutputProcessor.process_outputs\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:215: in apache_beam.runners.worker.operations.SingletonConsumerSet.receive\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:707: in apache_beam.runners.worker.operations.DoOperation.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:708: in apache_beam.runners.worker.operations.DoOperation.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1200: in apache_beam.runners.common.DoFnRunner.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1265: in apache_beam.runners.common.DoFnRunner._reraise_augmented\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1198: in apache_beam.runners.common.DoFnRunner.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:536: in apache_beam.runners.common.SimpleInvoker.invoke_process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1361: in apache_beam.runners.common._OutputProcessor.process_outputs\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:215: in apache_beam.runners.worker.operations.SingletonConsumerSet.receive\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:707: in apache_beam.runners.worker.operations.DoOperation.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:708: in apache_beam.runners.worker.operations.DoOperation.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1200: in apache_beam.runners.common.DoFnRunner.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1265: in apache_beam.runners.common.DoFnRunner._reraise_augmented\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1198: in apache_beam.runners.common.DoFnRunner.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:536: in apache_beam.runners.common.SimpleInvoker.invoke_process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1361: in apache_beam.runners.common._OutputProcessor.process_outputs\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:215: in apache_beam.runners.worker.operations.SingletonConsumerSet.receive\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:707: in apache_beam.runners.worker.operations.DoOperation.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/worker/operations.py\u001b[0m:708: in apache_beam.runners.worker.operations.DoOperation.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1200: in apache_beam.runners.common.DoFnRunner.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1281: in apache_beam.runners.common.DoFnRunner._reraise_augmented\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:1198: in apache_beam.runners.common.DoFnRunner.process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mapache_beam/runners/common.py\u001b[0m:537: in apache_beam.runners.common.SimpleInvoker.invoke_process\n",
      "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../.local/lib/python3.7/site-packages/tensorflow_model_analysis/utils/model_util.py\u001b[0m:762: in process\n",
      "    result.extend(\u001b[96mself\u001b[39;49;00m._batch_reducible_process(unbatched_element))\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <tensorflow_model_analysis.utils.model_util.ModelSignaturesDoFn object at 0x7f487515be50>\n",
      "batched_extract = {'features': {'dropoff_grid': array([[b'POINT(-87.7 42)']], dtype=object), 'euclidean': array([[1618.4586]], dtype=flo...ip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa4\\x03']],\n",
      "      dtype=object), 'labels': array([[0]]), 'transformed_features': None}\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m_batch_reducible_process\u001b[39;49;00m(\n",
      "        \u001b[96mself\u001b[39;49;00m, batched_extract: types.Extracts) -> List[types.Extracts]:\n",
      "    \n",
      "      \u001b[94mdef\u001b[39;49;00m \u001b[92mmaybe_expand_dims\u001b[39;49;00m(arr):\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96mhasattr\u001b[39;49;00m(arr, \u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[95mor\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m arr.shape:\n",
      "          \u001b[94mreturn\u001b[39;49;00m np.expand_dims(arr, axis=\u001b[94m0\u001b[39;49;00m)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "          \u001b[94mreturn\u001b[39;49;00m arr\n",
      "    \n",
      "      \u001b[94mdef\u001b[39;49;00m \u001b[92mto_dense\u001b[39;49;00m(t):\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(t, tf.SparseTensor):\n",
      "          \u001b[94mreturn\u001b[39;49;00m tf.sparse.to_dense(t)\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(t, tf.RaggedTensor):\n",
      "          \u001b[94mreturn\u001b[39;49;00m t.to_tensor()\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "          \u001b[94mreturn\u001b[39;49;00m t\n",
      "    \n",
      "      \u001b[94mdef\u001b[39;49;00m \u001b[92mcheck_shape\u001b[39;49;00m(t, batch_size, key=\u001b[94mNone\u001b[39;49;00m):\n",
      "        \u001b[94mif\u001b[39;49;00m t.shape[\u001b[94m0\u001b[39;49;00m] != batch_size:\n",
      "          \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\n",
      "              \u001b[33m'\u001b[39;49;00m\u001b[33mFirst dimension does not correspond with batch size. \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "              \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mBatch size: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mbatch_size\u001b[33m}\u001b[39;49;00m\u001b[33m, Dimensions: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mt.shape\u001b[33m}\u001b[39;49;00m\u001b[33m, Key: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mkey\u001b[33m}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \n",
      "      result = copy.copy(batched_extract)\n",
      "      batch_size = util.batch_size(batched_extract)\n",
      "      features = util.get_features_from_extracts(batched_extract)\n",
      "      serialized_examples = batched_extract[constants.INPUT_KEY]\n",
      "      \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(serialized_examples, np.ndarray):\n",
      "        \u001b[90m# Most models only accept serialized examples as a 1-d tensor\u001b[39;49;00m\n",
      "        serialized_examples = serialized_examples.flatten()\n",
      "      \u001b[94mfor\u001b[39;49;00m extracts_key \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._signature_names.keys():\n",
      "        \u001b[94mif\u001b[39;49;00m extracts_key \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m result:\n",
      "          result[extracts_key] = \u001b[94mNone\u001b[39;49;00m\n",
      "      \u001b[94mfor\u001b[39;49;00m model_name, model \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._loaded_models.items():\n",
      "        \u001b[94mfor\u001b[39;49;00m extracts_key, signature_names \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._signature_names.items():\n",
      "          \u001b[94mfor\u001b[39;49;00m signature_name \u001b[95min\u001b[39;49;00m (signature_names[model_name] \u001b[95mor\u001b[39;49;00m\n",
      "                                 \u001b[96mself\u001b[39;49;00m._default_signature_names):\n",
      "            signature = \u001b[94mNone\u001b[39;49;00m\n",
      "            input_specs = \u001b[94mNone\u001b[39;49;00m\n",
      "            inputs = \u001b[94mNone\u001b[39;49;00m\n",
      "            positional_inputs = \u001b[94mFalse\u001b[39;49;00m\n",
      "            required = \u001b[96mbool\u001b[39;49;00m(signature_names[model_name])\n",
      "            \u001b[94mif\u001b[39;49;00m signature_name \u001b[95mand\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33m@\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[95min\u001b[39;49;00m signature_name:\n",
      "              \u001b[94mtry\u001b[39;49;00m:\n",
      "                signature_name, input_names = get_preprocessing_signature(\n",
      "                    signature_name)\n",
      "                signature = \u001b[96mgetattr\u001b[39;49;00m(preprocessing_functions, signature_name)\n",
      "                input_specs = {\n",
      "                    input_name: type_spec \u001b[94mfor\u001b[39;49;00m input_name, type_spec \u001b[95min\u001b[39;49;00m \u001b[96mzip\u001b[39;49;00m(\n",
      "                        input_names, signature.input_signature)\n",
      "                }\n",
      "                inputs = get_inputs(features, input_specs)\n",
      "                positional_inputs = \u001b[94mTrue\u001b[39;49;00m\n",
      "              \u001b[94mexcept\u001b[39;49;00m \u001b[96mAttributeError\u001b[39;49;00m \u001b[94mas\u001b[39;49;00m e:\n",
      "                logging.warning(\n",
      "                    \u001b[33m\"\"\"Failed to get signature of %s or as TFMA\u001b[39;49;00m\n",
      "    \u001b[33m                preprocessing function. Trying in-graph preprocessing\u001b[39;49;00m\n",
      "    \u001b[33m                function.\"\"\"\u001b[39;49;00m, signature_name)\n",
      "    \n",
      "            \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m input_specs:\n",
      "              input_specs = get_input_specs(model, signature_name, required) \u001b[95mor\u001b[39;49;00m {}\n",
      "              \u001b[90m# If input_specs exist then try to filter the inputs by the input\u001b[39;49;00m\n",
      "              \u001b[90m# names (unlike estimators, keras does not accept unknown inputs).\u001b[39;49;00m\n",
      "              \u001b[94mif\u001b[39;49;00m input_specs:\n",
      "                inputs = get_inputs(features, input_specs)\n",
      "            \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m inputs:\n",
      "              \u001b[90m# Assume serialized examples\u001b[39;49;00m\n",
      "              \u001b[94massert\u001b[39;49;00m serialized_examples \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mRaw examples not found.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "              inputs = serialized_examples\n",
      "              \u001b[90m# If a signature name was not provided, default to using the serving\u001b[39;49;00m\n",
      "              \u001b[90m# signature since parsing normally will be done outside model.\u001b[39;49;00m\n",
      "              \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m signature_name:\n",
      "                signature_name = get_default_signature_name(model)\n",
      "    \n",
      "            signature = signature \u001b[95mor\u001b[39;49;00m get_callable(model, signature_name, required)\n",
      "            \u001b[94mif\u001b[39;49;00m signature \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\n",
      "              \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m required:\n",
      "                \u001b[94mcontinue\u001b[39;49;00m\n",
      "              \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mUnable to find \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m function needed to update \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m %\n",
      "                               (signature_name, extracts_key))\n",
      "            \u001b[94mtry\u001b[39;49;00m:\n",
      "              \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(inputs, \u001b[96mdict\u001b[39;49;00m):\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96mhasattr\u001b[39;49;00m(signature, \u001b[33m'\u001b[39;49;00m\u001b[33mstructured_input_signature\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\n",
      "                  outputs = signature(**inputs)\n",
      "                \u001b[94melif\u001b[39;49;00m positional_inputs:\n",
      "                  outputs = signature(*inputs.values())\n",
      "                \u001b[94melse\u001b[39;49;00m:\n",
      "                  outputs = signature(inputs)\n",
      "              \u001b[94melse\u001b[39;49;00m:\n",
      "                outputs = signature(tf.constant(inputs, dtype=tf.string))\n",
      "            \u001b[94mexcept\u001b[39;49;00m (\u001b[96mTypeError\u001b[39;49;00m, tf.errors.InvalidArgumentError) \u001b[94mas\u001b[39;49;00m e:\n",
      "              \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\n",
      "                  \u001b[33m\"\"\"Fail to call signature func with signature_name: {}.\u001b[39;49;00m\n",
      "    \u001b[33m              the inputs are:\\n {}.\u001b[39;49;00m\n",
      "    \u001b[33m              The input_specs are:\\n {}.\"\"\"\u001b[39;49;00m.format(signature_name, inputs,\n",
      ">                                                      input_specs)) \u001b[94mfrom\u001b[39;49;00m \u001b[04m\u001b[96me\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE             ValueError: Fail to call signature func with signature_name: serving_tf_example.\u001b[0m\n",
      "\u001b[1m\u001b[31mE                             the inputs are:\u001b[0m\n",
      "\u001b[1m\u001b[31mE              [b'\\n\\xc7\\x02\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 42)\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04333?\\n\\x1b\\n\\x0cpayment_type\\x12\\x0b\\n\\t\\n\\x07Dispute\\n/\\n\\tloc_cross\\x12\"\\n \\n\\x1ePOINT(-87.7 42)POINT(-87.7 42)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\xadN\\xcaD\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\"\\n\\x0bpickup_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 42)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa4\\x03'].\u001b[0m\n",
      "\u001b[1m\u001b[31mE                             The input_specs are:\u001b[0m\n",
      "\u001b[1m\u001b[31mE              {'examples': TensorSpec(shape=(None,), dtype=tf.string, name='examples')}. [while running 'ExtractEvaluateAndWriteResults/ExtractAndEvaluate/ExtractPredictions/Predict']\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m../.local/lib/python3.7/site-packages/tensorflow_model_analysis/utils/model_util.py\u001b[0m:940: ValueError\n",
      "------------------------------ Captured log call -------------------------------\n",
      "\u001b[32mINFO    \u001b[0m root:pipeline_deployment_tests.py:56 upload_model: 0\n",
      "\u001b[32mINFO    \u001b[0m root:pipeline_deployment_tests.py:59 Pipeline e2e test artifacts stored in: gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests\n",
      "\u001b[32mINFO    \u001b[0m root:pipeline_deployment_tests.py:67 ML metadata store is ready.\n",
      "\u001b[32mINFO    \u001b[0m absl:component.py:78 Excluding no splits because exclude_splits is not set.\n",
      "\u001b[32mINFO    \u001b[0m absl:component.py:80 Excluding no splits because exclude_splits is not set.\n",
      "\u001b[32mINFO    \u001b[0m root:training_pipeline.py:293 Pipeline components: ['HyperparamsGen', 'TrainDataGen', 'TestDataGen', 'StatisticsGen', 'SchemaImporter', 'ExampleValidator', 'DataTransformer', 'WarmstartModelResolver', 'ModelTrainer', 'BaselineModelResolver', 'ModelEvaluator', 'ModelPusher']\n",
      "\u001b[32mINFO    \u001b[0m root:training_pipeline.py:300 Beam pipeline args: ['--project=mwpmltr', '--temp_location=gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/temp', '--region=us-central1', '--runner=DirectRunner']\n",
      "\u001b[32mINFO    \u001b[0m absl:udf_utils.py:233 Generating ephemeral wheel package for '/home/jupyter/mlops-with-vertex-ai/src/preprocessing/transformations.py' (including modules: ['etl', 'transformations']).\n",
      "\u001b[32mINFO    \u001b[0m absl:udf_utils.py:237 User module package has hash fingerprint version de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d.\n",
      "\u001b[32mINFO    \u001b[0m absl:udf_utils.py:251 Executing: ['/opt/conda/bin/python', '/tmp/tmpjqkb_4mg/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/tmp/tmpcv0z3p_a', '--dist-dir', '/tmp/tmprpvt86k6']\n",
      "\u001b[32mINFO    \u001b[0m absl:udf_utils.py:272 Successfully built user code wheel distribution at 'gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/_wheels/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl'; target user module is 'transformations'.\n",
      "\u001b[32mINFO    \u001b[0m absl:udf_utils.py:279 Full user module path is 'transformations@gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/_wheels/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl'\n",
      "\u001b[32mINFO    \u001b[0m absl:udf_utils.py:233 Generating ephemeral wheel package for '/home/jupyter/mlops-with-vertex-ai/src/model_training/runner.py' (including modules: ['data', 'exporter', 'trainer', 'task', 'model', 'runner', 'defaults']).\n",
      "\u001b[32mINFO    \u001b[0m absl:udf_utils.py:237 User module package has hash fingerprint version 437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8.\n",
      "\u001b[32mINFO    \u001b[0m absl:udf_utils.py:251 Executing: ['/opt/conda/bin/python', '/tmp/tmpnc4to2rs/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/tmp/tmpjqle583s', '--dist-dir', '/tmp/tmpmn2gzwdp']\n",
      "\u001b[32mINFO    \u001b[0m absl:udf_utils.py:272 Successfully built user code wheel distribution at 'gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/_wheels/tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8-py3-none-any.whl'; target user module is 'runner'.\n",
      "\u001b[32mINFO    \u001b[0m absl:udf_utils.py:279 Full user module path is 'runner@gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/_wheels/tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8-py3-none-any.whl'\n",
      "\u001b[32mINFO    \u001b[0m absl:local_dag_runner.py:68 Using deployment config:\n",
      " executor_specs {\n",
      "  key: \"DataTransformer\"\n",
      "  value {\n",
      "    beam_executable_spec {\n",
      "      python_executor_spec {\n",
      "        class_path: \"tfx.components.transform.executor.Executor\"\n",
      "      }\n",
      "      beam_pipeline_args: \"--project=mwpmltr\"\n",
      "      beam_pipeline_args: \"--temp_location=gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/temp\"\n",
      "      beam_pipeline_args: \"--region=us-central1\"\n",
      "      beam_pipeline_args: \"--runner=DirectRunner\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"ExampleValidator\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.example_validator.executor.Executor\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"HyperparamsGen\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"src.tfx_pipelines.components.hyperparameters_gen_Executor\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"ModelEvaluator\"\n",
      "  value {\n",
      "    beam_executable_spec {\n",
      "      python_executor_spec {\n",
      "        class_path: \"tfx.components.evaluator.executor.Executor\"\n",
      "      }\n",
      "      beam_pipeline_args: \"--project=mwpmltr\"\n",
      "      beam_pipeline_args: \"--temp_location=gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/temp\"\n",
      "      beam_pipeline_args: \"--region=us-central1\"\n",
      "      beam_pipeline_args: \"--runner=DirectRunner\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"ModelPusher\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.pusher.executor.Executor\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"ModelTrainer\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.trainer.executor.GenericExecutor\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"StatisticsGen\"\n",
      "  value {\n",
      "    beam_executable_spec {\n",
      "      python_executor_spec {\n",
      "        class_path: \"tfx.components.statistics_gen.executor.Executor\"\n",
      "      }\n",
      "      beam_pipeline_args: \"--project=mwpmltr\"\n",
      "      beam_pipeline_args: \"--temp_location=gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/temp\"\n",
      "      beam_pipeline_args: \"--region=us-central1\"\n",
      "      beam_pipeline_args: \"--runner=DirectRunner\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"TestDataGen\"\n",
      "  value {\n",
      "    beam_executable_spec {\n",
      "      python_executor_spec {\n",
      "        class_path: \"tfx.extensions.google_cloud_big_query.example_gen.executor.Executor\"\n",
      "      }\n",
      "      beam_pipeline_args: \"--project=mwpmltr\"\n",
      "      beam_pipeline_args: \"--temp_location=gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/temp\"\n",
      "      beam_pipeline_args: \"--region=us-central1\"\n",
      "      beam_pipeline_args: \"--runner=DirectRunner\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"TrainDataGen\"\n",
      "  value {\n",
      "    beam_executable_spec {\n",
      "      python_executor_spec {\n",
      "        class_path: \"tfx.extensions.google_cloud_big_query.example_gen.executor.Executor\"\n",
      "      }\n",
      "      beam_pipeline_args: \"--project=mwpmltr\"\n",
      "      beam_pipeline_args: \"--temp_location=gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/temp\"\n",
      "      beam_pipeline_args: \"--region=us-central1\"\n",
      "      beam_pipeline_args: \"--runner=DirectRunner\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "custom_driver_specs {\n",
      "  key: \"TestDataGen\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.example_gen.driver.QueryBasedDriver\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "custom_driver_specs {\n",
      "  key: \"TrainDataGen\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.example_gen.driver.QueryBasedDriver\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "metadata_connection_config {\n",
      "  database_connection_config {\n",
      "    sqlite {\n",
      "      filename_uri: \"mlmd.sqllite\"\n",
      "      connection_mode: READWRITE_OPENCREATE\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\u001b[32mINFO    \u001b[0m absl:local_dag_runner.py:69 Using connection config:\n",
      " sqlite {\n",
      "  filename_uri: \"mlmd.sqllite\"\n",
      "  connection_mode: READWRITE_OPENCREATE\n",
      "}\n",
      "\n",
      "\u001b[32mINFO    \u001b[0m absl:local_dag_runner.py:105 Component BaselineModelResolver is running.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:519 Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.dsl.components.common.resolver.Resolver\"\n",
      "  }\n",
      "  id: \"BaselineModelResolver\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.BaselineModelResolver\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model_blessing\"\n",
      "    value {\n",
      "      channels {\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ModelBlessing\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  resolver_config {\n",
      "    resolver_steps {\n",
      "      class_path: \"tfx.dsl.input_resolution.strategies.latest_blessed_model_strategy.LatestBlessedModelStrategy\"\n",
      "      config_json: \"{}\"\n",
      "      input_keys: \"model\"\n",
      "      input_keys: \"model_blessing\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"ModelEvaluator\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "\u001b[32mINFO    \u001b[0m absl:resolver_node_handler.py:63 Running as an resolver node.\n",
      "\u001b[32mINFO    \u001b[0m absl:metadata_store.py:105 MetadataStore with DB connection initialized\n",
      "\u001b[33mWARNING \u001b[0m absl:inputs_utils.py:60 Artifact type ModelBlessing is not found in MLMD.\n",
      "\u001b[33mWARNING \u001b[0m absl:inputs_utils.py:60 Artifact type Model is not found in MLMD.\n",
      "\u001b[32mINFO    \u001b[0m absl:local_dag_runner.py:110 Component BaselineModelResolver is finished.\n",
      "\u001b[32mINFO    \u001b[0m absl:local_dag_runner.py:105 Component HyperparamsGen is running.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:519 Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"src.tfx_pipelines.components.hyperparameters_gen\"\n",
      "  }\n",
      "  id: \"HyperparamsGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.HyperparamsGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"hyperparameters\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"HyperParameters\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"batch_size\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 512\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"hidden_units\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"128,128\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"learning_rate\"\n",
      "    value {\n",
      "      field_value {\n",
      "        double_value: 0.001\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"num_epochs\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"ModelTrainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "\u001b[32mINFO    \u001b[0m absl:metadata_store.py:105 MetadataStore with DB connection initialized\n",
      "\u001b[32mINFO    \u001b[0m absl:metadata_store.py:105 MetadataStore with DB connection initialized\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:380 Going to run a new execution 2\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:420 Going to run a new execution: ExecutionInfo(execution_id=2, input_dict={}, output_dict=defaultdict(<class 'list'>, {'hyperparameters': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/HyperparamsGen/hyperparameters/2\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:HyperparamsGen:hyperparameters:0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:HyperparamsGen:hyperparameters:0\"\n",
      ", artifact_type: name: \"HyperParameters\"\n",
      ")]}), exec_properties={'hidden_units': '128,128', 'num_epochs': 1, 'learning_rate': 0.001, 'batch_size': 512}, execution_output_uri='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/HyperparamsGen/.system/executor_execution/2/executor_output.pb', stateful_working_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/HyperparamsGen/.system/stateful_working_dir/2022-09-10T23:47:00.785303', tmp_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/HyperparamsGen/.system/executor_execution/2/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"src.tfx_pipelines.components.hyperparameters_gen\"\n",
      "  }\n",
      "  id: \"HyperparamsGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.HyperparamsGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"hyperparameters\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"HyperParameters\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"batch_size\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 512\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"hidden_units\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"128,128\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"learning_rate\"\n",
      "    value {\n",
      "      field_value {\n",
      "        double_value: 0.001\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"num_epochs\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"ModelTrainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      ", pipeline_run_id='2022-09-10T23:47:00.785303')\n",
      "\u001b[32mINFO    \u001b[0m root:components.py:66 Hyperparameters: {'num_epochs': 1, 'batch_size': 512, 'learning_rate': 0.001, 'hidden_units': [128, 128]}\n",
      "\u001b[32mINFO    \u001b[0m root:components.py:72 Hyperparameters are written to: gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/HyperparamsGen/hyperparameters/2/hyperparameters.json\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:467 Cleaning up stateless execution info.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:562 Execution 2 succeeded.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:481 Cleaning up stateful execution info.\n",
      "\u001b[33mWARNING \u001b[0m absl:outputs_utils.py:95 stateful_working_dir /home/jupyter/mlops-with-vertex-ai/gs:/gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/HyperparamsGen/.system/stateful_working_dir is not found, not going to delete it.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:573 Publishing output artifacts defaultdict(<class 'list'>, {'hyperparameters': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/HyperparamsGen/hyperparameters/2\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:HyperparamsGen:hyperparameters:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:HyperparamsGen:hyperparameters:0\"\n",
      ", artifact_type: name: \"HyperParameters\"\n",
      ")]}) for execution 2\n",
      "\u001b[32mINFO    \u001b[0m absl:metadata_store.py:105 MetadataStore with DB connection initialized\n",
      "\u001b[32mINFO    \u001b[0m absl:local_dag_runner.py:110 Component HyperparamsGen is finished.\n",
      "\u001b[32mINFO    \u001b[0m absl:local_dag_runner.py:105 Component SchemaImporter is running.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:519 Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.dsl.components.common.importer.Importer\"\n",
      "  }\n",
      "  id: \"SchemaImporter\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.SchemaImporter\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"result\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"artifact_uri\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"src/raw_schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"reimport\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"DataTransformer\"\n",
      "downstream_nodes: \"ExampleValidator\"\n",
      "downstream_nodes: \"ModelEvaluator\"\n",
      "downstream_nodes: \"ModelTrainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "\u001b[32mINFO    \u001b[0m absl:importer_node_handler.py:69 Running as an importer node.\n",
      "\u001b[32mINFO    \u001b[0m absl:metadata_store.py:105 MetadataStore with DB connection initialized\n",
      "\u001b[32mINFO    \u001b[0m absl:importer.py:87 Processing source uri: src/raw_schema, properties: {}, custom_properties: {}\n",
      "\u001b[32mINFO    \u001b[0m absl:local_dag_runner.py:110 Component SchemaImporter is finished.\n",
      "\u001b[32mINFO    \u001b[0m absl:local_dag_runner.py:105 Component TestDataGen is running.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:519 Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.extensions.google_cloud_big_query.example_gen.component.BigQueryExampleGen\"\n",
      "    base_type: PROCESS\n",
      "  }\n",
      "  id: \"TestDataGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.TestDataGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "          base_type: DATASET\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"input_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"\\\\n    SELECT \\\\n        IF(trip_month IS NULL, -1, trip_month) trip_month,\\\\n        IF(trip_day IS NULL, -1, trip_day) trip_day,\\\\n        IF(trip_day_of_week IS NULL, -1, trip_day_of_week) trip_day_of_week,\\\\n        IF(trip_hour IS NULL, -1, trip_hour) trip_hour,\\\\n        IF(trip_seconds IS NULL, -1, trip_seconds) trip_seconds,\\\\n        IF(trip_miles IS NULL, -1, trip_miles) trip_miles,\\\\n        IF(payment_type IS NULL, \\'NA\\', payment_type) payment_type,\\\\n        IF(pickup_grid IS NULL, \\'NA\\', pickup_grid) pickup_grid,\\\\n        IF(dropoff_grid IS NULL, \\'NA\\', dropoff_grid) dropoff_grid,\\\\n        IF(euclidean IS NULL, -1, euclidean) euclidean,\\\\n        IF(loc_cross IS NULL, \\'NA\\', loc_cross) loc_cross,\\\\n        tip_bin\\\\n    FROM playground_central.chicago_taxitrips_prep \\\\n    WHERE ML_use = \\'TEST\\'\\\\n    LIMIT 100\\\"\\n    }\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"test\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_data_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 6\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_file_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 5\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"ModelEvaluator\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "\u001b[32mINFO    \u001b[0m absl:metadata_store.py:105 MetadataStore with DB connection initialized\n",
      "\u001b[32mINFO    \u001b[0m absl:metadata_store.py:105 MetadataStore with DB connection initialized\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:380 Going to run a new execution 4\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:420 Going to run a new execution: ExecutionInfo(execution_id=4, input_dict={}, output_dict=defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/TestDataGen/examples/4\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:TestDataGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:TestDataGen:examples:0\"\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}), exec_properties={'output_data_format': 6, 'output_config': '{\\n  \"split_config\": {\\n    \"splits\": [\\n      {\\n        \"hash_buckets\": 1,\\n        \"name\": \"test\"\\n      }\\n    ]\\n  }\\n}', 'output_file_format': 5, 'input_config': '{\\n  \"splits\": [\\n    {\\n      \"name\": \"single_split\",\\n      \"pattern\": \"\\\\n    SELECT \\\\n        IF(trip_month IS NULL, -1, trip_month) trip_month,\\\\n        IF(trip_day IS NULL, -1, trip_day) trip_day,\\\\n        IF(trip_day_of_week IS NULL, -1, trip_day_of_week) trip_day_of_week,\\\\n        IF(trip_hour IS NULL, -1, trip_hour) trip_hour,\\\\n        IF(trip_seconds IS NULL, -1, trip_seconds) trip_seconds,\\\\n        IF(trip_miles IS NULL, -1, trip_miles) trip_miles,\\\\n        IF(payment_type IS NULL, \\'NA\\', payment_type) payment_type,\\\\n        IF(pickup_grid IS NULL, \\'NA\\', pickup_grid) pickup_grid,\\\\n        IF(dropoff_grid IS NULL, \\'NA\\', dropoff_grid) dropoff_grid,\\\\n        IF(euclidean IS NULL, -1, euclidean) euclidean,\\\\n        IF(loc_cross IS NULL, \\'NA\\', loc_cross) loc_cross,\\\\n        tip_bin\\\\n    FROM playground_central.chicago_taxitrips_prep \\\\n    WHERE ML_use = \\'TEST\\'\\\\n    LIMIT 100\"\\n    }\\n  ]\\n}', 'span': 0, 'version': None, 'input_fingerprint': None}, execution_output_uri='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/TestDataGen/.system/executor_execution/4/executor_output.pb', stateful_working_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/TestDataGen/.system/stateful_working_dir/2022-09-10T23:47:00.785303', tmp_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/TestDataGen/.system/executor_execution/4/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.extensions.google_cloud_big_query.example_gen.component.BigQueryExampleGen\"\n",
      "    base_type: PROCESS\n",
      "  }\n",
      "  id: \"TestDataGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.TestDataGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "          base_type: DATASET\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"input_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"\\\\n    SELECT \\\\n        IF(trip_month IS NULL, -1, trip_month) trip_month,\\\\n        IF(trip_day IS NULL, -1, trip_day) trip_day,\\\\n        IF(trip_day_of_week IS NULL, -1, trip_day_of_week) trip_day_of_week,\\\\n        IF(trip_hour IS NULL, -1, trip_hour) trip_hour,\\\\n        IF(trip_seconds IS NULL, -1, trip_seconds) trip_seconds,\\\\n        IF(trip_miles IS NULL, -1, trip_miles) trip_miles,\\\\n        IF(payment_type IS NULL, \\'NA\\', payment_type) payment_type,\\\\n        IF(pickup_grid IS NULL, \\'NA\\', pickup_grid) pickup_grid,\\\\n        IF(dropoff_grid IS NULL, \\'NA\\', dropoff_grid) dropoff_grid,\\\\n        IF(euclidean IS NULL, -1, euclidean) euclidean,\\\\n        IF(loc_cross IS NULL, \\'NA\\', loc_cross) loc_cross,\\\\n        tip_bin\\\\n    FROM playground_central.chicago_taxitrips_prep \\\\n    WHERE ML_use = \\'TEST\\'\\\\n    LIMIT 100\\\"\\n    }\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"test\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_data_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 6\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_file_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 5\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"ModelEvaluator\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      ", pipeline_run_id='2022-09-10T23:47:00.785303')\n",
      "\u001b[32mINFO    \u001b[0m absl:dependency_utils.py:67 Attempting to infer TFX Python dependency for beam\n",
      "\u001b[32mINFO    \u001b[0m absl:dependency_utils.py:108 Copying all content from install dir /home/jupyter/.local/lib/python3.7/site-packages/tfx to temp dir /tmp/tmp26_kt8kr/build/tfx\n",
      "\u001b[32mINFO    \u001b[0m absl:dependency_utils.py:114 Generating a temp setup file at /tmp/tmp26_kt8kr/build/tfx/setup.py\n",
      "\u001b[32mINFO    \u001b[0m absl:dependency_utils.py:127 Creating temporary sdist package, logs available at /tmp/tmp26_kt8kr/build/tfx/setup.log\n",
      "\u001b[32mINFO    \u001b[0m absl:dependency_utils.py:70 Added --extra_package=/tmp/tmp26_kt8kr/build/tfx/dist/tfx_ephemeral-1.8.0.tar.gz to beam args\n",
      "\u001b[33mWARNING \u001b[0m absl:telemetry_utils.py:62 Length of label `tfx-extensions-google_cloud_big_query-example_gen-executor-executor` exceeds maximum length(63), trimmed.\n",
      "\u001b[32mINFO    \u001b[0m absl:base_example_gen_executor.py:272 Generating examples.\n",
      "\u001b[33mWARNING \u001b[0m root:environments.py:374 Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n",
      "\u001b[32mINFO    \u001b[0m root:environments.py:380 Default Python SDK image for environment is apache/beam_python3.7_sdk:2.39.0\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function annotate_downstream_side_inputs at 0x7f48d14ee5f0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function fix_side_input_pcoll_coders at 0x7f48d14ee710> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function pack_combiners at 0x7f48d14eec20> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function lift_combiners at 0x7f48d14eecb0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function expand_sdf at 0x7f48d14eee60> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function expand_gbk at 0x7f48d14eeef0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function sink_flattens at 0x7f48d14ef050> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function greedily_fuse at 0x7f48d14ef0e0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function read_to_impulse at 0x7f48d14ef170> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function impulse_to_input at 0x7f48d14ef200> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function sort_stages at 0x7f48d14ef440> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function add_impulse_to_dangling_transforms at 0x7f48d14ef560> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function setup_timer_mapping at 0x7f48d14ef3b0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function populate_data_channel_coders at 0x7f48d14ef4d0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.worker.statecache:statecache.py:172 Creating state cache with size 100\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.worker_handlers:worker_handlers.py:894 Created Worker handler <apache_beam.runners.portability.fn_api_runner.worker_handlers.EmbeddedWorkerHandler object at 0x7f48fe733910> for environment ref_Environment_default_environment_1 (beam:env:embedded_python:v1, b'')\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.internal.gcp.auth:auth.py:136 Setting socket default timeout to 60 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.internal.gcp.auth:auth.py:139 socket default timeout is 60.0 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.bigquery_tools:bigquery_tools.py:563 Started BigQuery job: <JobReference\n",
      " location: 'us-central1'\n",
      " projectId: 'mwpmltr'>\n",
      " bq show -j --format=prettyjson --project_id=mwpmltr None\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.bigquery_tools:bigquery_tools.py:446 Using location 'us-central1' from table <TableReference\n",
      " datasetId: 'playground_central'\n",
      " projectId: 'mwpmltr'\n",
      " tableId: 'chicago_taxitrips_prep'> referenced by query \n",
      "    SELECT \n",
      "        IF(trip_month IS NULL, -1, trip_month) trip_month,\n",
      "        IF(trip_day IS NULL, -1, trip_day) trip_day,\n",
      "        IF(trip_day_of_week IS NULL, -1, trip_day_of_week) trip_day_of_week,\n",
      "        IF(trip_hour IS NULL, -1, trip_hour) trip_hour,\n",
      "        IF(trip_seconds IS NULL, -1, trip_seconds) trip_seconds,\n",
      "        IF(trip_miles IS NULL, -1, trip_miles) trip_miles,\n",
      "        IF(payment_type IS NULL, 'NA', payment_type) payment_type,\n",
      "        IF(pickup_grid IS NULL, 'NA', pickup_grid) pickup_grid,\n",
      "        IF(dropoff_grid IS NULL, 'NA', dropoff_grid) dropoff_grid,\n",
      "        IF(euclidean IS NULL, -1, euclidean) euclidean,\n",
      "        IF(loc_cross IS NULL, 'NA', loc_cross) loc_cross,\n",
      "        tip_bin\n",
      "    FROM playground_central.chicago_taxitrips_prep \n",
      "    WHERE ML_use = 'TEST'\n",
      "    LIMIT 100\n",
      "\u001b[33mWARNING \u001b[0m apache_beam.io.gcp.bigquery_tools:bigquery_tools.py:892 Dataset mwpmltr:beam_temp_dataset_69f3bfda333441b1aaece9fefd6c8433 does not exist so we will create it as temporary with location=us-central1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.bigquery_tools:bigquery_tools.py:563 Started BigQuery job: <JobReference\n",
      " jobId: 'beam_bq_job_QUERY_BQ_EXPORT_JOB_b0f2fd48-d_1662853630_600'\n",
      " location: 'us-central1'\n",
      " projectId: 'mwpmltr'>\n",
      " bq show -j --format=prettyjson --project_id=mwpmltr beam_bq_job_QUERY_BQ_EXPORT_JOB_b0f2fd48-d_1662853630_600\n",
      "\u001b[32mINFO    \u001b[0m root:bigquery_tools.py:631 Job status: RUNNING\n",
      "\u001b[32mINFO    \u001b[0m root:bigquery_tools.py:631 Job status: DONE\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.bigquery_tools:bigquery_tools.py:563 Started BigQuery job: <JobReference\n",
      " jobId: 'beam_bq_job_EXPORT_BQ_EXPORT_JOB_b0f2fd48-d_1662853635_700'\n",
      " location: 'us-central1'\n",
      " projectId: 'mwpmltr'>\n",
      " bq show -j --format=prettyjson --project_id=mwpmltr beam_bq_job_EXPORT_BQ_EXPORT_JOB_b0f2fd48-d_1662853635_700\n",
      "\u001b[32mINFO    \u001b[0m root:bigquery_tools.py:631 Job status: RUNNING\n",
      "\u001b[32mINFO    \u001b[0m root:bigquery_tools.py:631 Job status: DONE\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.043398141860961914 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.03715634346008301 seconds.\n",
      "\u001b[33mWARNING \u001b[0m apache_beam.io.tfrecordio:tfrecordio.py:60 Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.029029369354248047 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.03907179832458496 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.03478527069091797 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.20 seconds.\n",
      "\u001b[32mINFO    \u001b[0m absl:base_example_gen_executor.py:300 Examples generated.\n",
      "\u001b[32mINFO    \u001b[0m absl:outputs_utils.py:291 Value type <class 'NoneType'> of key version in exec_properties is not supported, going to drop it\n",
      "\u001b[32mINFO    \u001b[0m absl:outputs_utils.py:291 Value type <class 'NoneType'> of key input_fingerprint in exec_properties is not supported, going to drop it\n",
      "\u001b[32mINFO    \u001b[0m absl:outputs_utils.py:291 Value type <class 'list'> of key _beam_pipeline_args in exec_properties is not supported, going to drop it\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:467 Cleaning up stateless execution info.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:562 Execution 4 succeeded.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:481 Cleaning up stateful execution info.\n",
      "\u001b[33mWARNING \u001b[0m absl:outputs_utils.py:95 stateful_working_dir /home/jupyter/mlops-with-vertex-ai/gs:/gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/TestDataGen/.system/stateful_working_dir is not found, not going to delete it.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:573 Publishing output artifacts defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/TestDataGen/examples/4\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:TestDataGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:TestDataGen:examples:0\"\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}) for execution 4\n",
      "\u001b[32mINFO    \u001b[0m absl:metadata_store.py:105 MetadataStore with DB connection initialized\n",
      "\u001b[32mINFO    \u001b[0m absl:local_dag_runner.py:110 Component TestDataGen is finished.\n",
      "\u001b[32mINFO    \u001b[0m absl:local_dag_runner.py:105 Component TrainDataGen is running.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:519 Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.extensions.google_cloud_big_query.example_gen.component.BigQueryExampleGen\"\n",
      "    base_type: PROCESS\n",
      "  }\n",
      "  id: \"TrainDataGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.TrainDataGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "          base_type: DATASET\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"input_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"\\\\n    SELECT \\\\n        IF(trip_month IS NULL, -1, trip_month) trip_month,\\\\n        IF(trip_day IS NULL, -1, trip_day) trip_day,\\\\n        IF(trip_day_of_week IS NULL, -1, trip_day_of_week) trip_day_of_week,\\\\n        IF(trip_hour IS NULL, -1, trip_hour) trip_hour,\\\\n        IF(trip_seconds IS NULL, -1, trip_seconds) trip_seconds,\\\\n        IF(trip_miles IS NULL, -1, trip_miles) trip_miles,\\\\n        IF(payment_type IS NULL, \\'NA\\', payment_type) payment_type,\\\\n        IF(pickup_grid IS NULL, \\'NA\\', pickup_grid) pickup_grid,\\\\n        IF(dropoff_grid IS NULL, \\'NA\\', dropoff_grid) dropoff_grid,\\\\n        IF(euclidean IS NULL, -1, euclidean) euclidean,\\\\n        IF(loc_cross IS NULL, \\'NA\\', loc_cross) loc_cross,\\\\n        tip_bin\\\\n    FROM playground_central.chicago_taxitrips_prep \\\\n    WHERE ML_use = \\'UNASSIGNED\\'\\\\n    LIMIT 1000\\\"\\n    }\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 4,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_data_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 6\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_file_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 5\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"DataTransformer\"\n",
      "downstream_nodes: \"StatisticsGen\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "\u001b[32mINFO    \u001b[0m absl:metadata_store.py:105 MetadataStore with DB connection initialized\n",
      "\u001b[32mINFO    \u001b[0m absl:metadata_store.py:105 MetadataStore with DB connection initialized\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:380 Going to run a new execution 5\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:420 Going to run a new execution: ExecutionInfo(execution_id=5, input_dict={}, output_dict=defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/TrainDataGen/examples/5\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:TrainDataGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:TrainDataGen:examples:0\"\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}), exec_properties={'output_file_format': 5, 'output_config': '{\\n  \"split_config\": {\\n    \"splits\": [\\n      {\\n        \"hash_buckets\": 4,\\n        \"name\": \"train\"\\n      },\\n      {\\n        \"hash_buckets\": 1,\\n        \"name\": \"eval\"\\n      }\\n    ]\\n  }\\n}', 'input_config': '{\\n  \"splits\": [\\n    {\\n      \"name\": \"single_split\",\\n      \"pattern\": \"\\\\n    SELECT \\\\n        IF(trip_month IS NULL, -1, trip_month) trip_month,\\\\n        IF(trip_day IS NULL, -1, trip_day) trip_day,\\\\n        IF(trip_day_of_week IS NULL, -1, trip_day_of_week) trip_day_of_week,\\\\n        IF(trip_hour IS NULL, -1, trip_hour) trip_hour,\\\\n        IF(trip_seconds IS NULL, -1, trip_seconds) trip_seconds,\\\\n        IF(trip_miles IS NULL, -1, trip_miles) trip_miles,\\\\n        IF(payment_type IS NULL, \\'NA\\', payment_type) payment_type,\\\\n        IF(pickup_grid IS NULL, \\'NA\\', pickup_grid) pickup_grid,\\\\n        IF(dropoff_grid IS NULL, \\'NA\\', dropoff_grid) dropoff_grid,\\\\n        IF(euclidean IS NULL, -1, euclidean) euclidean,\\\\n        IF(loc_cross IS NULL, \\'NA\\', loc_cross) loc_cross,\\\\n        tip_bin\\\\n    FROM playground_central.chicago_taxitrips_prep \\\\n    WHERE ML_use = \\'UNASSIGNED\\'\\\\n    LIMIT 1000\"\\n    }\\n  ]\\n}', 'output_data_format': 6, 'span': 0, 'version': None, 'input_fingerprint': None}, execution_output_uri='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/TrainDataGen/.system/executor_execution/5/executor_output.pb', stateful_working_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/TrainDataGen/.system/stateful_working_dir/2022-09-10T23:47:00.785303', tmp_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/TrainDataGen/.system/executor_execution/5/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.extensions.google_cloud_big_query.example_gen.component.BigQueryExampleGen\"\n",
      "    base_type: PROCESS\n",
      "  }\n",
      "  id: \"TrainDataGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.TrainDataGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "          base_type: DATASET\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"input_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"\\\\n    SELECT \\\\n        IF(trip_month IS NULL, -1, trip_month) trip_month,\\\\n        IF(trip_day IS NULL, -1, trip_day) trip_day,\\\\n        IF(trip_day_of_week IS NULL, -1, trip_day_of_week) trip_day_of_week,\\\\n        IF(trip_hour IS NULL, -1, trip_hour) trip_hour,\\\\n        IF(trip_seconds IS NULL, -1, trip_seconds) trip_seconds,\\\\n        IF(trip_miles IS NULL, -1, trip_miles) trip_miles,\\\\n        IF(payment_type IS NULL, \\'NA\\', payment_type) payment_type,\\\\n        IF(pickup_grid IS NULL, \\'NA\\', pickup_grid) pickup_grid,\\\\n        IF(dropoff_grid IS NULL, \\'NA\\', dropoff_grid) dropoff_grid,\\\\n        IF(euclidean IS NULL, -1, euclidean) euclidean,\\\\n        IF(loc_cross IS NULL, \\'NA\\', loc_cross) loc_cross,\\\\n        tip_bin\\\\n    FROM playground_central.chicago_taxitrips_prep \\\\n    WHERE ML_use = \\'UNASSIGNED\\'\\\\n    LIMIT 1000\\\"\\n    }\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 4,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_data_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 6\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_file_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 5\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"DataTransformer\"\n",
      "downstream_nodes: \"StatisticsGen\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      ", pipeline_run_id='2022-09-10T23:47:00.785303')\n",
      "\u001b[32mINFO    \u001b[0m absl:dependency_utils.py:67 Attempting to infer TFX Python dependency for beam\n",
      "\u001b[32mINFO    \u001b[0m absl:dependency_utils.py:108 Copying all content from install dir /home/jupyter/.local/lib/python3.7/site-packages/tfx to temp dir /tmp/tmpsq6b5ie7/build/tfx\n",
      "\u001b[32mINFO    \u001b[0m absl:dependency_utils.py:114 Generating a temp setup file at /tmp/tmpsq6b5ie7/build/tfx/setup.py\n",
      "\u001b[32mINFO    \u001b[0m absl:dependency_utils.py:127 Creating temporary sdist package, logs available at /tmp/tmpsq6b5ie7/build/tfx/setup.log\n",
      "\u001b[32mINFO    \u001b[0m absl:dependency_utils.py:70 Added --extra_package=/tmp/tmpsq6b5ie7/build/tfx/dist/tfx_ephemeral-1.8.0.tar.gz to beam args\n",
      "\u001b[33mWARNING \u001b[0m absl:telemetry_utils.py:62 Length of label `tfx-extensions-google_cloud_big_query-example_gen-executor-executor` exceeds maximum length(63), trimmed.\n",
      "\u001b[32mINFO    \u001b[0m absl:base_example_gen_executor.py:272 Generating examples.\n",
      "\u001b[33mWARNING \u001b[0m root:environments.py:374 Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n",
      "\u001b[32mINFO    \u001b[0m root:environments.py:380 Default Python SDK image for environment is apache/beam_python3.7_sdk:2.39.0\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function annotate_downstream_side_inputs at 0x7f48d14ee5f0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function fix_side_input_pcoll_coders at 0x7f48d14ee710> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function pack_combiners at 0x7f48d14eec20> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function lift_combiners at 0x7f48d14eecb0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function expand_sdf at 0x7f48d14eee60> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function expand_gbk at 0x7f48d14eeef0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function sink_flattens at 0x7f48d14ef050> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function greedily_fuse at 0x7f48d14ef0e0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function read_to_impulse at 0x7f48d14ef170> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function impulse_to_input at 0x7f48d14ef200> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function sort_stages at 0x7f48d14ef440> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function add_impulse_to_dangling_transforms at 0x7f48d14ef560> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function setup_timer_mapping at 0x7f48d14ef3b0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function populate_data_channel_coders at 0x7f48d14ef4d0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.worker.statecache:statecache.py:172 Creating state cache with size 100\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.worker_handlers:worker_handlers.py:894 Created Worker handler <apache_beam.runners.portability.fn_api_runner.worker_handlers.EmbeddedWorkerHandler object at 0x7f48cc9c2510> for environment ref_Environment_default_environment_1 (beam:env:embedded_python:v1, b'')\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.bigquery_tools:bigquery_tools.py:563 Started BigQuery job: <JobReference\n",
      " location: 'us-central1'\n",
      " projectId: 'mwpmltr'>\n",
      " bq show -j --format=prettyjson --project_id=mwpmltr None\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.bigquery_tools:bigquery_tools.py:446 Using location 'us-central1' from table <TableReference\n",
      " datasetId: 'playground_central'\n",
      " projectId: 'mwpmltr'\n",
      " tableId: 'chicago_taxitrips_prep'> referenced by query \n",
      "    SELECT \n",
      "        IF(trip_month IS NULL, -1, trip_month) trip_month,\n",
      "        IF(trip_day IS NULL, -1, trip_day) trip_day,\n",
      "        IF(trip_day_of_week IS NULL, -1, trip_day_of_week) trip_day_of_week,\n",
      "        IF(trip_hour IS NULL, -1, trip_hour) trip_hour,\n",
      "        IF(trip_seconds IS NULL, -1, trip_seconds) trip_seconds,\n",
      "        IF(trip_miles IS NULL, -1, trip_miles) trip_miles,\n",
      "        IF(payment_type IS NULL, 'NA', payment_type) payment_type,\n",
      "        IF(pickup_grid IS NULL, 'NA', pickup_grid) pickup_grid,\n",
      "        IF(dropoff_grid IS NULL, 'NA', dropoff_grid) dropoff_grid,\n",
      "        IF(euclidean IS NULL, -1, euclidean) euclidean,\n",
      "        IF(loc_cross IS NULL, 'NA', loc_cross) loc_cross,\n",
      "        tip_bin\n",
      "    FROM playground_central.chicago_taxitrips_prep \n",
      "    WHERE ML_use = 'UNASSIGNED'\n",
      "    LIMIT 1000\n",
      "\u001b[33mWARNING \u001b[0m apache_beam.io.gcp.bigquery_tools:bigquery_tools.py:892 Dataset mwpmltr:beam_temp_dataset_4c776635ac1d4d13a49b5cff9014f045 does not exist so we will create it as temporary with location=us-central1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.bigquery_tools:bigquery_tools.py:563 Started BigQuery job: <JobReference\n",
      " jobId: 'beam_bq_job_QUERY_BQ_EXPORT_JOB_3eff58bc-d_1662853648_288'\n",
      " location: 'us-central1'\n",
      " projectId: 'mwpmltr'>\n",
      " bq show -j --format=prettyjson --project_id=mwpmltr beam_bq_job_QUERY_BQ_EXPORT_JOB_3eff58bc-d_1662853648_288\n",
      "\u001b[32mINFO    \u001b[0m root:bigquery_tools.py:631 Job status: RUNNING\n",
      "\u001b[32mINFO    \u001b[0m root:bigquery_tools.py:631 Job status: DONE\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.bigquery_tools:bigquery_tools.py:563 Started BigQuery job: <JobReference\n",
      " jobId: 'beam_bq_job_EXPORT_BQ_EXPORT_JOB_3eff58bc-d_1662853654_587'\n",
      " location: 'us-central1'\n",
      " projectId: 'mwpmltr'>\n",
      " bq show -j --format=prettyjson --project_id=mwpmltr beam_bq_job_EXPORT_BQ_EXPORT_JOB_3eff58bc-d_1662853654_587\n",
      "\u001b[32mINFO    \u001b[0m root:bigquery_tools.py:631 Job status: RUNNING\n",
      "\u001b[32mINFO    \u001b[0m root:bigquery_tools.py:631 Job status: DONE\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.04310035705566406 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.04169893264770508 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.036736488342285156 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.030621767044067383 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.042211055755615234 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.041640520095825195 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.20 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.03886723518371582 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.03961682319641113 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.20 seconds.\n",
      "\u001b[32mINFO    \u001b[0m absl:base_example_gen_executor.py:300 Examples generated.\n",
      "\u001b[32mINFO    \u001b[0m absl:outputs_utils.py:291 Value type <class 'NoneType'> of key version in exec_properties is not supported, going to drop it\n",
      "\u001b[32mINFO    \u001b[0m absl:outputs_utils.py:291 Value type <class 'NoneType'> of key input_fingerprint in exec_properties is not supported, going to drop it\n",
      "\u001b[32mINFO    \u001b[0m absl:outputs_utils.py:291 Value type <class 'list'> of key _beam_pipeline_args in exec_properties is not supported, going to drop it\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:467 Cleaning up stateless execution info.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:562 Execution 5 succeeded.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:481 Cleaning up stateful execution info.\n",
      "\u001b[33mWARNING \u001b[0m absl:outputs_utils.py:95 stateful_working_dir /home/jupyter/mlops-with-vertex-ai/gs:/gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/TrainDataGen/.system/stateful_working_dir is not found, not going to delete it.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:573 Publishing output artifacts defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/TrainDataGen/examples/5\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:TrainDataGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:TrainDataGen:examples:0\"\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}) for execution 5\n",
      "\u001b[32mINFO    \u001b[0m absl:metadata_store.py:105 MetadataStore with DB connection initialized\n",
      "\u001b[32mINFO    \u001b[0m absl:local_dag_runner.py:110 Component TrainDataGen is finished.\n",
      "\u001b[32mINFO    \u001b[0m absl:local_dag_runner.py:105 Component WarmstartModelResolver is running.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:519 Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.dsl.components.common.resolver.Resolver\"\n",
      "  }\n",
      "  id: \"WarmstartModelResolver\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.WarmstartModelResolver\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"latest_model\"\n",
      "    value {\n",
      "      channels {\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  resolver_config {\n",
      "    resolver_steps {\n",
      "      class_path: \"tfx.dsl.input_resolution.strategies.latest_artifact_strategy.LatestArtifactStrategy\"\n",
      "      config_json: \"{}\"\n",
      "      input_keys: \"latest_model\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"ModelTrainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "\u001b[32mINFO    \u001b[0m absl:resolver_node_handler.py:63 Running as an resolver node.\n",
      "\u001b[32mINFO    \u001b[0m absl:metadata_store.py:105 MetadataStore with DB connection initialized\n",
      "\u001b[33mWARNING \u001b[0m absl:inputs_utils.py:60 Artifact type Model is not found in MLMD.\n",
      "\u001b[32mINFO    \u001b[0m absl:local_dag_runner.py:110 Component WarmstartModelResolver is finished.\n",
      "\u001b[32mINFO    \u001b[0m absl:local_dag_runner.py:105 Component StatisticsGen is running.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:519 Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
      "    base_type: PROCESS\n",
      "  }\n",
      "  id: \"StatisticsGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.StatisticsGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"TrainDataGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.TrainDataGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          base_type: STATISTICS\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"TrainDataGen\"\n",
      "downstream_nodes: \"ExampleValidator\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "\u001b[32mINFO    \u001b[0m absl:metadata_store.py:105 MetadataStore with DB connection initialized\n",
      "\u001b[32mINFO    \u001b[0m absl:metadata_store.py:105 MetadataStore with DB connection initialized\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:380 Going to run a new execution 7\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:420 Going to run a new execution: ExecutionInfo(execution_id=7, input_dict={'examples': [Artifact(artifact: id: 4\n",
      "type_id: 20\n",
      "uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/TrainDataGen/examples/5\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"file_format\"\n",
      "  value {\n",
      "    string_value: \"tfrecords_gzip\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:TrainDataGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:TrainDataGen:examples:0\"\n",
      "create_time_since_epoch: 1662853662190\n",
      "last_update_time_since_epoch: 1662853662190\n",
      ", artifact_type: id: 20\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/StatisticsGen/statistics/7\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:StatisticsGen:statistics:0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:StatisticsGen:statistics:0\"\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")]}), exec_properties={'exclude_splits': '[]'}, execution_output_uri='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/StatisticsGen/.system/executor_execution/7/executor_output.pb', stateful_working_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/StatisticsGen/.system/stateful_working_dir/2022-09-10T23:47:00.785303', tmp_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/StatisticsGen/.system/executor_execution/7/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
      "    base_type: PROCESS\n",
      "  }\n",
      "  id: \"StatisticsGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.StatisticsGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"TrainDataGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.TrainDataGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          base_type: STATISTICS\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"TrainDataGen\"\n",
      "downstream_nodes: \"ExampleValidator\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      ", pipeline_run_id='2022-09-10T23:47:00.785303')\n",
      "\u001b[32mINFO    \u001b[0m absl:dependency_utils.py:67 Attempting to infer TFX Python dependency for beam\n",
      "\u001b[32mINFO    \u001b[0m absl:dependency_utils.py:108 Copying all content from install dir /home/jupyter/.local/lib/python3.7/site-packages/tfx to temp dir /tmp/tmps6xvrn4i/build/tfx\n",
      "\u001b[32mINFO    \u001b[0m absl:dependency_utils.py:114 Generating a temp setup file at /tmp/tmps6xvrn4i/build/tfx/setup.py\n",
      "\u001b[32mINFO    \u001b[0m absl:dependency_utils.py:127 Creating temporary sdist package, logs available at /tmp/tmps6xvrn4i/build/tfx/setup.log\n",
      "\u001b[32mINFO    \u001b[0m absl:dependency_utils.py:70 Added --extra_package=/tmp/tmps6xvrn4i/build/tfx/dist/tfx_ephemeral-1.8.0.tar.gz to beam args\n",
      "\u001b[32mINFO    \u001b[0m absl:executor.py:130 Generating statistics for split train.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.04429793357849121 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.Mapping[tensorflow_data_validation.types.FeaturePath, ForwardRef('schema_pb2.FeatureType')]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.Mapping[tensorflow_data_validation.types.FeaturePath, ForwardRef('schema_pb2.FeatureType')]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.Mapping[tensorflow_data_validation.types.FeaturePath, ForwardRef('schema_pb2.FeatureType')]\n",
      "\u001b[32mINFO    \u001b[0m absl:executor.py:142 Statistics for split train written to gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/StatisticsGen/statistics/7/Split-train.\n",
      "\u001b[32mINFO    \u001b[0m absl:executor.py:130 Generating statistics for split eval.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.03654670715332031 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.Mapping[tensorflow_data_validation.types.FeaturePath, ForwardRef('schema_pb2.FeatureType')]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.Mapping[tensorflow_data_validation.types.FeaturePath, ForwardRef('schema_pb2.FeatureType')]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.Mapping[tensorflow_data_validation.types.FeaturePath, ForwardRef('schema_pb2.FeatureType')]\n",
      "\u001b[32mINFO    \u001b[0m absl:executor.py:142 Statistics for split eval written to gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/StatisticsGen/statistics/7/Split-eval.\n",
      "\u001b[33mWARNING \u001b[0m root:environments.py:374 Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n",
      "\u001b[32mINFO    \u001b[0m root:environments.py:380 Default Python SDK image for environment is apache/beam_python3.7_sdk:2.39.0\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function annotate_downstream_side_inputs at 0x7f48d14ee5f0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function fix_side_input_pcoll_coders at 0x7f48d14ee710> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function pack_combiners at 0x7f48d14eec20> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function lift_combiners at 0x7f48d14eecb0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function expand_sdf at 0x7f48d14eee60> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function expand_gbk at 0x7f48d14eeef0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function sink_flattens at 0x7f48d14ef050> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function greedily_fuse at 0x7f48d14ef0e0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function read_to_impulse at 0x7f48d14ef170> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function impulse_to_input at 0x7f48d14ef200> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function sort_stages at 0x7f48d14ef440> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function add_impulse_to_dangling_transforms at 0x7f48d14ef560> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function setup_timer_mapping at 0x7f48d14ef3b0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function populate_data_channel_coders at 0x7f48d14ef4d0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.worker.statecache:statecache.py:172 Creating state cache with size 100\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.worker_handlers:worker_handlers.py:894 Created Worker handler <apache_beam.runners.portability.fn_api_runner.worker_handlers.EmbeddedWorkerHandler object at 0x7f48cce95650> for environment ref_Environment_default_environment_1 (beam:env:embedded_python:v1, b'')\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.03538846969604492 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.028158187866210938 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.03311610221862793 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.029183626174926758 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.038233041763305664 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.20 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.03914237022399902 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.20 seconds.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:467 Cleaning up stateless execution info.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:562 Execution 7 succeeded.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:481 Cleaning up stateful execution info.\n",
      "\u001b[33mWARNING \u001b[0m absl:outputs_utils.py:95 stateful_working_dir /home/jupyter/mlops-with-vertex-ai/gs:/gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/StatisticsGen/.system/stateful_working_dir is not found, not going to delete it.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:573 Publishing output artifacts defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/StatisticsGen/statistics/7\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:StatisticsGen:statistics:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:StatisticsGen:statistics:0\"\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")]}) for execution 7\n",
      "\u001b[32mINFO    \u001b[0m absl:metadata_store.py:105 MetadataStore with DB connection initialized\n",
      "\u001b[32mINFO    \u001b[0m absl:local_dag_runner.py:110 Component StatisticsGen is finished.\n",
      "\u001b[32mINFO    \u001b[0m absl:local_dag_runner.py:105 Component ExampleValidator is running.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:519 Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.example_validator.component.ExampleValidator\"\n",
      "  }\n",
      "  id: \"ExampleValidator\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.ExampleValidator\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaImporter\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.SchemaImporter\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"result\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"StatisticsGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.StatisticsGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ExampleStatistics\"\n",
      "            base_type: STATISTICS\n",
      "          }\n",
      "        }\n",
      "        output_key: \"statistics\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"anomalies\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleAnomalies\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"SchemaImporter\"\n",
      "upstream_nodes: \"StatisticsGen\"\n",
      "downstream_nodes: \"DataTransformer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "\u001b[32mINFO    \u001b[0m absl:metadata_store.py:105 MetadataStore with DB connection initialized\n",
      "\u001b[32mINFO    \u001b[0m absl:metadata_store.py:105 MetadataStore with DB connection initialized\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:380 Going to run a new execution 8\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:420 Going to run a new execution: ExecutionInfo(execution_id=8, input_dict={'schema': [Artifact(artifact: id: 2\n",
      "type_id: 18\n",
      "uri: \"src/raw_schema\"\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1662853623948\n",
      "last_update_time_since_epoch: 1662853623948\n",
      ", artifact_type: id: 18\n",
      "name: \"Schema\"\n",
      ")], 'statistics': [Artifact(artifact: id: 5\n",
      "type_id: 22\n",
      "uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/StatisticsGen/statistics/7\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:StatisticsGen:statistics:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:StatisticsGen:statistics:0\"\n",
      "create_time_since_epoch: 1662853671441\n",
      "last_update_time_since_epoch: 1662853671441\n",
      ", artifact_type: id: 22\n",
      "name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'anomalies': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ExampleValidator/anomalies/8\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:ExampleValidator:anomalies:0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:ExampleValidator:anomalies:0\"\n",
      ", artifact_type: name: \"ExampleAnomalies\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")]}), exec_properties={'exclude_splits': '[]'}, execution_output_uri='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ExampleValidator/.system/executor_execution/8/executor_output.pb', stateful_working_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ExampleValidator/.system/stateful_working_dir/2022-09-10T23:47:00.785303', tmp_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ExampleValidator/.system/executor_execution/8/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.example_validator.component.ExampleValidator\"\n",
      "  }\n",
      "  id: \"ExampleValidator\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.ExampleValidator\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaImporter\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.SchemaImporter\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"result\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"StatisticsGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.StatisticsGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ExampleStatistics\"\n",
      "            base_type: STATISTICS\n",
      "          }\n",
      "        }\n",
      "        output_key: \"statistics\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"anomalies\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleAnomalies\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"SchemaImporter\"\n",
      "upstream_nodes: \"StatisticsGen\"\n",
      "downstream_nodes: \"DataTransformer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      ", pipeline_run_id='2022-09-10T23:47:00.785303')\n",
      "\u001b[32mINFO    \u001b[0m absl:executor.py:96 Validating schema against the computed statistics for split train.\n",
      "\u001b[32mINFO    \u001b[0m absl:executor.py:109 Validation complete for split train. Anomalies written to gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ExampleValidator/anomalies/8/Split-train.\n",
      "\u001b[32mINFO    \u001b[0m absl:executor.py:96 Validating schema against the computed statistics for split eval.\n",
      "\u001b[32mINFO    \u001b[0m absl:executor.py:109 Validation complete for split eval. Anomalies written to gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ExampleValidator/anomalies/8/Split-eval.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:467 Cleaning up stateless execution info.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:562 Execution 8 succeeded.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:481 Cleaning up stateful execution info.\n",
      "\u001b[33mWARNING \u001b[0m absl:outputs_utils.py:95 stateful_working_dir /home/jupyter/mlops-with-vertex-ai/gs:/gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ExampleValidator/.system/stateful_working_dir is not found, not going to delete it.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:573 Publishing output artifacts defaultdict(<class 'list'>, {'anomalies': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ExampleValidator/anomalies/8\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:ExampleValidator:anomalies:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:ExampleValidator:anomalies:0\"\n",
      ", artifact_type: name: \"ExampleAnomalies\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")]}) for execution 8\n",
      "\u001b[32mINFO    \u001b[0m absl:metadata_store.py:105 MetadataStore with DB connection initialized\n",
      "\u001b[32mINFO    \u001b[0m absl:local_dag_runner.py:110 Component ExampleValidator is finished.\n",
      "\u001b[32mINFO    \u001b[0m absl:local_dag_runner.py:105 Component DataTransformer is running.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:519 Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.transform.component.Transform\"\n",
      "    base_type: TRANSFORM\n",
      "  }\n",
      "  id: \"DataTransformer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.DataTransformer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"TrainDataGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.TrainDataGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaImporter\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.SchemaImporter\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"result\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"post_transform_anomalies\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleAnomalies\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"post_transform_schema\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"post_transform_stats\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          base_type: STATISTICS\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"pre_transform_schema\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"pre_transform_stats\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          base_type: STATISTICS\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"TransformGraph\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"transformed_examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "          base_type: DATASET\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"updated_analyzer_cache\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"TransformCache\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"disable_statistics\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"force_tf_compat_v1\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"transformations@gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/_wheels/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"splits_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"analyze\\\": [\\n    \\\"train\\\"\\n  ],\\n  \\\"transform\\\": [\\n    \\\"train\\\",\\n    \\\"eval\\\"\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"ExampleValidator\"\n",
      "upstream_nodes: \"SchemaImporter\"\n",
      "upstream_nodes: \"TrainDataGen\"\n",
      "downstream_nodes: \"ModelTrainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "\u001b[32mINFO    \u001b[0m absl:metadata_store.py:105 MetadataStore with DB connection initialized\n",
      "\u001b[32mINFO    \u001b[0m absl:metadata_store.py:105 MetadataStore with DB connection initialized\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:380 Going to run a new execution 9\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:420 Going to run a new execution: ExecutionInfo(execution_id=9, input_dict={'schema': [Artifact(artifact: id: 2\n",
      "type_id: 18\n",
      "uri: \"src/raw_schema\"\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1662853623948\n",
      "last_update_time_since_epoch: 1662853623948\n",
      ", artifact_type: id: 18\n",
      "name: \"Schema\"\n",
      ")], 'examples': [Artifact(artifact: id: 4\n",
      "type_id: 20\n",
      "uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/TrainDataGen/examples/5\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"file_format\"\n",
      "  value {\n",
      "    string_value: \"tfrecords_gzip\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:TrainDataGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:TrainDataGen:examples:0\"\n",
      "create_time_since_epoch: 1662853662190\n",
      "last_update_time_since_epoch: 1662853662190\n",
      ", artifact_type: id: 20\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'pre_transform_schema': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/pre_transform_schema/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:pre_transform_schema:0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:pre_transform_schema:0\"\n",
      ", artifact_type: name: \"Schema\"\n",
      ")], 'post_transform_stats': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/post_transform_stats/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:post_transform_stats:0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:post_transform_stats:0\"\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")], 'post_transform_schema': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/post_transform_schema/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:post_transform_schema:0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:post_transform_schema:0\"\n",
      ", artifact_type: name: \"Schema\"\n",
      ")], 'transformed_examples': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transformed_examples/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:transformed_examples:0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:transformed_examples:0\"\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")], 'post_transform_anomalies': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/post_transform_anomalies/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:post_transform_anomalies:0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:post_transform_anomalies:0\"\n",
      ", artifact_type: name: \"ExampleAnomalies\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")], 'updated_analyzer_cache': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/updated_analyzer_cache/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:updated_analyzer_cache:0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:updated_analyzer_cache:0\"\n",
      ", artifact_type: name: \"TransformCache\"\n",
      ")], 'pre_transform_stats': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/pre_transform_stats/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:pre_transform_stats:0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:pre_transform_stats:0\"\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")], 'transform_graph': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transform_graph/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:transform_graph:0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:transform_graph:0\"\n",
      ", artifact_type: name: \"TransformGraph\"\n",
      ")]}), exec_properties={'force_tf_compat_v1': 1, 'custom_config': 'null', 'splits_config': '{\\n  \"analyze\": [\\n    \"train\"\\n  ],\\n  \"transform\": [\\n    \"train\",\\n    \"eval\"\\n  ]\\n}', 'module_path': 'transformations@gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/_wheels/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl', 'disable_statistics': 0}, execution_output_uri='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/.system/executor_execution/9/executor_output.pb', stateful_working_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/.system/stateful_working_dir/2022-09-10T23:47:00.785303', tmp_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/.system/executor_execution/9/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.transform.component.Transform\"\n",
      "    base_type: TRANSFORM\n",
      "  }\n",
      "  id: \"DataTransformer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.DataTransformer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"TrainDataGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.TrainDataGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaImporter\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.SchemaImporter\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"result\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"post_transform_anomalies\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleAnomalies\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"post_transform_schema\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"post_transform_stats\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          base_type: STATISTICS\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"pre_transform_schema\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"pre_transform_stats\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          base_type: STATISTICS\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"TransformGraph\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"transformed_examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "          base_type: DATASET\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"updated_analyzer_cache\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"TransformCache\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"disable_statistics\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"force_tf_compat_v1\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"transformations@gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/_wheels/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"splits_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"analyze\\\": [\\n    \\\"train\\\"\\n  ],\\n  \\\"transform\\\": [\\n    \\\"train\\\",\\n    \\\"eval\\\"\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"ExampleValidator\"\n",
      "upstream_nodes: \"SchemaImporter\"\n",
      "upstream_nodes: \"TrainDataGen\"\n",
      "downstream_nodes: \"ModelTrainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      ", pipeline_run_id='2022-09-10T23:47:00.785303')\n",
      "\u001b[32mINFO    \u001b[0m absl:dependency_utils.py:67 Attempting to infer TFX Python dependency for beam\n",
      "\u001b[32mINFO    \u001b[0m absl:dependency_utils.py:108 Copying all content from install dir /home/jupyter/.local/lib/python3.7/site-packages/tfx to temp dir /tmp/tmprlpk3vip/build/tfx\n",
      "\u001b[32mINFO    \u001b[0m absl:dependency_utils.py:114 Generating a temp setup file at /tmp/tmprlpk3vip/build/tfx/setup.py\n",
      "\u001b[32mINFO    \u001b[0m absl:dependency_utils.py:127 Creating temporary sdist package, logs available at /tmp/tmprlpk3vip/build/tfx/setup.log\n",
      "\u001b[32mINFO    \u001b[0m absl:dependency_utils.py:70 Added --extra_package=/tmp/tmprlpk3vip/build/tfx/dist/tfx_ephemeral-1.8.0.tar.gz to beam args\n",
      "\u001b[32mINFO    \u001b[0m absl:udf_utils.py:48 udf_utils.get_fn {'module_file': None, 'module_path': 'transformations@gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/_wheels/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl', 'preprocessing_fn': None} 'preprocessing_fn'\n",
      "\u001b[32mINFO    \u001b[0m absl:udf_utils.py:331 Installing '/tmp/tmpbj7d51az/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl' to a temporary directory.\n",
      "\u001b[32mINFO    \u001b[0m absl:udf_utils.py:338 Executing: ['/opt/conda/bin/python', '-m', 'pip', 'install', '--target', '/tmp/tmpeuiwvfza', '/tmp/tmpbj7d51az/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl']\n",
      "\u001b[32mINFO    \u001b[0m absl:udf_utils.py:340 Successfully installed '/tmp/tmpbj7d51az/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl'.\n",
      "\u001b[32mINFO    \u001b[0m absl:udf_utils.py:48 udf_utils.get_fn {'module_file': None, 'module_path': 'transformations@gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/_wheels/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl', 'stats_options_updater_fn': None} 'stats_options_updater_fn'\n",
      "\u001b[32mINFO    \u001b[0m absl:udf_utils.py:331 Installing '/tmp/tmpd0q95g4e/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl' to a temporary directory.\n",
      "\u001b[32mINFO    \u001b[0m absl:udf_utils.py:338 Executing: ['/opt/conda/bin/python', '-m', 'pip', 'install', '--target', '/tmp/tmpwig7yys8', '/tmp/tmpd0q95g4e/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl']\n",
      "\u001b[32mINFO    \u001b[0m absl:udf_utils.py:340 Successfully installed '/tmp/tmpd0q95g4e/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl'.\n",
      "\u001b[32mINFO    \u001b[0m absl:udf_utils.py:331 Installing '/tmp/tmpxvxjvil2/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl' to a temporary directory.\n",
      "\u001b[32mINFO    \u001b[0m absl:udf_utils.py:338 Executing: ['/opt/conda/bin/python', '-m', 'pip', 'install', '--target', '/tmp/tmp2jyh_uvw', '/tmp/tmpxvxjvil2/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl']\n",
      "\u001b[32mINFO    \u001b[0m absl:udf_utils.py:340 Successfully installed '/tmp/tmpxvxjvil2/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl'.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:deprecation.py:343 From /home/jupyter/.local/lib/python3.7/site-packages/tensorflow_transform/tf_utils.py:326: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[33mWARNING \u001b[0m root:decorators.py:371 This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[str, Union[NoneType, _Dataset]], Union[Dict[str, Dict[str, PCollection]], NoneType], int] instead.\n",
      "\u001b[33mWARNING \u001b[0m root:decorators.py:371 This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[str, Union[NoneType, _Dataset]], Union[Dict[str, Dict[str, PCollection]], NoneType], int] instead.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.03173947334289551 seconds.\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:impl.py:427 Tensorflow version (2.8.2) found. However Tensorflow Transform is running in tf.compat.v1 mode. This could be either because TF2 was disabled or `Context.force_tf_compat_v1=True`. Features such as tf.function may not work as intended. \n",
      "\u001b[33mWARNING \u001b[0m tensorflow:deprecation.py:343 From /opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:204: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:builder_impl.py:669 Assets added to graph.\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:builder_impl.py:463 No assets to write.\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:meta_graph.py:442 Issue encountered when serializing tft_mapper_use.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Counter' object has no attribute 'name'\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:meta_graph.py:442 Issue encountered when serializing tft_vocabulary_size_by_name_collection.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'tuple' object has no attribute 'name'\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:builder_impl.py:428 SavedModel written to: gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transform_graph/9/.temp_path/tftransform_tmp/6af83b9f3dd949899a38fa2794e28945/saved_model.pb\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:builder_impl.py:669 Assets added to graph.\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:builder_impl.py:463 No assets to write.\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:meta_graph.py:442 Issue encountered when serializing tft_mapper_use.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Counter' object has no attribute 'name'\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:meta_graph.py:442 Issue encountered when serializing tft_vocabulary_size_by_name_collection.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'tuple' object has no attribute 'name'\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:builder_impl.py:428 SavedModel written to: gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transform_graph/9/.temp_path/tftransform_tmp/abf82edf09df42fcae449e83f04ee853/saved_model.pb\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.03489089012145996 seconds.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:impl.py:427 Tensorflow version (2.8.2) found. However Tensorflow Transform is running in tf.compat.v1 mode. This could be either because TF2 was disabled or `Context.force_tf_compat_v1=True`. Features such as tf.function may not work as intended. \n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.043512582778930664 seconds.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[32mINFO    \u001b[0m absl:tensor_representation_util.py:347 Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:impl.py:427 Tensorflow version (2.8.2) found. However Tensorflow Transform is running in tf.compat.v1 mode. This could be either because TF2 was disabled or `Context.force_tf_compat_v1=True`. Features such as tf.function may not work as intended. \n",
      "\u001b[33mWARNING \u001b[0m root:environments.py:374 Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n",
      "\u001b[32mINFO    \u001b[0m root:environments.py:380 Default Python SDK image for environment is apache/beam_python3.7_sdk:2.39.0\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function annotate_downstream_side_inputs at 0x7f48d14ee5f0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function fix_side_input_pcoll_coders at 0x7f48d14ee710> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function pack_combiners at 0x7f48d14eec20> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function lift_combiners at 0x7f48d14eecb0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function expand_sdf at 0x7f48d14eee60> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function expand_gbk at 0x7f48d14eeef0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function sink_flattens at 0x7f48d14ef050> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function greedily_fuse at 0x7f48d14ef0e0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function read_to_impulse at 0x7f48d14ef170> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function impulse_to_input at 0x7f48d14ef200> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function sort_stages at 0x7f48d14ef440> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function add_impulse_to_dangling_transforms at 0x7f48d14ef560> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function setup_timer_mapping at 0x7f48d14ef3b0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function populate_data_channel_coders at 0x7f48d14ef4d0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.worker.statecache:statecache.py:172 Creating state cache with size 100\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.worker_handlers:worker_handlers.py:894 Created Worker handler <apache_beam.runners.portability.fn_api_runner.worker_handlers.EmbeddedWorkerHandler object at 0x7f48ccb29a90> for environment ref_Environment_default_environment_1 (beam:env:embedded_python:v1, b'')\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.036908864974975586 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.03158259391784668 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.039559125900268555 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.03606438636779785 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.03939652442932129 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.039464712142944336 seconds.\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:saved_transform_io.py:166 struct2tensor is not available.\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:saved_transform_io.py:166 tensorflow_decision_forests is not available.\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:saved_transform_io.py:166 tensorflow_text is not available.\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:saver.py:1617 Saver not created because there are no variables in the graph to restore\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.03729748725891113 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.20 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.04367327690124512 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.20 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.036072492599487305 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.036774396896362305 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.03928351402282715 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.026566743850708008 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.04478764533996582 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.03420543670654297 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.032756805419921875 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.03750157356262207 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.040021419525146484 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.03999185562133789 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.20 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.03941512107849121 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.034501075744628906 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.20 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.03462553024291992 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.04417896270751953 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.20 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.0374302864074707 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.038400888442993164 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.20 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.03315424919128418 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.036769866943359375 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.20 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.03467988967895508 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.04660153388977051 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.20 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.03742170333862305 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.03423714637756348 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.20 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.037746429443359375 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.034739017486572266 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.20 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.030169963836669922 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.20 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.042162179946899414 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.02952265739440918 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.03178215026855469 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.03750443458557129 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.20 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.03923463821411133 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.30 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.03898334503173828 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.20 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.03101325035095215 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.20 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.03961515426635742 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.20 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.0322566032409668 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.20 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.04391908645629883 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.20 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.039785146713256836 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.03528785705566406 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.20 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.034070730209350586 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.03702592849731445 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.20 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.03626680374145508 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.028893470764160156 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.20 seconds.\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:saved_transform_io.py:166 struct2tensor is not available.\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:saved_transform_io.py:166 tensorflow_decision_forests is not available.\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:saved_transform_io.py:166 tensorflow_text is not available.\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:saver.py:1617 Saver not created because there are no variables in the graph to restore\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:builder_impl.py:669 Assets added to graph.\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:builder_impl.py:780 Assets written to: gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transform_graph/9/.temp_path/tftransform_tmp/3829c0b4703d4d1bb1e8a520ccf7f44c/assets\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:builder_impl.py:428 SavedModel written to: gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transform_graph/9/.temp_path/tftransform_tmp/3829c0b4703d4d1bb1e8a520ccf7f44c/saved_model.pb\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:saved_transform_io.py:166 struct2tensor is not available.\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:saved_transform_io.py:166 tensorflow_decision_forests is not available.\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:saved_transform_io.py:166 tensorflow_text is not available.\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:ops.py:7040 Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_4:0\\022\\ntrip_month\"\n",
      "\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:ops.py:7040 Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_7:0\\022\\010trip_day\"\n",
      "\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:ops.py:7040 Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_10:0\\022\\020trip_day_of_week\"\n",
      "\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:ops.py:7040 Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_13:0\\022\\ttrip_hour\"\n",
      "\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:ops.py:7040 Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_16:0\\022\\014payment_type\"\n",
      "\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:ops.py:7040 Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_19:0\\022\\013pickup_grid\"\n",
      "\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:ops.py:7040 Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_22:0\\022\\014dropoff_grid\"\n",
      "\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:ops.py:7040 Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_25:0\\022\\tloc_cross\"\n",
      "\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:saver.py:1617 Saver not created because there are no variables in the graph to restore\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.03582358360290527 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.20 seconds.\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:saved_transform_io.py:166 struct2tensor is not available.\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:saved_transform_io.py:166 tensorflow_decision_forests is not available.\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:saved_transform_io.py:166 tensorflow_text is not available.\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:ops.py:7040 Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_4:0\\022\\ntrip_month\"\n",
      "\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:ops.py:7040 Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_7:0\\022\\010trip_day\"\n",
      "\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:ops.py:7040 Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_10:0\\022\\020trip_day_of_week\"\n",
      "\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:ops.py:7040 Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_13:0\\022\\ttrip_hour\"\n",
      "\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:ops.py:7040 Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_16:0\\022\\014payment_type\"\n",
      "\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:ops.py:7040 Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_19:0\\022\\013pickup_grid\"\n",
      "\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:ops.py:7040 Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_22:0\\022\\014dropoff_grid\"\n",
      "\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:ops.py:7040 Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_25:0\\022\\tloc_cross\"\n",
      "\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:saver.py:1617 Saver not created because there are no variables in the graph to restore\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:saved_transform_io.py:166 struct2tensor is not available.\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:saved_transform_io.py:166 tensorflow_decision_forests is not available.\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:saved_transform_io.py:166 tensorflow_text is not available.\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:ops.py:7040 Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_4:0\\022\\ntrip_month\"\n",
      "\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:ops.py:7040 Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_7:0\\022\\010trip_day\"\n",
      "\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:ops.py:7040 Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_10:0\\022\\020trip_day_of_week\"\n",
      "\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:ops.py:7040 Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_13:0\\022\\ttrip_hour\"\n",
      "\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:ops.py:7040 Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_16:0\\022\\014payment_type\"\n",
      "\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:ops.py:7040 Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_19:0\\022\\013pickup_grid\"\n",
      "\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:ops.py:7040 Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_22:0\\022\\014dropoff_grid\"\n",
      "\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:ops.py:7040 Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\014\\n\\nConst_25:0\\022\\tloc_cross\"\n",
      "\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:saver.py:1617 Saver not created because there are no variables in the graph to restore\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.032745361328125 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.041396379470825195 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.036142826080322266 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.03240799903869629 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.20 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.042412519454956055 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 0 files in 0.04018235206604004 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.20 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.0328981876373291 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.20 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.0379183292388916 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:303 Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.filebasedsink:filebasedsink.py:348 Renamed 1 shards in 0.30 seconds.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:467 Cleaning up stateless execution info.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:562 Execution 9 succeeded.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:481 Cleaning up stateful execution info.\n",
      "\u001b[33mWARNING \u001b[0m absl:outputs_utils.py:95 stateful_working_dir /home/jupyter/mlops-with-vertex-ai/gs:/gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/.system/stateful_working_dir is not found, not going to delete it.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:573 Publishing output artifacts defaultdict(<class 'list'>, {'pre_transform_schema': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/pre_transform_schema/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:pre_transform_schema:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:pre_transform_schema:0\"\n",
      ", artifact_type: name: \"Schema\"\n",
      ")], 'post_transform_stats': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/post_transform_stats/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:post_transform_stats:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:post_transform_stats:0\"\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")], 'post_transform_schema': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/post_transform_schema/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:post_transform_schema:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:post_transform_schema:0\"\n",
      ", artifact_type: name: \"Schema\"\n",
      ")], 'transformed_examples': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transformed_examples/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:transformed_examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:transformed_examples:0\"\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")], 'post_transform_anomalies': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/post_transform_anomalies/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:post_transform_anomalies:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:post_transform_anomalies:0\"\n",
      ", artifact_type: name: \"ExampleAnomalies\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")], 'updated_analyzer_cache': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/updated_analyzer_cache/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:updated_analyzer_cache:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:updated_analyzer_cache:0\"\n",
      ", artifact_type: name: \"TransformCache\"\n",
      ")], 'pre_transform_stats': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/pre_transform_stats/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:pre_transform_stats:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:pre_transform_stats:0\"\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")], 'transform_graph': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transform_graph/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:transform_graph:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:transform_graph:0\"\n",
      ", artifact_type: name: \"TransformGraph\"\n",
      ")]}) for execution 9\n",
      "\u001b[32mINFO    \u001b[0m absl:metadata_store.py:105 MetadataStore with DB connection initialized\n",
      "\u001b[32mINFO    \u001b[0m absl:local_dag_runner.py:110 Component DataTransformer is finished.\n",
      "\u001b[32mINFO    \u001b[0m absl:local_dag_runner.py:105 Component ModelTrainer is running.\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:519 Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.trainer.component.Trainer\"\n",
      "    base_type: TRAIN\n",
      "  }\n",
      "  id: \"ModelTrainer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.ModelTrainer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"base_model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"WarmstartModelResolver\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.WarmstartModelResolver\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"latest_model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"DataTransformer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.DataTransformer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transformed_examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"hyperparameters\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"HyperparamsGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.HyperparamsGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"HyperParameters\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"hyperparameters\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaImporter\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.SchemaImporter\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"result\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"DataTransformer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.DataTransformer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"TransformGraph\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transform_graph\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Model\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"model_run\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelRun\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"eval_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"runner@gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/_wheels/tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"train_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"DataTransformer\"\n",
      "upstream_nodes: \"HyperparamsGen\"\n",
      "upstream_nodes: \"SchemaImporter\"\n",
      "upstream_nodes: \"WarmstartModelResolver\"\n",
      "downstream_nodes: \"ModelEvaluator\"\n",
      "downstream_nodes: \"ModelPusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "\u001b[32mINFO    \u001b[0m absl:metadata_store.py:105 MetadataStore with DB connection initialized\n",
      "\u001b[33mWARNING \u001b[0m absl:inputs_utils.py:60 Artifact type Model is not found in MLMD.\n",
      "\u001b[32mINFO    \u001b[0m absl:metadata_store.py:105 MetadataStore with DB connection initialized\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:380 Going to run a new execution 10\n",
      "\u001b[32mINFO    \u001b[0m absl:launcher.py:420 Going to run a new execution: ExecutionInfo(execution_id=10, input_dict={'schema': [Artifact(artifact: id: 2\n",
      "type_id: 18\n",
      "uri: \"src/raw_schema\"\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1662853623948\n",
      "last_update_time_since_epoch: 1662853623948\n",
      ", artifact_type: id: 18\n",
      "name: \"Schema\"\n",
      ")], 'transform_graph': [Artifact(artifact: id: 14\n",
      "type_id: 27\n",
      "uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transform_graph/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:transform_graph:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:transform_graph:0\"\n",
      "create_time_since_epoch: 1662853754259\n",
      "last_update_time_since_epoch: 1662853754259\n",
      ", artifact_type: id: 27\n",
      "name: \"TransformGraph\"\n",
      ")], 'examples': [Artifact(artifact: id: 10\n",
      "type_id: 20\n",
      "uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transformed_examples/9\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:transformed_examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:DataTransformer:transformed_examples:0\"\n",
      "create_time_since_epoch: 1662853754258\n",
      "last_update_time_since_epoch: 1662853754258\n",
      ", artifact_type: id: 20\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")], 'hyperparameters': [Artifact(artifact: id: 1\n",
      "type_id: 16\n",
      "uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/HyperparamsGen/hyperparameters/2\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:HyperparamsGen:hyperparameters:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:HyperparamsGen:hyperparameters:0\"\n",
      "create_time_since_epoch: 1662853623904\n",
      "last_update_time_since_epoch: 1662853623904\n",
      ", artifact_type: id: 16\n",
      "name: \"HyperParameters\"\n",
      ")], 'base_model': []}, output_dict=defaultdict(<class 'list'>, {'model': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ModelTrainer/model/10\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:ModelTrainer:model:0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:ModelTrainer:model:0\"\n",
      ", artifact_type: name: \"Model\"\n",
      "base_type: MODEL\n",
      ")], 'model_run': [Artifact(artifact: uri: \"gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ModelTrainer/model_run/10\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:ModelTrainer:model_run:0\"\n",
      "  }\n",
      "}\n",
      "name: \"chicago-taxi-tips-classifier-v01-train-pipeline:2022-09-10T23:47:00.785303:ModelTrainer:model_run:0\"\n",
      ", artifact_type: name: \"ModelRun\"\n",
      ")]}), exec_properties={'module_path': 'runner@gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/_wheels/tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8-py3-none-any.whl', 'train_args': '{}', 'custom_config': 'null', 'eval_args': '{}'}, execution_output_uri='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ModelTrainer/.system/executor_execution/10/executor_output.pb', stateful_working_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ModelTrainer/.system/stateful_working_dir/2022-09-10T23:47:00.785303', tmp_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ModelTrainer/.system/executor_execution/10/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.trainer.component.Trainer\"\n",
      "    base_type: TRAIN\n",
      "  }\n",
      "  id: \"ModelTrainer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-09-10T23:47:00.785303\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.ModelTrainer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"base_model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"WarmstartModelResolver\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.WarmstartModelResolver\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"latest_model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"DataTransformer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.DataTransformer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transformed_examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"hyperparameters\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"HyperparamsGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.HyperparamsGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"HyperParameters\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"hyperparameters\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaImporter\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.SchemaImporter\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"result\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"DataTransformer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-09-10T23:47:00.785303\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v01-train-pipeline.DataTransformer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"TransformGraph\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transform_graph\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Model\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"model_run\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelRun\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"eval_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"runner@gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/_wheels/tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"train_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"DataTransformer\"\n",
      "upstream_nodes: \"HyperparamsGen\"\n",
      "upstream_nodes: \"SchemaImporter\"\n",
      "upstream_nodes: \"WarmstartModelResolver\"\n",
      "downstream_nodes: \"ModelEvaluator\"\n",
      "downstream_nodes: \"ModelPusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"chicago-taxi-tips-classifier-v01-train-pipeline\"\n",
      ", pipeline_run_id='2022-09-10T23:47:00.785303')\n",
      "\u001b[32mINFO    \u001b[0m absl:fn_args_utils.py:134 Train on the 'train' split when train_args.splits is not set.\n",
      "\u001b[32mINFO    \u001b[0m absl:fn_args_utils.py:138 Evaluate on the 'eval' split when eval_args.splits is not set.\n",
      "\u001b[33mWARNING \u001b[0m absl:examples_utils.py:50 Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "\u001b[33mWARNING \u001b[0m absl:examples_utils.py:50 Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "\u001b[33mWARNING \u001b[0m absl:examples_utils.py:50 Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "\u001b[32mINFO    \u001b[0m absl:udf_utils.py:48 udf_utils.get_fn {'module_path': 'runner@gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/_wheels/tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8-py3-none-any.whl', 'train_args': '{}', 'custom_config': 'null', 'eval_args': '{}'} 'run_fn'\n",
      "\u001b[32mINFO    \u001b[0m absl:udf_utils.py:331 Installing '/tmp/tmpw3m7g_fg/tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8-py3-none-any.whl' to a temporary directory.\n",
      "\u001b[32mINFO    \u001b[0m absl:udf_utils.py:338 Executing: ['/opt/conda/bin/python', '-m', 'pip', 'install', '--target', '/tmp/tmp9g2lgp7z', '/tmp/tmpw3m7g_fg/tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8-py3-none-any.whl']\n",
      "\u001b[32mINFO    \u001b[0m absl:udf_utils.py:340 Successfully installed '/tmp/tmpw3m7g_fg/tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8-py3-none-any.whl'.\n",
      "\u001b[32mINFO    \u001b[0m absl:executor.py:177 Training model.\n",
      "\u001b[32mINFO    \u001b[0m root:runner.py:28 Runner started...\n",
      "\u001b[32mINFO    \u001b[0m root:runner.py:29 fn_args: FnArgs(working_dir=None, train_files=['gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transformed_examples/9/Split-train/*'], eval_files=['gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transformed_examples/9/Split-eval/*'], train_steps=None, eval_steps=None, schema_path='src/raw_schema/schema.pbtxt', schema_file='src/raw_schema/schema.pbtxt', transform_graph_path='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transform_graph/9', transform_output='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transform_graph/9', data_accessor=DataAccessor(tf_dataset_factory=<function get_tf_dataset_factory_from_artifact.<locals>.dataset_factory at 0x7f48750167a0>, record_batch_factory=<function get_record_batch_factory_from_artifact.<locals>.record_batch_factory at 0x7f487607ef80>, data_view_decode_fn=None), serving_model_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ModelTrainer/model/10/Format-Serving', eval_model_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ModelTrainer/model/10/Format-TFMA', model_run_dir='gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ModelTrainer/model_run/10', base_model=None, hyperparameters={'num_epochs': 1, 'batch_size': 512, 'learning_rate': 0.001, 'hidden_units': [128, 128]}, custom_config=None)\n",
      "\u001b[32mINFO    \u001b[0m root:runner.py:30 \n",
      "\u001b[32mINFO    \u001b[0m root:runner.py:42 Hyperparameter:\n",
      "\u001b[32mINFO    \u001b[0m root:runner.py:43 {'num_epochs': 1, 'batch_size': 512, 'learning_rate': 0.001, 'hidden_units': [128, 128]}\n",
      "\u001b[32mINFO    \u001b[0m root:runner.py:44 \n",
      "\u001b[32mINFO    \u001b[0m root:runner.py:46 Runner executing trainer...\n",
      "\u001b[32mINFO    \u001b[0m root:trainer.py:34 Loading tft output from gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/DataTransformer/transform_graph/9\n",
      "\u001b[32mINFO    \u001b[0m root:trainer.py:68 Model training started...\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:callbacks.py:1887 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "\u001b[32mINFO    \u001b[0m root:trainer.py:75 Model training completed.\n",
      "\u001b[32mINFO    \u001b[0m root:runner.py:56 Runner executing exporter...\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:saver.py:1617 Saver not created because there are no variables in the graph to restore\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:saved_transform_io.py:166 struct2tensor is not available.\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:saved_transform_io.py:166 tensorflow_decision_forests is not available.\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:saved_transform_io.py:166 tensorflow_text is not available.\n",
      "\u001b[32mINFO    \u001b[0m root:exporter.py:98 Model export started...\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:builder_impl.py:780 Assets written to: gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ModelTrainer/model/10/Format-Serving/assets\n",
      "\u001b[32mINFO    \u001b[0m root:exporter.py:100 Model export completed.\n",
      "\u001b[32mINFO    \u001b[0m root:runner.py:63 Runner completed.\n",
      "\u001b[33mWARNING \u001b[0m absl:outputs_utils.py:95 stateful_working_dir /home/jupyter/mlops-with-vertex-ai/gs:/gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v01-train-pipeline/ModelTrainer/.system/stateful_working_dir is not found, not going to delete it.\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:base.py:360 Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7f48755fb910> and <keras.engine.input_layer.InputLayer object at 0x7f48c44be7d0>).\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.03341841697692871 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.Sequence[typing.MutableMapping[str, typing.Any]]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.Sequence[typing.MutableMapping[str, typing.Any]]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.Sequence[typing.MutableMapping[str, typing.Any]]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.Sequence[typing.MutableMapping[str, typing.Any]]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.Sequence[typing.MutableMapping[str, typing.Any]]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.Sequence[typing.MutableMapping[str, typing.Any]]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.Sequence[typing.MutableMapping[str, typing.Any]]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.Sequence[typing.MutableMapping[str, typing.Any]]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.Sequence[typing.MutableMapping[str, typing.Any]]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:base.py:360 Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7f4875d42110> and <keras.engine.input_layer.InputLayer object at 0x7f4875dcc6d0>).\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.Type[typing.Union[tensorflow_model_analysis.metrics.metric_types.MetricKey, tensorflow_model_analysis.metrics.metric_types.PlotKey, tensorflow_model_analysis.metrics.metric_types.AttributionsKey]]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.Type[typing.Union[tensorflow_model_analysis.metrics.metric_types.MetricKey, tensorflow_model_analysis.metrics.metric_types.PlotKey, tensorflow_model_analysis.metrics.metric_types.AttributionsKey]]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.Type[typing.Union[tensorflow_model_analysis.metrics.metric_types.MetricKey, tensorflow_model_analysis.metrics.metric_types.PlotKey, tensorflow_model_analysis.metrics.metric_types.AttributionsKey]]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.Callable[[typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, typing.Dict[str, typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor]]], typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, typing.Dict[str, typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor]]], typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, typing.Dict[str, typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor]]]], typing.Dict[str, typing.Tuple[typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor], typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor]]]]\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.typehints.native_type_compatibility:native_type_compatibility.py:248 Using Any for unsupported type: typing.Callable[[typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, typing.Dict[str, typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor]]], typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, typing.Dict[str, typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor]]], typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, typing.Dict[str, typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor]]]], typing.Dict[str, typing.Tuple[typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor], typing.Union[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor]]]]\n",
      "\u001b[33mWARNING \u001b[0m root:environments.py:374 Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n",
      "\u001b[32mINFO    \u001b[0m root:environments.py:380 Default Python SDK image for environment is apache/beam_python3.7_sdk:2.39.0\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function annotate_downstream_side_inputs at 0x7f48d14ee5f0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function fix_side_input_pcoll_coders at 0x7f48d14ee710> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function pack_combiners at 0x7f48d14eec20> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function lift_combiners at 0x7f48d14eecb0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function expand_sdf at 0x7f48d14eee60> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function expand_gbk at 0x7f48d14eeef0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function sink_flattens at 0x7f48d14ef050> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function greedily_fuse at 0x7f48d14ef0e0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function read_to_impulse at 0x7f48d14ef170> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function impulse_to_input at 0x7f48d14ef200> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function sort_stages at 0x7f48d14ef440> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function add_impulse_to_dangling_transforms at 0x7f48d14ef560> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function setup_timer_mapping at 0x7f48d14ef3b0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.translations:translations.py:714 ==================== <function populate_data_channel_coders at 0x7f48d14ef4d0> ====================\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.worker.statecache:statecache.py:172 Creating state cache with size 100\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.runners.portability.fn_api_runner.worker_handlers:worker_handlers.py:894 Created Worker handler <apache_beam.runners.portability.fn_api_runner.worker_handlers.EmbeddedWorkerHandler object at 0x7f4875182090> for environment ref_Environment_default_environment_1 (beam:env:embedded_python:v1, b'')\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.03832530975341797 seconds.\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:577 Starting the file information of the input\n",
      "\u001b[32mINFO    \u001b[0m apache_beam.io.gcp.gcsio:gcsio.py:604 Finished listing 1 files in 0.04328656196594238 seconds.\n",
      "\u001b[33mWARNING \u001b[0m tensorflow:base.py:360 Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7f487506fe10> and <keras.engine.input_layer.InputLayer object at 0x7f487503eb90>).\n",
      "\u001b[33mWARNING \u001b[0m absl:model_util.py:756 Large batch_size 36 failed with error Fail to call signature func with signature_name: serving_tf_example.\n",
      "                the inputs are:\n",
      " [b'\\n\\xcc\\x02\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa1\\x1d\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\xd4\\x1a\\x16E\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x85\\xeb\\xd1?\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x04'\n",
      " b'\\n\\xcc\\x02\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00@\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.7 41.9)\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\x94\\x05\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x8b\\xcclE\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x04\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)'\n",
      " b'\\n\\xcc\\x02\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa4\\x03\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x04\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.7 41.9)POINT(-87.7 41.9)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xcc\\xcc>'\n",
      " b'\\n\\xcc\\x02\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.7)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x8b\\x9blE\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xb8\\x1e\\x15@\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x11\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xe2\\x03\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x05\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.7)POINT(-87.6 41.7)\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.7)'\n",
      " b'\\n\\xcc\\x02\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0f\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x05\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\n\\xd7#?\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xd6\\x01\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)'\n",
      " b'\\n\\xc7\\x02\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 42)\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04333?\\n\\x1b\\n\\x0cpayment_type\\x12\\x0b\\n\\t\\n\\x07Dispute\\n/\\n\\tloc_cross\\x12\"\\n \\n\\x1ePOINT(-87.7 42)POINT(-87.7 42)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\xadN\\xcaD\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\"\\n\\x0bpickup_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 42)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa4\\x03'\n",
      " b'\\n\\xc6\\x02\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x1a\\n\\x0cpayment_type\\x12\\n\\n\\x08\\n\\x06Prcard\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa8\\x01\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0f\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n/\\n\\tloc_cross\\x12\"\\n \\n\\x1ePOINT(-87.7 42)POINT(-87.7 42)\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 42)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\"\\n\\x0bpickup_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 42)\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xcc\\x0c?'\n",
      " b'\\n\\xcb\\x02\\n\"\\n\\x0bpickup_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 42)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xa4pqA\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\x8a\\x12\\n\\x1f\\n\\x0cpayment_type\\x12\\x0f\\n\\r\\n\\x0bCredit Card\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\xab\\xa1F\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\n\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.9 42)\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n/\\n\\tloc_cross\\x12\"\\n \\n\\x1ePOINT(-87.7 42)POINT(-87.9 42)'\n",
      " b'\\n\\xc8\\x02\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\xdd7\\xc2F\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\x8d\\x0b\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04ff\\x8aA\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x06\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.9 42)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n1\\n\\tloc_cross\\x12$\\n\"\\n POINT(-87.6 41.9)POINT(-87.9 42)'\n",
      " b'\\n\\xcf\\x02\\n\\x1f\\n\\x0cpayment_type\\x12\\x0f\\n\\r\\n\\x0bCredit Card\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\x98\\x0c\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n1\\n\\tloc_cross\\x12$\\n\"\\n POINT(-87.7 41.9)POINT(-87.7 42)\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.7 42)\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x9a\\x99\\x19?\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\xf4\\xcf\\x1fF\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x12'\n",
      " b'\\n\\xc8\\x02\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xec\\t\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\xb6J\\x93F\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0b\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n1\\n\\tloc_cross\\x12$\\n\"\\n POINT(-87.7 41.9)POINT(-87.9 42)\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x9a\\x99AA\\n#\\n\\x0cdropoff_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.9 42)'\n",
      " b'\\n\\xcf\\x02\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xd1\\x12\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04_C\\xa9F\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\"\\n\\x0bpickup_grid\\x12\\x13\\n\\x11\\n\\x0fPOINT(-87.9 42)\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0e\\n1\\n\\tloc_cross\\x12$\\n\"\\n POINT(-87.9 42)POINT(-87.6 41.9)\\n\\x1f\\n\\x0cpayment_type\\x12\\x0f\\n\\r\\n\\x0bCredit Card\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04{\\x14ZA\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02'\n",
      " b'\\n\\xcf\\x02\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xb0\\t\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.8)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x1b\\n\\x0cpayment_type\\x12\\x0b\\n\\t\\n\\x07Unknown\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x17\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x0f-\\xf7E\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.8)\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.8)POINT(-87.7 41.8)\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xcc4A\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02'\n",
      " b'\\n\\xcc\\x02\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.8)POINT(-87.7 41.9)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\x80\\x1e\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04@\\xf4\\x88E\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0c\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.8)\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00?\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)'\n",
      " b'\\n\\xcc\\x02\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0c\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04}\\x13\\xbeE\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xe1\\x03\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xccl@'\n",
      " b'\\n\\xcc\\x02\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04ff\\xc6?\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04:\\xf14E\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa6\\x03\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0f\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00'\n",
      " b'\\n\\xcc\\x02\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0e\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x9a\\x99\\x99?\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xf8\\x03\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01'\n",
      " b'\\n\\xcc\\x02\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x8f\\xc25?\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xc5\\x02\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x14'\n",
      " b'\\n\\xcc\\x02\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\t\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x04\\x13(D\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xccL?\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xac\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00'\n",
      " b'\\n\\xcc\\x02\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x1f\\x85k?\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\x9f\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\'\\xe4\\x8eD\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)'\n",
      " b'\\n\\xcc\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04333?\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x16\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xf0\\x01\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)'\n",
      " b'\\n\\xcc\\x02\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xf6(\\x1c?\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0f\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x1e\\x95RD\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa2\\x02\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01'\n",
      " b'\\n\\xcc\\x02\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04fff?\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xa4\\x03\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x15\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00'\n",
      " b'\\n\\xcc\\x02\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xac\\x02\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xcc\\x8c?\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x06\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04:\\xf14E'\n",
      " b'\\n\\xcc\\x02\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xf0\\x01\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xcc\\xcc>\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01'\n",
      " b'\\n\\xcb\\x02\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xecQ8>\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0c\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x15\\n\\x0ctrip_seconds\\x12\\x05\\x1a\\x03\\n\\x018'\n",
      " b'\\n\\xcc\\x02\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.6 41.9)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xe0\\x03\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x11\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x9a\\x99\\x99?'\n",
      " b'\\n\\xcc\\x02\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.7 41.9)\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\r\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04ff>A\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xc4\\x0e\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x8b\\xcclE\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)'\n",
      " b'\\n\\xcc\\x02\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04ffv@\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x17\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xb0\\t\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.6 41.9)POINT(-87.7 41.9)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x8b\\xcclE\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)'\n",
      " b'\\n\\xcc\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x14\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xca\\x03\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x8b\\xcclE\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.7 41.9)POINT(-87.6 41.9)\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x9a\\x99\\xb9?\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)'\n",
      " b'\\n\\xcc\\x02\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.7 41.9)POINT(-87.6 41.9)\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xb2\\x03\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x9c\\x9b\\xacD\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04H\\xe1z?'\n",
      " b'\\n\\xce\\x02\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xcc\\x05\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x8b\\xcclE\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x1a\\n\\x0cpayment_type\\x12\\n\\n\\x08\\n\\x06Mobile\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.7 41.9)POINT(-87.6 41.9)\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0f\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x8f\\xc25@'\n",
      " b'\\n\\xcc\\x02\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0e\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.7 41.9)POINT(-87.6 41.9)\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04#\\xca\\xa5E\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xccL>\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\x94\\x05'\n",
      " b'\\n\\xd3\\x02\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.7 41.9)POINT(-87.6 41.9)\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00 @\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x8b\\xcclE\\n\\x1f\\n\\x0cpayment_type\\x12\\x0f\\n\\r\\n\\x0bCredit Card\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x12\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\xf9\\x08\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.9)'\n",
      " b'\\n\\xcc\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.7 41.9)POINT(-87.7 41.9)\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\x8c\\x06\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04^\\xde\\xc0E\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04ff\\xb6@\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.7 41.9)\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x05'\n",
      " b'\\n\\xcc\\x02\\n\\x15\\n\\teuclidean\\x12\\x08\\x12\\x06\\n\\x04\\x15\\x11PF\\n\\x18\\n\\x0cpayment_type\\x12\\x08\\n\\x06\\n\\x04Cash\\n\\x13\\n\\ntrip_month\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x10\\n\\x07tip_bin\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08trip_day\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n%\\n\\x0cdropoff_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.6 41.8)\\n$\\n\\x0bpickup_grid\\x12\\x15\\n\\x13\\n\\x11POINT(-87.8 41.8)\\n3\\n\\tloc_cross\\x12&\\n$\\n\"POINT(-87.8 41.8)POINT(-87.6 41.8)\\n\\x12\\n\\ttrip_hour\\x12\\x05\\x1a\\x03\\n\\x01\\x0f\\n\\x16\\n\\x0ctrip_seconds\\x12\\x06\\x1a\\x04\\n\\x02\\x90\\r\\n\\x16\\n\\ntrip_miles\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xcc\\\\A\\n\\x19\\n\\x10trip_day_of_week\\x12\\x05\\x1a\\x03\\n\\x01\\x07'].\n",
      "                The input_specs are:\n",
      " {'examples': TensorSpec(shape=(None,), dtype=tf.string, name='examples')}.. Attempting to run batch through serially. Note that this will significantly affect the performance.\n",
      "\u001b[1m\u001b[31mERROR   \u001b[0m absl:launcher.py:555 Execution 11 failed.\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      "../../../opt/conda/lib/python3.7/site-packages/flatbuffers/compat.py:19\n",
      "  /opt/conda/lib/python3.7/site-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "    import imp\n",
      "\n",
      "../../../opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:23\n",
      "  /opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:23: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "    'nearest': pil_image.NEAREST,\n",
      "\n",
      "../../../opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:24\n",
      "  /opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:24: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "    'bilinear': pil_image.BILINEAR,\n",
      "\n",
      "../../../opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:25\n",
      "  /opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:25: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "    'bicubic': pil_image.BICUBIC,\n",
      "\n",
      "../../../opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:28\n",
      "  /opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:28: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.\n",
      "    if hasattr(pil_image, 'HAMMING'):\n",
      "\n",
      "../../../opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:29\n",
      "  /opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:29: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.\n",
      "    _PIL_INTERPOLATION_METHODS['hamming'] = pil_image.HAMMING\n",
      "\n",
      "../../../opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:30\n",
      "  /opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:30: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "    if hasattr(pil_image, 'BOX'):\n",
      "\n",
      "../../../opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:31\n",
      "  /opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:31: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "    _PIL_INTERPOLATION_METHODS['box'] = pil_image.BOX\n",
      "\n",
      "../../../opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:33\n",
      "  /opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:33: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "    if hasattr(pil_image, 'LANCZOS'):\n",
      "\n",
      "../../../opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:34\n",
      "  /opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:34: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "    _PIL_INTERPOLATION_METHODS['lanczos'] = pil_image.LANCZOS\n",
      "\n",
      "src/tests/pipeline_deployment_tests.py::test_e2e_pipeline\n",
      "src/tests/pipeline_deployment_tests.py::test_e2e_pipeline\n",
      "  /opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery.py:2471: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "    temp_location = pcoll.pipeline.options.view_as(\n",
      "\n",
      "src/tests/pipeline_deployment_tests.py::test_e2e_pipeline\n",
      "src/tests/pipeline_deployment_tests.py::test_e2e_pipeline\n",
      "  /opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery.py:2473: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "    job_name = pcoll.pipeline.options.view_as(GoogleCloudOptions).job_name\n",
      "\n",
      "src/tests/pipeline_deployment_tests.py::test_e2e_pipeline\n",
      "src/tests/pipeline_deployment_tests.py::test_e2e_pipeline\n",
      "  /opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery.py:2504: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "    | _PassThroughThenCleanup(files_to_remove_pcoll))\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "=========================== short test summary info ============================\n",
      "FAILED src/tests/pipeline_deployment_tests.py::test_e2e_pipeline - ValueError...\n",
      "\u001b[31m================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m16 warnings\u001b[0m\u001b[31m in 193.81s (0:03:13)\u001b[0m\u001b[31m ==================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest src/tests/pipeline_deployment_tests.py::test_e2e_pipeline -s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5704bcb",
   "metadata": {},
   "source": [
    "## 2. Run the training pipeline using Vertex Pipelines\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d7db74",
   "metadata": {},
   "source": [
    "### Set the pipeline configurations for the Vertex AI run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e2fe69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"DATASET_DISPLAY_NAME\"] = DATASET_DISPLAY_NAME\n",
    "os.environ[\"MODEL_DISPLAY_NAME\"] = MODEL_DISPLAY_NAME\n",
    "os.environ[\"PIPELINE_NAME\"] = PIPELINE_NAME\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"REGION\"] = REGION\n",
    "os.environ[\"GCS_LOCATION\"] = f\"gs://{BUCKET}/{DATASET_DISPLAY_NAME}\"\n",
    "os.environ[\"TRAIN_LIMIT\"] = \"85000\"\n",
    "os.environ[\"TEST_LIMIT\"] = \"15000\"\n",
    "os.environ[\"BEAM_RUNNER\"] = \"DataflowRunner\"\n",
    "os.environ[\"TRAINING_RUNNER\"] = \"vertex\"\n",
    "os.environ[\"TFX_IMAGE_URI\"] = f\"gcr.io/{PROJECT}/{DATASET_DISPLAY_NAME}:{VERSION}\"\n",
    "os.environ[\"ENABLE_CACHE\"] = \"1\"\n",
    "\n",
    "# Debug\n",
    "os.environ[\"SERVING_RUNTIME\"] = \"tf2-cpu.2-8\"\n",
    "# os.environ[\"UPLOAD_MODEL\"] = \"1\" # # testing purposes: why was this missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d83ef31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT: mwpmltr\n",
      "REGION: us-central1\n",
      "GCS_LOCATION: gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips\n",
      "ARTIFACT_STORE_URI: gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/tfx_artifacts\n",
      "MODEL_REGISTRY_URI: gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/e2e_tests/model_registry\n",
      "DATASET_DISPLAY_NAME: chicago-taxi-tips\n",
      "MODEL_DISPLAY_NAME: chicago-taxi-tips-classifier-v01\n",
      "PIPELINE_NAME: chicago-taxi-tips-classifier-v01-train-pipeline\n",
      "ML_USE_COLUMN: ml_use\n",
      "EXCLUDE_COLUMNS: trip_start_timestamp\n",
      "TRAIN_LIMIT: 85000\n",
      "TEST_LIMIT: 15000\n",
      "SERVE_LIMIT: 0\n",
      "NUM_TRAIN_SPLITS: 4\n",
      "NUM_EVAL_SPLITS: 1\n",
      "ACCURACY_THRESHOLD: 0.1\n",
      "USE_KFP_SA: False\n",
      "TFX_IMAGE_URI: gcr.io/mwpmltr/chicago-taxi-tips:v01\n",
      "BEAM_RUNNER: DataflowRunner\n",
      "BEAM_DIRECT_PIPELINE_ARGS: ['--project=mwpmltr', '--temp_location=gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/temp']\n",
      "BEAM_DATAFLOW_PIPELINE_ARGS: ['--project=mwpmltr', '--temp_location=gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/temp', '--region=us-central1', '--runner=DataflowRunner']\n",
      "TRAINING_RUNNER: vertex\n",
      "VERTEX_TRAINING_ARGS: {'project': 'mwpmltr', 'worker_pool_specs': [{'machine_spec': {'machine_type': 'n1-standard-4'}, 'replica_count': 1, 'container_spec': {'image_uri': 'gcr.io/mwpmltr/chicago-taxi-tips:v01'}}]}\n",
      "VERTEX_TRAINING_CONFIG: {'ai_platform_training_enable_ucaip': True, 'ai_platform_training_ucaip_region': 'us-central1', 'ai_platform_training_args': {'project': 'mwpmltr', 'worker_pool_specs': [{'machine_spec': {'machine_type': 'n1-standard-4'}, 'replica_count': 1, 'container_spec': {'image_uri': 'gcr.io/mwpmltr/chicago-taxi-tips:v01'}}]}, 'use_gpu': False}\n",
      "SERVING_RUNTIME: tf2-cpu.2-8\n",
      "SERVING_IMAGE_URI: us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-8:latest\n",
      "BATCH_PREDICTION_BQ_DATASET_NAME: playground_us\n",
      "BATCH_PREDICTION_BQ_TABLE_NAME: chicago_taxitrips_prep\n",
      "BATCH_PREDICTION_BEAM_ARGS: {'runner': 'DataflowRunner', 'temporary_dir': 'gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/temp', 'gcs_location': 'gs://gcp-certification-chicago-taxi-demo/chicago-taxi-tips/temp', 'project': 'mwpmltr', 'region': 'us-central1', 'setup_file': './setup.py'}\n",
      "BATCH_PREDICTION_JOB_RESOURCES: {'machine_type': 'n1-standard-2', 'starting_replica_count': 1, 'max_replica_count': 10}\n",
      "DATASTORE_PREDICTION_KIND: chicago-taxi-tips-classifier-v01-predictions\n",
      "ENABLE_CACHE: 1\n",
      "UPLOAD_MODEL: 0\n"
     ]
    }
   ],
   "source": [
    "from src.tfx_pipelines import config\n",
    "import importlib\n",
    "importlib.reload(config)\n",
    "\n",
    "for key, value in config.__dict__.items():\n",
    "    if key.isupper(): print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f3164f",
   "metadata": {},
   "source": [
    "### Build the ML container image\n",
    "\n",
    "This is the `TFX` runtime environment for the training pipeline steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a0e729b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcr.io/mwpmltr/chicago-taxi-tips:v01\n"
     ]
    }
   ],
   "source": [
    "!echo $TFX_IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3087da4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 59 file(s) totalling 1.5 MiB before compression.\n",
      "Some files were not included in the source upload.\n",
      "\n",
      "Check the gcloud log [/home/jupyter/.config/gcloud/logs/2022.09.10/23.49.59.476470.log] to see which files and the contents of the\n",
      "default gcloudignore file used (see `$ gcloud topic gcloudignore` to learn\n",
      "more).\n",
      "\n",
      "Uploading tarball of [.] to [gs://mwpmltr_cloudbuild/source/1662853799.572005-91114e838bc44ba690f6da0299d3603c.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/mwpmltr/locations/global/builds/bea39746-48aa-4fde-8d02-21d26022dfba].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/bea39746-48aa-4fde-8d02-21d26022dfba?project=55590906972].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"bea39746-48aa-4fde-8d02-21d26022dfba\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://mwpmltr_cloudbuild/source/1662853799.572005-91114e838bc44ba690f6da0299d3603c.tgz#1662853800133539\n",
      "Copying gs://mwpmltr_cloudbuild/source/1662853799.572005-91114e838bc44ba690f6da0299d3603c.tgz#1662853800133539...\n",
      "/ [1 files][331.7 KiB/331.7 KiB]                                                \n",
      "Operation completed over 1 objects/331.7 KiB.                                    \n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  1.636MB\n",
      "Step 1/5 : FROM gcr.io/tfx-oss-public/tfx:1.8.0\n",
      "1.8.0: Pulling from tfx-oss-public/tfx\n",
      "d5fd17ec1767: Pulling fs layer\n",
      "086b79b77a03: Pulling fs layer\n",
      "4698168f5888: Pulling fs layer\n",
      "86de3d566666: Pulling fs layer\n",
      "30d00d530989: Pulling fs layer\n",
      "69a2bfee9a44: Pulling fs layer\n",
      "381964195b8b: Pulling fs layer\n",
      "fe1468e51d2b: Pulling fs layer\n",
      "e807ad87032f: Pulling fs layer\n",
      "0c557f25f33e: Pulling fs layer\n",
      "67cab7d11474: Pulling fs layer\n",
      "4f4fb700ef54: Pulling fs layer\n",
      "999747c8e1ca: Pulling fs layer\n",
      "e92bc58784f1: Pulling fs layer\n",
      "a9d25440a572: Pulling fs layer\n",
      "ee75ae25ade1: Pulling fs layer\n",
      "b13c015c05f0: Pulling fs layer\n",
      "8f0d2639aefc: Pulling fs layer\n",
      "11646adc2850: Pulling fs layer\n",
      "14c7723c1bbe: Pulling fs layer\n",
      "6252b7e4a35a: Pulling fs layer\n",
      "ae96ea101185: Pulling fs layer\n",
      "8553e38f9d3b: Pulling fs layer\n",
      "86de3d566666: Waiting\n",
      "b4375d47e797: Pulling fs layer\n",
      "e807ad87032f: Waiting\n",
      "906cdf1c6b78: Pulling fs layer\n",
      "30d00d530989: Waiting\n",
      "d70342317ce5: Pulling fs layer\n",
      "acea7e9af8f8: Pulling fs layer\n",
      "0c557f25f33e: Waiting\n",
      "69a2bfee9a44: Waiting\n",
      "e9ec5ae321aa: Pulling fs layer\n",
      "67cab7d11474: Waiting\n",
      "381964195b8b: Waiting\n",
      "32eed1f081f7: Pulling fs layer\n",
      "4f4fb700ef54: Waiting\n",
      "4b5c1c89bd3d: Pulling fs layer\n",
      "999747c8e1ca: Waiting\n",
      "80c2cbe5e4a8: Pulling fs layer\n",
      "e92bc58784f1: Waiting\n",
      "a9d25440a572: Waiting\n",
      "85c3c971789d: Pulling fs layer\n",
      "ee75ae25ade1: Waiting\n",
      "fa58d293bde3: Pulling fs layer\n",
      "ae96ea101185: Waiting\n",
      "a0efb95d3b56: Pulling fs layer\n",
      "8553e38f9d3b: Waiting\n",
      "1bb05b14fb7d: Pulling fs layer\n",
      "b4375d47e797: Waiting\n",
      "906cdf1c6b78: Waiting\n",
      "3cebcf201134: Pulling fs layer\n",
      "b13c015c05f0: Waiting\n",
      "d70342317ce5: Waiting\n",
      "14c7723c1bbe: Waiting\n",
      "8f0d2639aefc: Waiting\n",
      "acea7e9af8f8: Waiting\n",
      "6252b7e4a35a: Waiting\n",
      "11646adc2850: Waiting\n",
      "e9ec5ae321aa: Waiting\n",
      "fa58d293bde3: Waiting\n",
      "32eed1f081f7: Waiting\n",
      "3cebcf201134: Waiting\n",
      "4b5c1c89bd3d: Waiting\n",
      "fe1468e51d2b: Waiting\n",
      "a0efb95d3b56: Waiting\n",
      "80c2cbe5e4a8: Waiting\n",
      "85c3c971789d: Waiting\n",
      "1bb05b14fb7d: Waiting\n",
      "086b79b77a03: Verifying Checksum\n",
      "086b79b77a03: Download complete\n",
      "4698168f5888: Verifying Checksum\n",
      "4698168f5888: Download complete\n",
      "86de3d566666: Verifying Checksum\n",
      "86de3d566666: Download complete\n",
      "30d00d530989: Verifying Checksum\n",
      "30d00d530989: Download complete\n",
      "d5fd17ec1767: Verifying Checksum\n",
      "d5fd17ec1767: Download complete\n",
      "381964195b8b: Verifying Checksum\n",
      "381964195b8b: Download complete\n",
      "e807ad87032f: Verifying Checksum\n",
      "e807ad87032f: Download complete\n",
      "d5fd17ec1767: Pull complete\n",
      "086b79b77a03: Pull complete\n",
      "4698168f5888: Pull complete\n",
      "86de3d566666: Pull complete\n",
      "30d00d530989: Pull complete\n",
      "69a2bfee9a44: Verifying Checksum\n",
      "69a2bfee9a44: Download complete\n",
      "67cab7d11474: Download complete\n",
      "4f4fb700ef54: Verifying Checksum\n",
      "4f4fb700ef54: Download complete\n",
      "fe1468e51d2b: Download complete\n",
      "999747c8e1ca: Verifying Checksum\n",
      "999747c8e1ca: Download complete\n",
      "a9d25440a572: Verifying Checksum\n",
      "a9d25440a572: Download complete\n",
      "ee75ae25ade1: Download complete\n",
      "e92bc58784f1: Verifying Checksum\n",
      "e92bc58784f1: Download complete\n",
      "8f0d2639aefc: Verifying Checksum\n",
      "8f0d2639aefc: Download complete\n",
      "11646adc2850: Download complete\n",
      "14c7723c1bbe: Verifying Checksum\n",
      "14c7723c1bbe: Download complete\n",
      "6252b7e4a35a: Verifying Checksum\n",
      "6252b7e4a35a: Download complete\n",
      "ae96ea101185: Verifying Checksum\n",
      "ae96ea101185: Download complete\n",
      "8553e38f9d3b: Verifying Checksum\n",
      "8553e38f9d3b: Download complete\n",
      "b4375d47e797: Verifying Checksum\n",
      "b4375d47e797: Download complete\n",
      "b13c015c05f0: Verifying Checksum\n",
      "b13c015c05f0: Download complete\n",
      "906cdf1c6b78: Verifying Checksum\n",
      "906cdf1c6b78: Download complete\n",
      "d70342317ce5: Verifying Checksum\n",
      "d70342317ce5: Download complete\n",
      "acea7e9af8f8: Verifying Checksum\n",
      "acea7e9af8f8: Download complete\n",
      "32eed1f081f7: Verifying Checksum\n",
      "32eed1f081f7: Download complete\n",
      "0c557f25f33e: Download complete\n",
      "80c2cbe5e4a8: Download complete\n",
      "85c3c971789d: Verifying Checksum\n",
      "85c3c971789d: Download complete\n",
      "fa58d293bde3: Download complete\n",
      "a0efb95d3b56: Verifying Checksum\n",
      "a0efb95d3b56: Download complete\n",
      "1bb05b14fb7d: Verifying Checksum\n",
      "1bb05b14fb7d: Download complete\n",
      "4b5c1c89bd3d: Verifying Checksum\n",
      "4b5c1c89bd3d: Download complete\n",
      "3cebcf201134: Verifying Checksum\n",
      "3cebcf201134: Download complete\n",
      "e9ec5ae321aa: Verifying Checksum\n",
      "e9ec5ae321aa: Download complete\n",
      "69a2bfee9a44: Pull complete\n",
      "381964195b8b: Pull complete\n",
      "fe1468e51d2b: Pull complete\n",
      "e807ad87032f: Pull complete\n",
      "0c557f25f33e: Pull complete\n",
      "67cab7d11474: Pull complete\n",
      "4f4fb700ef54: Pull complete\n",
      "999747c8e1ca: Pull complete\n",
      "e92bc58784f1: Pull complete\n",
      "a9d25440a572: Pull complete\n",
      "ee75ae25ade1: Pull complete\n",
      "b13c015c05f0: Pull complete\n",
      "8f0d2639aefc: Pull complete\n",
      "11646adc2850: Pull complete\n",
      "14c7723c1bbe: Pull complete\n",
      "6252b7e4a35a: Pull complete\n",
      "ae96ea101185: Pull complete\n",
      "8553e38f9d3b: Pull complete\n",
      "b4375d47e797: Pull complete\n",
      "906cdf1c6b78: Pull complete\n",
      "d70342317ce5: Pull complete\n",
      "acea7e9af8f8: Pull complete\n",
      "e9ec5ae321aa: Pull complete\n",
      "32eed1f081f7: Pull complete\n",
      "4b5c1c89bd3d: Pull complete\n",
      "80c2cbe5e4a8: Pull complete\n",
      "85c3c971789d: Pull complete\n",
      "fa58d293bde3: Pull complete\n",
      "a0efb95d3b56: Pull complete\n",
      "1bb05b14fb7d: Pull complete\n",
      "3cebcf201134: Pull complete\n",
      "Digest: sha256:5d99c562fcc484d1bd104abab75267f37586d23a97a5a6e354c7828a1d2dfb83\n",
      "Status: Downloaded newer image for gcr.io/tfx-oss-public/tfx:1.8.0\n",
      " ---> 864d5f66048d\n",
      "Step 2/5 : COPY requirements.txt requirements.txt\n",
      " ---> 0cafe6ca1218\n",
      "Step 3/5 : RUN pip install -r requirements.txt\n",
      " ---> Running in 9d7d17462830\n",
      "Collecting kfp==1.8.12\n",
      "  Downloading kfp-1.8.12.tar.gz (301 kB)\n",
      "      301.2/301.2 kB 6.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: google-cloud-bigquery==2.34.3 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (2.34.3)\n",
      "Requirement already satisfied: google-cloud-bigquery-storage==2.13.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (2.13.1)\n",
      "Requirement already satisfied: google-cloud-aiplatform==1.13.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (1.13.0)\n",
      "Collecting cloudml-hypertune==0.1.0.dev6\n",
      "  Downloading cloudml-hypertune-0.1.0.dev6.tar.gz (3.2 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pytest\n",
      "  Downloading pytest-7.1.3-py3-none-any.whl (298 kB)\n",
      "      298.2/298.2 kB 30.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: absl-py<2,>=0.9 in /opt/conda/lib/python3.7/site-packages (from kfp==1.8.12->-r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: PyYAML<6,>=5.3 in /opt/conda/lib/python3.7/site-packages (from kfp==1.8.12->-r requirements.txt (line 1)) (5.4.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/lib/python3.7/site-packages (from kfp==1.8.12->-r requirements.txt (line 1)) (1.31.5)\n",
      "Collecting google-cloud-storage<2,>=1.20.0\n",
      "  Downloading google_cloud_storage-1.44.0-py2.py3-none-any.whl (106 kB)\n",
      "      106.8/106.8 kB 16.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: kubernetes<19,>=8.0.0 in /opt/conda/lib/python3.7/site-packages (from kfp==1.8.12->-r requirements.txt (line 1)) (12.0.1)\n",
      "Requirement already satisfied: google-api-python-client<2,>=1.7.8 in /opt/conda/lib/python3.7/site-packages (from kfp==1.8.12->-r requirements.txt (line 1)) (1.12.11)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.1 in /opt/conda/lib/python3.7/site-packages (from kfp==1.8.12->-r requirements.txt (line 1)) (1.35.0)\n",
      "Collecting requests-toolbelt<1,>=0.8.0\n",
      "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
      "      54.3/54.3 kB 9.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: cloudpickle<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from kfp==1.8.12->-r requirements.txt (line 1)) (2.0.0)\n",
      "Collecting kfp-server-api<2.0.0,>=1.1.2\n",
      "  Downloading kfp-server-api-1.8.5.tar.gz (58 kB)\n",
      "      58.1/58.1 kB 9.8 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting jsonschema<4,>=3.0.1\n",
      "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "      56.3/56.3 kB 9.6 MB/s eta 0:00:00\n",
      "Collecting tabulate<1,>=0.8.6\n",
      "  Downloading tabulate-0.8.10-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: click<9,>=7.1.2 in /opt/conda/lib/python3.7/site-packages (from kfp==1.8.12->-r requirements.txt (line 1)) (7.1.2)\n",
      "Collecting Deprecated<2,>=1.2.7\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting strip-hints<1,>=0.1.8\n",
      "  Downloading strip-hints-0.1.10.tar.gz (29 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting docstring-parser<1,>=0.7.3\n",
      "  Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: kfp-pipeline-spec<0.2.0,>=0.1.14 in /opt/conda/lib/python3.7/site-packages (from kfp==1.8.12->-r requirements.txt (line 1)) (0.1.15)\n",
      "Collecting fire<1,>=0.3.1\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
      "      87.7/87.7 kB 13.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: protobuf<4,>=3.13.0 in /opt/conda/lib/python3.7/site-packages (from kfp==1.8.12->-r requirements.txt (line 1)) (3.20.1)\n",
      "Requirement already satisfied: uritemplate<4,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from kfp==1.8.12->-r requirements.txt (line 1)) (3.0.1)\n",
      "Requirement already satisfied: pydantic<2,>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from kfp==1.8.12->-r requirements.txt (line 1)) (1.9.0)\n",
      "Collecting typer<1.0,>=0.3.2\n",
      "  Downloading typer-0.6.1-py3-none-any.whl (38 kB)\n",
      "Collecting typing-extensions<4,>=3.7.4\n",
      "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery==2.34.3->-r requirements.txt (line 2)) (2.27.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery==2.34.3->-r requirements.txt (line 2)) (2.2.2)\n",
      "Requirement already satisfied: proto-plus>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery==2.34.3->-r requirements.txt (line 2)) (1.20.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery==2.34.3->-r requirements.txt (line 2)) (20.9)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery==2.34.3->-r requirements.txt (line 2)) (2.3.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.38.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery==2.34.3->-r requirements.txt (line 2)) (1.46.1)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery==2.34.3->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform==1.13.0->-r requirements.txt (line 4)) (1.4.1)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from pytest->-r requirements.txt (line 6)) (2.0.1)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest->-r requirements.txt (line 6)) (1.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest->-r requirements.txt (line 6)) (4.11.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.7/site-packages (from pytest->-r requirements.txt (line 6)) (20.3.0)\n",
      "Collecting py>=1.8.2\n",
      "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
      "      98.7/98.7 kB 13.7 MB/s eta 0:00:00\n",
      "Collecting iniconfig\n",
      "  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py<2,>=0.9->kfp==1.8.12->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from Deprecated<2,>=1.2.7->kfp==1.8.12->-r requirements.txt (line 1)) (1.14.1)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.7/site-packages (from fire<1,>=0.3.1->kfp==1.8.12->-r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp==1.8.12->-r requirements.txt (line 1)) (1.56.1)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp==1.8.12->-r requirements.txt (line 1)) (59.8.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp==1.8.12->-r requirements.txt (line 1)) (2022.1)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp==1.8.12->-r requirements.txt (line 1)) (0.19.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp==1.8.12->-r requirements.txt (line 1)) (0.1.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp==1.8.12->-r requirements.txt (line 1)) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp==1.8.12->-r requirements.txt (line 1)) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp==1.8.12->-r requirements.txt (line 1)) (0.2.7)\n",
      "Requirement already satisfied: grpc-google-iam-v1<0.13dev,>=0.12.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform==1.13.0->-r requirements.txt (line 4)) (0.12.4)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery==2.34.3->-r requirements.txt (line 2)) (1.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest->-r requirements.txt (line 6)) (3.8.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp==1.8.12->-r requirements.txt (line 1)) (0.18.1)\n",
      "Requirement already satisfied: urllib3>=1.15 in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp==1.8.12->-r requirements.txt (line 1)) (1.26.9)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp==1.8.12->-r requirements.txt (line 1)) (2021.10.8)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.7/site-packages (from kubernetes<19,>=8.0.0->kfp==1.8.12->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from kubernetes<19,>=8.0.0->kfp==1.8.12->-r requirements.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->google-cloud-bigquery==2.34.3->-r requirements.txt (line 2)) (2.4.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-bigquery==2.34.3->-r requirements.txt (line 2)) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-bigquery==2.34.3->-r requirements.txt (line 2)) (3.3)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from strip-hints<1,>=0.1.8->kfp==1.8.12->-r requirements.txt (line 1)) (0.37.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery==2.34.3->-r requirements.txt (line 2)) (1.15.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.1->kfp==1.8.12->-r requirements.txt (line 1)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib->kubernetes<19,>=8.0.0->kfp==1.8.12->-r requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery==2.34.3->-r requirements.txt (line 2)) (2.21)\n",
      "Building wheels for collected packages: kfp, cloudml-hypertune, fire, kfp-server-api, strip-hints\n",
      "  Building wheel for kfp (setup.py): started\n",
      "  Building wheel for kfp (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp: filename=kfp-1.8.12-py3-none-any.whl size=419048 sha256=9e171096a8986bc6f4400b8584dfbf4d7b581e76b7fec61f7a9fadb41c91809c\n",
      "  Stored in directory: /root/.cache/pip/wheels/54/0c/4a/3fc55077bc88cc17eacaae34c5fd3f6178c1d16d2ee3b0afdf\n",
      "  Building wheel for cloudml-hypertune (setup.py): started\n",
      "  Building wheel for cloudml-hypertune (setup.py): finished with status 'done'\n",
      "  Created wheel for cloudml-hypertune: filename=cloudml_hypertune-0.1.0.dev6-py2.py3-none-any.whl size=3987 sha256=0aa283c5be9363ff34a8ac6ed96c189e83f94ac9fae4dbf8f2cba1305db2383f\n",
      "  Stored in directory: /root/.cache/pip/wheels/a7/ff/87/e7bed0c2741fe219b3d6da67c2431d7f7fedb183032e00f81e\n",
      "  Building wheel for fire (setup.py): started\n",
      "  Building wheel for fire (setup.py): finished with status 'done'\n",
      "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115942 sha256=dde9ce67b184fe23deb9c058f7c86f18417d6425610a793d7c200d51a07d926a\n",
      "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
      "  Building wheel for kfp-server-api (setup.py): started\n",
      "  Building wheel for kfp-server-api (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp-server-api: filename=kfp_server_api-1.8.5-py3-none-any.whl size=99715 sha256=b325535d630571ad1724de1459b6bb3771aa8824bc7f244e5f7264b50e73ded5\n",
      "  Stored in directory: /root/.cache/pip/wheels/77/0e/7b/ed385d69453b7b754834c01d83fa9f5708ba66b4f6ed5d6a35\n",
      "  Building wheel for strip-hints (setup.py): started\n",
      "  Building wheel for strip-hints (setup.py): finished with status 'done'\n",
      "  Created wheel for strip-hints: filename=strip_hints-0.1.10-py2.py3-none-any.whl size=22302 sha256=ad15f2b9a6b4ba93bdf4750c6f8a6374f0e7be2644c6f1044b0c83e873b36476\n",
      "  Stored in directory: /root/.cache/pip/wheels/5e/14/c3/6e44e9b2545f2d570b03f5b6d38c00b7534aa8abb376978363\n",
      "Successfully built kfp cloudml-hypertune fire kfp-server-api strip-hints\n",
      "Installing collected packages: typing-extensions, iniconfig, cloudml-hypertune, typer, tabulate, strip-hints, py, fire, docstring-parser, Deprecated, requests-toolbelt, kfp-server-api, jsonschema, pytest, google-cloud-storage, kfp\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.2.0\n",
      "    Uninstalling typing_extensions-4.2.0:\n",
      "      Successfully uninstalled typing_extensions-4.2.0\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.5.1\n",
      "    Uninstalling jsonschema-4.5.1:\n",
      "      Successfully uninstalled jsonschema-4.5.1\n",
      "  Attempting uninstall: google-cloud-storage\n",
      "    Found existing installation: google-cloud-storage 2.2.1\n",
      "    Uninstalling google-cloud-storage-2.2.1:\n",
      "      Successfully uninstalled google-cloud-storage-2.2.1\n",
      "\u001b[91mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "black 22.3.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible.\n",
      "\u001b[0mSuccessfully installed Deprecated-1.2.13 cloudml-hypertune-0.1.0.dev6 docstring-parser-0.15 fire-0.4.0 google-cloud-storage-2.1.0 iniconfig-1.1.1 jsonschema-3.2.0 kfp-1.8.12 kfp-server-api-1.8.5 py-1.11.0 pytest-7.1.3 requests-toolbelt-0.9.1 strip-hints-0.1.10 tabulate-0.8.10 typer-0.6.1 typing-extensions-3.10.0.2\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91mWARNING: There was an error checking the latest version of pip.\n",
      "\u001b[0mRemoving intermediate container 9d7d17462830\n",
      " ---> 5ac560196681\n",
      "Step 4/5 : COPY src/ src/\n",
      " ---> a9ea84b43c1b\n",
      "Step 5/5 : ENV PYTHONPATH=\"/pipeline:${PYTHONPATH}\"\n",
      " ---> Running in 09aeea6feb4e\n",
      "Removing intermediate container 09aeea6feb4e\n",
      " ---> dab633140310\n",
      "Successfully built dab633140310\n",
      "Successfully tagged gcr.io/mwpmltr/chicago-taxi-tips:v01\n",
      "PUSH\n",
      "Pushing gcr.io/mwpmltr/chicago-taxi-tips:v01\n",
      "The push refers to repository [gcr.io/mwpmltr/chicago-taxi-tips]\n",
      "060a819cc13e: Preparing\n",
      "d3df1e6ae766: Preparing\n",
      "fc60a4c145c7: Preparing\n",
      "849f99ab0557: Preparing\n",
      "003ab0deb210: Preparing\n",
      "051b5111dbe3: Preparing\n",
      "105aac973237: Preparing\n",
      "6b279ee1dea4: Preparing\n",
      "0f5815af70ed: Preparing\n",
      "a439fe54d797: Preparing\n",
      "e5bb7384706a: Preparing\n",
      "105aac973237: Waiting\n",
      "6b279ee1dea4: Waiting\n",
      "051b5111dbe3: Waiting\n",
      "0f5815af70ed: Waiting\n",
      "a439fe54d797: Waiting\n",
      "529b51f6018a: Preparing\n",
      "4d5391a66f17: Preparing\n",
      "8776dda77d84: Preparing\n",
      "e5bb7384706a: Waiting\n",
      "f7bf6100a736: Preparing\n",
      "2427ba19d9ab: Preparing\n",
      "c5d8ddc90738: Preparing\n",
      "f9d66d415903: Preparing\n",
      "4d5391a66f17: Waiting\n",
      "8776dda77d84: Waiting\n",
      "2427ba19d9ab: Waiting\n",
      "c5d8ddc90738: Waiting\n",
      "f7bf6100a736: Waiting\n",
      "529b51f6018a: Waiting\n",
      "0a0b70a03299: Preparing\n",
      "01d285020d37: Preparing\n",
      "ad52cc5ce980: Preparing\n",
      "40d867f1633d: Preparing\n",
      "695cde20e218: Preparing\n",
      "eab9c045ef1b: Preparing\n",
      "ad7c511b31df: Preparing\n",
      "ad52cc5ce980: Waiting\n",
      "0a0b70a03299: Waiting\n",
      "cd9f5c9bd89e: Preparing\n",
      "01d285020d37: Waiting\n",
      "40d867f1633d: Waiting\n",
      "ca40136e604d: Preparing\n",
      "f9d66d415903: Waiting\n",
      "5f70bf18a086: Preparing\n",
      "695cde20e218: Waiting\n",
      "eab9c045ef1b: Waiting\n",
      "08e753b98db4: Preparing\n",
      "8f9243705224: Preparing\n",
      "ad7c511b31df: Waiting\n",
      "cd9f5c9bd89e: Waiting\n",
      "ba42d5f65b46: Preparing\n",
      "51981f322139: Preparing\n",
      "5f70bf18a086: Waiting\n",
      "cbe679dd18e3: Preparing\n",
      "ce07be50029c: Preparing\n",
      "08e753b98db4: Waiting\n",
      "7011392a3aa0: Preparing\n",
      "8f9243705224: Waiting\n",
      "0cfddc66f231: Preparing\n",
      "ba42d5f65b46: Waiting\n",
      "a4a375cdde15: Preparing\n",
      "ac5045d5adeb: Preparing\n",
      "bf8cedc62fb3: Preparing\n",
      "51981f322139: Waiting\n",
      "7011392a3aa0: Waiting\n",
      "cbe679dd18e3: Waiting\n",
      "0cfddc66f231: Waiting\n",
      "ce07be50029c: Waiting\n",
      "a4a375cdde15: Waiting\n",
      "ac5045d5adeb: Waiting\n",
      "bf8cedc62fb3: Waiting\n",
      "ca40136e604d: Waiting\n",
      "849f99ab0557: Layer already exists\n",
      "003ab0deb210: Layer already exists\n",
      "105aac973237: Layer already exists\n",
      "051b5111dbe3: Layer already exists\n",
      "6b279ee1dea4: Layer already exists\n",
      "0f5815af70ed: Layer already exists\n",
      "a439fe54d797: Layer already exists\n",
      "e5bb7384706a: Layer already exists\n",
      "529b51f6018a: Layer already exists\n",
      "4d5391a66f17: Layer already exists\n",
      "8776dda77d84: Layer already exists\n",
      "f7bf6100a736: Layer already exists\n",
      "2427ba19d9ab: Layer already exists\n",
      "c5d8ddc90738: Layer already exists\n",
      "f9d66d415903: Layer already exists\n",
      "0a0b70a03299: Layer already exists\n",
      "01d285020d37: Layer already exists\n",
      "ad52cc5ce980: Layer already exists\n",
      "40d867f1633d: Layer already exists\n",
      "695cde20e218: Layer already exists\n",
      "eab9c045ef1b: Layer already exists\n",
      "ad7c511b31df: Layer already exists\n",
      "cd9f5c9bd89e: Layer already exists\n",
      "ca40136e604d: Layer already exists\n",
      "08e753b98db4: Layer already exists\n",
      "5f70bf18a086: Layer already exists\n",
      "ba42d5f65b46: Layer already exists\n",
      "8f9243705224: Layer already exists\n",
      "51981f322139: Layer already exists\n",
      "cbe679dd18e3: Layer already exists\n",
      "ce07be50029c: Layer already exists\n",
      "7011392a3aa0: Layer already exists\n",
      "0cfddc66f231: Layer already exists\n",
      "a4a375cdde15: Layer already exists\n",
      "ac5045d5adeb: Layer already exists\n",
      "bf8cedc62fb3: Layer already exists\n",
      "fc60a4c145c7: Pushed\n",
      "060a819cc13e: Pushed\n",
      "d3df1e6ae766: Pushed\n",
      "v01: digest: sha256:c4007f67d1531396aee2079cbd46e69c3b7bc80b4051a238b63de38f79ae4516 size: 8513\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                 IMAGES                                STATUS\n",
      "bea39746-48aa-4fde-8d02-21d26022dfba  2022-09-10T23:50:00+00:00  3M17S     gs://mwpmltr_cloudbuild/source/1662853799.572005-91114e838bc44ba690f6da0299d3603c.tgz  gcr.io/mwpmltr/chicago-taxi-tips:v01  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit --tag $TFX_IMAGE_URI . --timeout=15m --machine-type=e2-highcpu-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155568ca",
   "metadata": {},
   "source": [
    "### Compile pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c1d5ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying etl.py -> build/lib\n",
      "copying transformations.py -> build/lib\n",
      "installing to /tmp/tmpyay0iirs\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/transformations.py -> /tmp/tmpyay0iirs\n",
      "copying build/lib/etl.py -> /tmp/tmpyay0iirs\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_DataTransformer.egg-info\n",
      "writing tfx_user_code_DataTransformer.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_DataTransformer.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_DataTransformer.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_DataTransformer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_DataTransformer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_DataTransformer.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_DataTransformer.egg-info to /tmp/tmpyay0iirs/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3.7.egg-info\n",
      "running install_scripts\n",
      "creating /tmp/tmpyay0iirs/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d.dist-info/WHEEL\n",
      "creating '/tmp/tmpgcqzcnia/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl' and adding '/tmp/tmpyay0iirs' to it\n",
      "adding 'etl.py'\n",
      "adding 'transformations.py'\n",
      "adding 'tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d.dist-info/METADATA'\n",
      "adding 'tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d.dist-info/RECORD'\n",
      "removing /tmp/tmpyay0iirs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  setuptools.SetuptoolsDeprecationWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying data.py -> build/lib\n",
      "copying exporter.py -> build/lib\n",
      "copying trainer.py -> build/lib\n",
      "copying task.py -> build/lib\n",
      "copying model.py -> build/lib\n",
      "copying runner.py -> build/lib\n",
      "copying defaults.py -> build/lib\n",
      "installing to /tmp/tmp7f9yf1yi\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/trainer.py -> /tmp/tmp7f9yf1yi\n",
      "copying build/lib/model.py -> /tmp/tmp7f9yf1yi\n",
      "copying build/lib/runner.py -> /tmp/tmp7f9yf1yi\n",
      "copying build/lib/task.py -> /tmp/tmp7f9yf1yi\n",
      "copying build/lib/data.py -> /tmp/tmp7f9yf1yi\n",
      "copying build/lib/defaults.py -> /tmp/tmp7f9yf1yi\n",
      "copying build/lib/exporter.py -> /tmp/tmp7f9yf1yi\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_ModelTrainer.egg-info\n",
      "writing tfx_user_code_ModelTrainer.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_ModelTrainer.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_ModelTrainer.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_ModelTrainer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_ModelTrainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_ModelTrainer.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_ModelTrainer.egg-info to /tmp/tmp7f9yf1yi/tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8-py3.7.egg-info\n",
      "running install_scripts\n",
      "creating /tmp/tmp7f9yf1yi/tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8.dist-info/WHEEL\n",
      "creating '/tmp/tmpei2c5g_z/tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8-py3-none-any.whl' and adding '/tmp/tmp7f9yf1yi' to it\n",
      "adding 'data.py'\n",
      "adding 'defaults.py'\n",
      "adding 'exporter.py'\n",
      "adding 'model.py'\n",
      "adding 'runner.py'\n",
      "adding 'task.py'\n",
      "adding 'trainer.py'\n",
      "adding 'tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8.dist-info/METADATA'\n",
      "adding 'tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_ModelTrainer-0.0+437642825399ecb8802c98273bfd8605f1af4f0d57f21bf741e670d64447bfc8.dist-info/RECORD'\n",
      "removing /tmp/tmp7f9yf1yi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  setuptools.SetuptoolsDeprecationWarning,\n"
     ]
    }
   ],
   "source": [
    "from src.tfx_pipelines import runner\n",
    "\n",
    "pipeline_definition_file = f'{config.PIPELINE_NAME}.json'\n",
    "pipeline_definition = runner.compile_training_pipeline(pipeline_definition_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6644c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://chicago-taxi-tips-classifier-v01-train-pipeline.json [Content-Type=application/json]...\n",
      "/ [1 files][ 26.2 KiB/ 26.2 KiB]                                                \n",
      "Operation completed over 1 objects/26.2 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "PIPELINES_STORE = f\"gs://{BUCKET}/{DATASET_DISPLAY_NAME}/compiled_pipelines/\"\n",
    "!gsutil cp {pipeline_definition_file} {PIPELINES_STORE}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcb943e",
   "metadata": {},
   "source": [
    "### Submit run to Vertex Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62c6b0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.7/site-packages/kfp/v2/google/client/client.py:173: FutureWarning: AIPlatformClient will be deprecated in v2.0.0. Please use PipelineJob https://googleapis.dev/python/aiplatform/latest/_modules/google/cloud/aiplatform/pipeline_jobs.html in Vertex SDK. Install the SDK using \"pip install google-cloud-aiplatform\"\n",
      "  category=FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/chicago-taxi-tips-classifier-v01-train-pipeline-20220910235402?project=mwpmltr\" target=\"_blank\" >here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from kfp.v2.google.client import AIPlatformClient\n",
    "\n",
    "pipeline_client = AIPlatformClient(\n",
    "    project_id=PROJECT, region=REGION)\n",
    "                 \n",
    "job = pipeline_client.create_run_from_job_spec(\n",
    "    job_spec_path=pipeline_definition_file,\n",
    "    parameter_values={\n",
    "        'learning_rate': 0.003,\n",
    "        'batch_size': 512,\n",
    "        'hidden_units': '128,128',\n",
    "        'num_epochs': 30,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888be1fd",
   "metadata": {},
   "source": [
    "### Extracting pipeline runs metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37ae4aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pipeline_name</th>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipeline</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipeline</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipeline</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipeline</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipeline</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipeline</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipeline</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipeline</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipeline</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipeline</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipeline</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipeline</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipeline</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipeline</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run_name</th>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipelin...</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipelin...</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipelin...</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipelin...</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipelin...</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipelin...</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipelin...</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipelin...</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipelin...</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipelin...</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipelin...</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipelin...</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipelin...</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipelin...</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01-train-pipelin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.input:learning_rate</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.input:num_epochs</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.input:batch_size</th>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.input:hidden_units</th>\n",
       "      <td>128,128</td>\n",
       "      <td>256,126</td>\n",
       "      <td>128,128</td>\n",
       "      <td>128,128</td>\n",
       "      <td>128,128</td>\n",
       "      <td>128,128</td>\n",
       "      <td>128,128</td>\n",
       "      <td>128,128</td>\n",
       "      <td>128,128</td>\n",
       "      <td>128,128</td>\n",
       "      <td>128,128</td>\n",
       "      <td>128,128</td>\n",
       "      <td>128,128</td>\n",
       "      <td>128,128</td>\n",
       "      <td>128,128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          0   \\\n",
       "pipeline_name                chicago-taxi-tips-classifier-v01-train-pipeline   \n",
       "run_name                   chicago-taxi-tips-classifier-v01-train-pipelin...   \n",
       "param.input:learning_rate                                              0.003   \n",
       "param.input:num_epochs                                                    30   \n",
       "param.input:batch_size                                                   512   \n",
       "param.input:hidden_units                                             128,128   \n",
       "\n",
       "                                                                          1   \\\n",
       "pipeline_name                chicago-taxi-tips-classifier-v01-train-pipeline   \n",
       "run_name                   chicago-taxi-tips-classifier-v01-train-pipelin...   \n",
       "param.input:learning_rate                                             0.0015   \n",
       "param.input:num_epochs                                                     3   \n",
       "param.input:batch_size                                                   512   \n",
       "param.input:hidden_units                                             256,126   \n",
       "\n",
       "                                                                          2   \\\n",
       "pipeline_name                chicago-taxi-tips-classifier-v01-train-pipeline   \n",
       "run_name                   chicago-taxi-tips-classifier-v01-train-pipelin...   \n",
       "param.input:learning_rate                                              0.003   \n",
       "param.input:num_epochs                                                    30   \n",
       "param.input:batch_size                                                   512   \n",
       "param.input:hidden_units                                             128,128   \n",
       "\n",
       "                                                                          3   \\\n",
       "pipeline_name                chicago-taxi-tips-classifier-v01-train-pipeline   \n",
       "run_name                   chicago-taxi-tips-classifier-v01-train-pipelin...   \n",
       "param.input:learning_rate                                              0.003   \n",
       "param.input:num_epochs                                                     1   \n",
       "param.input:batch_size                                                   512   \n",
       "param.input:hidden_units                                             128,128   \n",
       "\n",
       "                                                                          4   \\\n",
       "pipeline_name                chicago-taxi-tips-classifier-v01-train-pipeline   \n",
       "run_name                   chicago-taxi-tips-classifier-v01-train-pipelin...   \n",
       "param.input:learning_rate                                              0.003   \n",
       "param.input:num_epochs                                                     1   \n",
       "param.input:batch_size                                                   512   \n",
       "param.input:hidden_units                                             128,128   \n",
       "\n",
       "                                                                          5   \\\n",
       "pipeline_name                chicago-taxi-tips-classifier-v01-train-pipeline   \n",
       "run_name                   chicago-taxi-tips-classifier-v01-train-pipelin...   \n",
       "param.input:learning_rate                                              0.003   \n",
       "param.input:num_epochs                                                     1   \n",
       "param.input:batch_size                                                   512   \n",
       "param.input:hidden_units                                             128,128   \n",
       "\n",
       "                                                                          6   \\\n",
       "pipeline_name                chicago-taxi-tips-classifier-v01-train-pipeline   \n",
       "run_name                   chicago-taxi-tips-classifier-v01-train-pipelin...   \n",
       "param.input:learning_rate                                              0.003   \n",
       "param.input:num_epochs                                                     1   \n",
       "param.input:batch_size                                                   512   \n",
       "param.input:hidden_units                                             128,128   \n",
       "\n",
       "                                                                          7   \\\n",
       "pipeline_name                chicago-taxi-tips-classifier-v01-train-pipeline   \n",
       "run_name                   chicago-taxi-tips-classifier-v01-train-pipelin...   \n",
       "param.input:learning_rate                                              0.003   \n",
       "param.input:num_epochs                                                    30   \n",
       "param.input:batch_size                                                   512   \n",
       "param.input:hidden_units                                             128,128   \n",
       "\n",
       "                                                                          8   \\\n",
       "pipeline_name                chicago-taxi-tips-classifier-v01-train-pipeline   \n",
       "run_name                   chicago-taxi-tips-classifier-v01-train-pipelin...   \n",
       "param.input:learning_rate                                              0.003   \n",
       "param.input:num_epochs                                                    30   \n",
       "param.input:batch_size                                                   512   \n",
       "param.input:hidden_units                                             128,128   \n",
       "\n",
       "                                                                          9   \\\n",
       "pipeline_name                chicago-taxi-tips-classifier-v01-train-pipeline   \n",
       "run_name                   chicago-taxi-tips-classifier-v01-train-pipelin...   \n",
       "param.input:learning_rate                                              0.003   \n",
       "param.input:num_epochs                                                    30   \n",
       "param.input:batch_size                                                   512   \n",
       "param.input:hidden_units                                             128,128   \n",
       "\n",
       "                                                                          10  \\\n",
       "pipeline_name                chicago-taxi-tips-classifier-v01-train-pipeline   \n",
       "run_name                   chicago-taxi-tips-classifier-v01-train-pipelin...   \n",
       "param.input:learning_rate                                              0.003   \n",
       "param.input:num_epochs                                                    30   \n",
       "param.input:batch_size                                                   512   \n",
       "param.input:hidden_units                                             128,128   \n",
       "\n",
       "                                                                          11  \\\n",
       "pipeline_name                chicago-taxi-tips-classifier-v01-train-pipeline   \n",
       "run_name                   chicago-taxi-tips-classifier-v01-train-pipelin...   \n",
       "param.input:learning_rate                                              0.003   \n",
       "param.input:num_epochs                                                    30   \n",
       "param.input:batch_size                                                   512   \n",
       "param.input:hidden_units                                             128,128   \n",
       "\n",
       "                                                                          12  \\\n",
       "pipeline_name                chicago-taxi-tips-classifier-v01-train-pipeline   \n",
       "run_name                   chicago-taxi-tips-classifier-v01-train-pipelin...   \n",
       "param.input:learning_rate                                              0.003   \n",
       "param.input:num_epochs                                                    30   \n",
       "param.input:batch_size                                                   512   \n",
       "param.input:hidden_units                                             128,128   \n",
       "\n",
       "                                                                          13  \\\n",
       "pipeline_name                chicago-taxi-tips-classifier-v01-train-pipeline   \n",
       "run_name                   chicago-taxi-tips-classifier-v01-train-pipelin...   \n",
       "param.input:learning_rate                                              0.003   \n",
       "param.input:num_epochs                                                    30   \n",
       "param.input:batch_size                                                   512   \n",
       "param.input:hidden_units                                             128,128   \n",
       "\n",
       "                                                                          14  \n",
       "pipeline_name                chicago-taxi-tips-classifier-v01-train-pipeline  \n",
       "run_name                   chicago-taxi-tips-classifier-v01-train-pipelin...  \n",
       "param.input:learning_rate                                              0.003  \n",
       "param.input:num_epochs                                                    30  \n",
       "param.input:batch_size                                                   512  \n",
       "param.input:hidden_units                                             128,128  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import aiplatform as vertex_ai\n",
    "\n",
    "pipeline_df = vertex_ai.get_pipeline_df(PIPELINE_NAME)\n",
    "pipeline_df = pipeline_df[pipeline_df.pipeline_name == PIPELINE_NAME]\n",
    "pipeline_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b454fe9",
   "metadata": {},
   "source": [
    "## 3. Execute the pipeline deployment CI/CD steps in Cloud Build\n",
    "\n",
    "The CI/CD routine is defined in the [pipeline-deployment.yaml](pipeline-deployment.yaml) file, and consists of the following steps:\n",
    "1. Clone the repository to the build environment.\n",
    "2. Run unit tests.\n",
    "3. Run a local e2e test of the pipeline.\n",
    "4. Build the ML container image for pipeline steps.\n",
    "5. Compile the pipeline.\n",
    "6. Upload the pipeline to Cloud Storage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29688d4d",
   "metadata": {},
   "source": [
    "### Build CI/CD container Image for Cloud Build\n",
    "\n",
    "This is the runtime environment where the steps of testing and deploying the pipeline will be executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4759b85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcr.io/mwpmltr/cicd:latest\n"
     ]
    }
   ],
   "source": [
    "!echo $CICD_IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc09c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 10 file(s) totalling 22.5 KiB before compression.\n",
      "Uploading tarball of [build/.] to [gs://mwpmltr_cloudbuild/source/1662854044.883605-72513495fd5b49f78b5882ad22a29dc2.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/mwpmltr/locations/global/builds/978f9be9-0487-4aa6-bb72-de7f5421ed6b].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/978f9be9-0487-4aa6-bb72-de7f5421ed6b?project=55590906972].\n",
      "Copying gs://mwpmltr_cloudbuild/source/1662854044.883605-72513495fd5b49f78b5882ad22a29dc2.tgz#1662854045111602...\n",
      "/ [1 files][  3.4 KiB/  3.4 KiB]                                                \n",
      "Operation completed over 1 objects/3.4 KiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  32.26kB\n",
      "Step 1/4 : FROM gcr.io/tfx-oss-public/tfx:1.8.0\n",
      "1.8.0: Pulling from tfx-oss-public/tfx\n",
      "d5fd17ec1767: Pulling fs layer\n",
      "086b79b77a03: Pulling fs layer\n",
      "4698168f5888: Pulling fs layer\n",
      "86de3d566666: Pulling fs layer\n",
      "30d00d530989: Pulling fs layer\n",
      "69a2bfee9a44: Pulling fs layer\n",
      "381964195b8b: Pulling fs layer\n",
      "fe1468e51d2b: Pulling fs layer\n",
      "e807ad87032f: Pulling fs layer\n",
      "0c557f25f33e: Pulling fs layer\n",
      "67cab7d11474: Pulling fs layer\n",
      "4f4fb700ef54: Pulling fs layer\n",
      "999747c8e1ca: Pulling fs layer\n",
      "e92bc58784f1: Pulling fs layer\n",
      "a9d25440a572: Pulling fs layer\n",
      "ee75ae25ade1: Pulling fs layer\n",
      "b13c015c05f0: Pulling fs layer\n",
      "8f0d2639aefc: Pulling fs layer\n",
      "11646adc2850: Pulling fs layer\n",
      "14c7723c1bbe: Pulling fs layer\n",
      "6252b7e4a35a: Pulling fs layer\n",
      "ae96ea101185: Pulling fs layer\n",
      "8553e38f9d3b: Pulling fs layer\n",
      "b4375d47e797: Pulling fs layer\n",
      "906cdf1c6b78: Pulling fs layer\n",
      "d70342317ce5: Pulling fs layer\n",
      "acea7e9af8f8: Pulling fs layer\n",
      "e9ec5ae321aa: Pulling fs layer\n",
      "32eed1f081f7: Pulling fs layer\n",
      "4b5c1c89bd3d: Pulling fs layer\n",
      "80c2cbe5e4a8: Pulling fs layer\n",
      "85c3c971789d: Pulling fs layer\n",
      "fa58d293bde3: Pulling fs layer\n",
      "a0efb95d3b56: Pulling fs layer\n",
      "1bb05b14fb7d: Pulling fs layer\n",
      "3cebcf201134: Pulling fs layer\n",
      "30d00d530989: Waiting\n",
      "69a2bfee9a44: Waiting\n",
      "381964195b8b: Waiting\n",
      "86de3d566666: Waiting\n",
      "fe1468e51d2b: Waiting\n",
      "e807ad87032f: Waiting\n",
      "0c557f25f33e: Waiting\n",
      "67cab7d11474: Waiting\n",
      "4f4fb700ef54: Waiting\n",
      "999747c8e1ca: Waiting\n",
      "d70342317ce5: Waiting\n",
      "e92bc58784f1: Waiting\n",
      "acea7e9af8f8: Waiting\n",
      "a9d25440a572: Waiting\n",
      "e9ec5ae321aa: Waiting\n",
      "32eed1f081f7: Waiting\n",
      "ee75ae25ade1: Waiting\n",
      "4b5c1c89bd3d: Waiting\n",
      "b13c015c05f0: Waiting\n",
      "80c2cbe5e4a8: Waiting\n",
      "8f0d2639aefc: Waiting\n",
      "11646adc2850: Waiting\n",
      "85c3c971789d: Waiting\n",
      "14c7723c1bbe: Waiting\n",
      "fa58d293bde3: Waiting\n",
      "6252b7e4a35a: Waiting\n",
      "a0efb95d3b56: Waiting\n",
      "ae96ea101185: Waiting\n",
      "1bb05b14fb7d: Waiting\n",
      "8553e38f9d3b: Waiting\n",
      "3cebcf201134: Waiting\n",
      "b4375d47e797: Waiting\n",
      "906cdf1c6b78: Waiting\n",
      "086b79b77a03: Download complete\n",
      "d5fd17ec1767: Verifying Checksum\n",
      "d5fd17ec1767: Download complete\n",
      "4698168f5888: Verifying Checksum\n",
      "4698168f5888: Download complete\n",
      "30d00d530989: Verifying Checksum\n",
      "30d00d530989: Download complete\n",
      "86de3d566666: Verifying Checksum\n",
      "86de3d566666: Download complete\n",
      "381964195b8b: Verifying Checksum\n",
      "381964195b8b: Download complete\n",
      "e807ad87032f: Verifying Checksum\n",
      "e807ad87032f: Download complete\n",
      "d5fd17ec1767: Pull complete\n",
      "086b79b77a03: Pull complete\n",
      "4698168f5888: Pull complete\n",
      "86de3d566666: Pull complete\n",
      "30d00d530989: Pull complete\n",
      "69a2bfee9a44: Verifying Checksum\n",
      "69a2bfee9a44: Download complete\n",
      "67cab7d11474: Verifying Checksum\n",
      "67cab7d11474: Download complete\n",
      "4f4fb700ef54: Verifying Checksum\n",
      "4f4fb700ef54: Download complete\n",
      "fe1468e51d2b: Download complete\n",
      "999747c8e1ca: Verifying Checksum\n",
      "999747c8e1ca: Download complete\n",
      "a9d25440a572: Download complete\n",
      "ee75ae25ade1: Download complete\n",
      "e92bc58784f1: Verifying Checksum\n",
      "e92bc58784f1: Download complete\n",
      "8f0d2639aefc: Verifying Checksum\n",
      "8f0d2639aefc: Download complete\n",
      "11646adc2850: Download complete\n",
      "14c7723c1bbe: Verifying Checksum\n",
      "14c7723c1bbe: Download complete\n",
      "6252b7e4a35a: Verifying Checksum\n",
      "6252b7e4a35a: Download complete\n",
      "ae96ea101185: Download complete\n",
      "8553e38f9d3b: Verifying Checksum\n",
      "8553e38f9d3b: Download complete\n",
      "b4375d47e797: Download complete\n",
      "906cdf1c6b78: Verifying Checksum\n",
      "906cdf1c6b78: Download complete\n",
      "d70342317ce5: Verifying Checksum\n",
      "d70342317ce5: Download complete\n",
      "b13c015c05f0: Verifying Checksum\n",
      "b13c015c05f0: Download complete\n",
      "acea7e9af8f8: Verifying Checksum\n",
      "acea7e9af8f8: Download complete\n",
      "32eed1f081f7: Verifying Checksum\n",
      "32eed1f081f7: Download complete\n",
      "0c557f25f33e: Verifying Checksum\n",
      "0c557f25f33e: Download complete\n",
      "80c2cbe5e4a8: Verifying Checksum\n",
      "80c2cbe5e4a8: Download complete\n",
      "85c3c971789d: Verifying Checksum\n",
      "85c3c971789d: Download complete\n",
      "fa58d293bde3: Verifying Checksum\n",
      "fa58d293bde3: Download complete\n",
      "4b5c1c89bd3d: Verifying Checksum\n",
      "4b5c1c89bd3d: Download complete\n",
      "a0efb95d3b56: Verifying Checksum\n",
      "a0efb95d3b56: Download complete\n",
      "1bb05b14fb7d: Verifying Checksum\n",
      "1bb05b14fb7d: Download complete\n",
      "3cebcf201134: Verifying Checksum\n",
      "3cebcf201134: Download complete\n",
      "e9ec5ae321aa: Verifying Checksum\n",
      "e9ec5ae321aa: Download complete\n",
      "69a2bfee9a44: Pull complete\n",
      "381964195b8b: Pull complete\n",
      "fe1468e51d2b: Pull complete\n",
      "e807ad87032f: Pull complete\n",
      "0c557f25f33e: Pull complete\n",
      "67cab7d11474: Pull complete\n",
      "4f4fb700ef54: Pull complete\n",
      "999747c8e1ca: Pull complete\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit --tag $CICD_IMAGE_URI build/. --timeout=15m --machine-type=e2-highcpu-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc9b2af",
   "metadata": {},
   "source": [
    "### Run CI/CD from pipeline deployment using Cloud Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b55593",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_URL = \"https://github.com/GoogleCloudPlatform/mlops-with-vertex-ai.git\" # Change to your github repo.\n",
    "BRANCH = \"main\"\n",
    "\n",
    "GCS_LOCATION = f\"gs://{BUCKET}/{DATASET_DISPLAY_NAME}/\"\n",
    "TEST_GCS_LOCATION = f\"gs://{BUCKET}/{DATASET_DISPLAY_NAME}/e2e_tests\"\n",
    "CI_TRAIN_LIMIT = 1000\n",
    "CI_TEST_LIMIT = 100\n",
    "CI_UPLOAD_MODEL = 0\n",
    "CI_ACCURACY_THRESHOLD = 0.1\n",
    "BEAM_RUNNER = \"DataflowRunner\"\n",
    "TRAINING_RUNNER = \"vertex\"\n",
    "VERSION = 'tfx-1.8'\n",
    "PIPELINE_NAME = f'{MODEL_DISPLAY_NAME}-train-pipeline'\n",
    "PIPELINES_STORE = os.path.join(GCS_LOCATION, \"compiled_pipelines\")\n",
    "\n",
    "TFX_IMAGE_URI = f\"gcr.io/{PROJECT}/{DATASET_DISPLAY_NAME}:{VERSION}\"\n",
    "\n",
    "SUBSTITUTIONS=f\"\"\"\\\n",
    "_REPO_URL='{REPO_URL}',\\\n",
    "_BRANCH={BRANCH},\\\n",
    "_CICD_IMAGE_URI={CICD_IMAGE_URI},\\\n",
    "_PROJECT={PROJECT},\\\n",
    "_REGION={REGION},\\\n",
    "_GCS_LOCATION={GCS_LOCATION},\\\n",
    "_TEST_GCS_LOCATION={TEST_GCS_LOCATION},\\\n",
    "_BQ_LOCATION={BQ_LOCATION},\\\n",
    "_BQ_DATASET_NAME={BQ_DATASET_NAME},\\\n",
    "_BQ_TABLE_NAME={BQ_TABLE_NAME},\\\n",
    "_DATASET_DISPLAY_NAME={DATASET_DISPLAY_NAME},\\\n",
    "_MODEL_DISPLAY_NAME={MODEL_DISPLAY_NAME},\\\n",
    "_CI_TRAIN_LIMIT={CI_TRAIN_LIMIT},\\\n",
    "_CI_TEST_LIMIT={CI_TEST_LIMIT},\\\n",
    "_CI_UPLOAD_MODEL={CI_UPLOAD_MODEL},\\\n",
    "_CI_ACCURACY_THRESHOLD={CI_ACCURACY_THRESHOLD},\\\n",
    "_BEAM_RUNNER={BEAM_RUNNER},\\\n",
    "_TRAINING_RUNNER={TRAINING_RUNNER},\\\n",
    "_TFX_IMAGE_URI={TFX_IMAGE_URI},\\\n",
    "_PIPELINE_NAME={PIPELINE_NAME},\\\n",
    "_PIPELINES_STORE={PIPELINES_STORE}\\\n",
    "\"\"\"\n",
    "\n",
    "!echo $SUBSTITUTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc589ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud builds submit --no-source --timeout=60m --config build/pipeline-deployment.yaml --substitutions {SUBSTITUTIONS} --machine-type=e2-highcpu-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16028a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
