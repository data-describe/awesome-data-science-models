{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66bb60d4-3f1b-45a1-9453-1513e208c411",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce485e64-c9fc-4b5d-918d-cf5c4c29c364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import google.cloud.aiplatform as aiplatform\n",
    "from google.cloud.aiplatform import model_monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6484802-2da5-4e72-ad9a-7d94d945f9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"ds-training-380514\"\n",
    "REGION = \"us-central1\"\n",
    "BUCKET_NAME = \"ds-training-380514\"\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcd45527-3952-4220-8935-4b29a4ec6f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID,\n",
    "                location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2257e070-5915-475f-bdbc-f50fc4212830",
   "metadata": {},
   "source": [
    "Copy-paste endpoint info from the AutoML notebook e.g. look for something like \"projects/123/locations/us-central1/endpoints/456\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b702b130-b7a2-437e-a5f9-8e3d1455bb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = aiplatform.Endpoint('projects/354621994428/locations/us-central1/endpoints/1823759936992051200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf10e516-34dd-4ed5-9636-51d6d469d230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<google.cloud.aiplatform.models.Endpoint object at 0x7f7d45bd02d0> \n",
      "resource name: projects/354621994428/locations/us-central1/endpoints/1823759936992051200\n"
     ]
    }
   ],
   "source": [
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e673f16b-35a9-4778-bb6e-d9b87af05a8f",
   "metadata": {},
   "source": [
    "## Configure alerting specification\n",
    "First, you configure the alerting_config specification with the following settings:\n",
    "\n",
    "user_emails: A list of one or more email to send alerts to.\n",
    "enable_logging: Streams detected anomalies to Cloud Logging. Default is False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "305a861b-da67-453c-88a3-b8b3b23aad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_EMAIL = \"abc@domain.com\"\n",
    "\n",
    "alerting_config = model_monitoring.EmailAlertConfig(user_emails=[USER_EMAIL],\n",
    "                                                    enable_logging=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b72422-7df8-4bce-9db5-93f2d11f08b2",
   "metadata": {},
   "source": [
    "### Configure the monitoring interval specification\n",
    "\n",
    "Next, you configure the `schedule_config` specification with the following settings:\n",
    "\n",
    "- `monitor_interval`:  Sets the model monitoring job scheduling interval in hours. Minimum time interval is 1 hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41cf1f2c-eeed-4419-aff6-e8f41633bd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitoring Interval\n",
    "MONITOR_INTERVAL = 1  # least count = 1; measured in hours\n",
    "\n",
    "# Create schedule configuration\n",
    "schedule_config = model_monitoring.ScheduleConfig(monitor_interval=MONITOR_INTERVAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088c1443-7920-4a62-8bbb-cb699147fc5b",
   "metadata": {},
   "source": [
    "### Configure the sampling specification\n",
    "\n",
    "Next, you configure the `logging_sampling_strategy` specification with the following settings:\n",
    "\n",
    "- `sample_rate`: The rate as a percentage (between 0 and 1) to randomly sample prediction requests for monitoring. Selected samples are logged to a BigQuery table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecaa360a-d563-4618-bb05-8c93cd080ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 0.5  # default value is 0.8 i.e. 80%\n",
    "\n",
    "# Create sampling configuration\n",
    "logging_sampling_strategy = model_monitoring.RandomSampleConfig(sample_rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c10d4e-6f13-428d-9837-6f7bee8fea2c",
   "metadata": {},
   "source": [
    "### Configure the drift detection specification\n",
    "\n",
    "Next, you configure the `drift_config` specification with the following settings:\n",
    "\n",
    "- `drift_thresholds`: A dictionary of key/value pairs where the keys are the input features for monitor for drift. The value is the detection threshold. When not specified, the default drift threshold for a feature is 0.3 (30%).\n",
    "\n",
    "*Note:* Enabling drift detection is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b94568cd-79e8-47e3-9910-05b64e2fdfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DRIFT_THRESHOLD_VALUE = 0.05\n",
    "\n",
    "# Set column-wise threshold values\n",
    "DRIFT_THRESHOLDS = {\"ABBA\": DRIFT_THRESHOLD_VALUE,\n",
    "                    }\n",
    "\n",
    "drift_config = model_monitoring.DriftDetectionConfig(drift_thresholds=DRIFT_THRESHOLDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16372b21-c790-4018-b980-3c1d9d7d4e66",
   "metadata": {},
   "source": [
    "### Configure the skew detection specification\n",
    "\n",
    "Next, you configure the `skew_config` specification with the following settings:\n",
    "\n",
    "- `data_source`: The source of the dataset of the original training data. The format of the source defaults to a BigQuery table. Otherwise the setting `data_format` must be set to one of the values below. The location of the data must be a Cloud Storage location.\n",
    "  - `csv`: \n",
    "  - `jsonl`:\n",
    "  - `tf-record`:\n",
    "- `skew_thresholds`: A dictionary of key/value pairs where the keys are the input features for monitor for skew. The value is the detection threshold. When not specified, the default skew threshold for a feature is 0.3 (30%).\n",
    "- `target_field`: The target label for the training dataset\n",
    "\n",
    "*Note:* Enabling skew detection is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "545575c8-df24-4f0c-971d-5c7f287b04d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_GCS_URI = \"gs://aaa-aca-ml-workshop/beatles/file_out_2485_tags.csv\"  # source of training csv file\n",
    "TARGET = \"Like_The_Beatles\"  # label column\n",
    "\n",
    "SKEW_THRESHOLD_VALUE = 0.05\n",
    "\n",
    "SKEW_THRESHOLDS = {\"ABBA\": SKEW_THRESHOLD_VALUE,\n",
    "                   }\n",
    "\n",
    "skew_config = model_monitoring.SkewDetectionConfig(data_source=TRAIN_DATA_GCS_URI,\n",
    "                                                   skew_thresholds=SKEW_THRESHOLDS,\n",
    "                                                   target_field=TARGET,\n",
    "                                                   data_format=\"csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86280a99-b84c-4710-a3f5-5ffff527e34d",
   "metadata": {},
   "source": [
    "### Assemble the objective specification\n",
    "\n",
    "Finally, you assemble the objective specification `objective_config` with the following settings:\n",
    "\n",
    "- `skew_detection_config`: (Optional) The specification for the skew detection configuration.\n",
    "- `drift_detection_config`: (Optional) The specification for the drift detection configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa755e7d-5654-41ab-bd92-62998075660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_config = model_monitoring.ObjectiveConfig(\n",
    "                                                    skew_detection_config=skew_config,\n",
    "                                                    drift_detection_config=drift_config,\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2e702c-5fa6-4a2d-977c-66e5ff377ce1",
   "metadata": {},
   "source": [
    "## Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3652aa6-7973-43ff-9e58-4f544eac179c",
   "metadata": {},
   "source": [
    "### Create the input schema\n",
    "\n",
    "The monitoring service needs to know the features and data types for the the feature inputs to the model, which is referred to as the `input schema`. \n",
    "\n",
    "For `AutoML` models, the `input schema` is predefined and automatically loaded by the monitoring service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f61664-2a1c-4cb7-9a57-3ee49c9bf75d",
   "metadata": {},
   "source": [
    "### Create the monitoring job\n",
    "\n",
    "You create a monitoring job, with your monitoring specifications, using the `aiplatform.ModelDeploymentMonitoringJob.create()` method, with the following parameters:\n",
    "\n",
    "- `display_name`: The human readable name for the monitoring job.\n",
    "- `project`: The project ID.\n",
    "- `region`: The region.\n",
    "- `endpoint`: The fully qualified resource name of the `Vertex AI Endpoint` to enable monitoring.\n",
    "- `logging_sampling_strategy`: The specification for the sampling configuration.\n",
    "- `schedule_config`: The specification for the scheduling configuration.\n",
    "- `alert_config`: The specification for the alerting configuration.\n",
    "- `objective_configs`: The specification for the objectives configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2d3ab3c-9604-4994-9849-9fbdb5db13be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ModelDeploymentMonitoringJob\n",
      "ModelDeploymentMonitoringJob created. Resource name: projects/354621994428/locations/us-central1/modelDeploymentMonitoringJobs/1365176039596097536\n",
      "To use this ModelDeploymentMonitoringJob in another session:\n",
      "mdm_job = aiplatform.ModelDeploymentMonitoringJob('projects/354621994428/locations/us-central1/modelDeploymentMonitoringJobs/1365176039596097536')\n",
      "View Model Deployment Monitoring Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/model-deployment-monitoring/1365176039596097536?project=354621994428\n",
      "<google.cloud.aiplatform.jobs.ModelDeploymentMonitoringJob object at 0x7f7d44326790> \n",
      "resource name: projects/354621994428/locations/us-central1/modelDeploymentMonitoringJobs/1365176039596097536\n"
     ]
    }
   ],
   "source": [
    "monitoring_job = aiplatform.ModelDeploymentMonitoringJob.create(\n",
    "                                                                display_name=\"beatles_monitoring\",  # for GCP console\n",
    "                                                                project=PROJECT_ID,\n",
    "                                                                location=REGION,\n",
    "                                                                endpoint=endpoint,\n",
    "                                                                logging_sampling_strategy=logging_sampling_strategy,\n",
    "                                                                schedule_config=schedule_config,\n",
    "                                                                alert_config=alerting_config,\n",
    "                                                                objective_configs=objective_config,\n",
    "                                                               )\n",
    "\n",
    "print(monitoring_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2196aecd-32b5-45d5-83b2-f92758991de5",
   "metadata": {},
   "source": [
    "Check current status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4355093-573a-4c36-b699-717811e8fa5c",
   "metadata": {},
   "source": [
    "#### Email notification of the monitoring job.\n",
    "\n",
    "An email notification is sent to the email address in the alerting configuration, notifying that the model monitoring job is now enabled.\n",
    "\n",
    "The contents will appear like:\n",
    "\n",
    "<blockquote>\n",
    "Hello Vertex AI Customer,\n",
    "\n",
    "You are receiving this mail because you are using the Vertex AI Model Monitoring service.\n",
    "This mail is to inform you that we received your request to set up drift or skew detection for the Prediction Endpoint listed below. Starting from now, incoming prediction requests will be sampled and logged for analysis.\n",
    "Raw requests and responses will be collected from prediction service and saved in bq://[your-project-id].model_deployment_monitoring_[endpoint-id].serving_predict .\n",
    "</blockquote>\n",
    "\n",
    "*Note:* You do not need to wait for the email notification to continue to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca34555-5229-4876-9044-2f310e7217b0",
   "metadata": {},
   "source": [
    "#### Monitoring Job State\n",
    "\n",
    "After you start the `Vertex AI Model Monitoring` job, it will be in a `PENDING` state until `skew distribution baseline` is calculated. The monitoring service will initiate a batch job to generate the distribution baseline from the training data. \n",
    "\n",
    "Once the baseline distribution is generated, then the monitoring job will enter `OFFLINE` state. On the per interval basis -- e.g., once an hour, the monitoring job will enter `RUNNING` state while analyzing the sampled data. Once completed, it will return to an `OFFLINE` state while awaiting the next scheduled analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf447d30-eb02-4abb-b31f-6399f60166c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobState.JOB_STATE_PENDING\n"
     ]
    }
   ],
   "source": [
    "jobs = monitoring_job.list(filter=\"display_name=beatles_monitoring\")  # same as in previous cell\n",
    "job = jobs[0]\n",
    "print(job.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93ea9ba-942d-4973-84c6-3c70b7c8f4a1",
   "metadata": {},
   "source": [
    "Wait for a few minutes and check again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c7f0c09-0d84-4765-aa3d-cc900ae9b717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobState.JOB_STATE_PENDING\n"
     ]
    }
   ],
   "source": [
    "print(job.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f6e582-ac54-417a-8b88-f8ef5b9f56cc",
   "metadata": {},
   "source": [
    "Generate synthetic data for prediction requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259c07d2-e75f-42ac-aa72-879e655cdfa6",
   "metadata": {},
   "source": [
    "### Make the prediction requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1694aba9-12e6-4a0d-b6d4-ed98ecd863dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "inference_sample = pd.read_feather('test_data/inference_sample.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1e09437-9214-4080-ac28-4e16c2e2684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a0f6ce4-ba21-4eee-8342-4074de0831af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>30_Seconds_to_Mars</th>\n",
       "      <th>65daysofstatic</th>\n",
       "      <th>A_Perfect_Circle</th>\n",
       "      <th>A_Tribe_Called_Quest</th>\n",
       "      <th>ABBA</th>\n",
       "      <th>ACDC</th>\n",
       "      <th>Adele</th>\n",
       "      <th>Aerosmith</th>\n",
       "      <th>Air</th>\n",
       "      <th>...</th>\n",
       "      <th>tag_shoegazer</th>\n",
       "      <th>tag_hair_metal</th>\n",
       "      <th>tag_rapcore</th>\n",
       "      <th>tag_underground_hip_hop</th>\n",
       "      <th>tag_symphonic_black_metal</th>\n",
       "      <th>tag_darkwave</th>\n",
       "      <th>tag_world</th>\n",
       "      <th>tag_latin</th>\n",
       "      <th>tag_spanish</th>\n",
       "      <th>Like_The_Beatles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thegiant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nezter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>augustohp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stalphonzo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>davenall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Andy_Greenwell</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lilyean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>absentbebnim</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>adherr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>auserzz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 514 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_name  30_Seconds_to_Mars  65daysofstatic  A_Perfect_Circle  \\\n",
       "0        thegiant                 1.0             NaN               NaN   \n",
       "1          nezter                 NaN             NaN               NaN   \n",
       "2       augustohp                 NaN            52.0             502.0   \n",
       "3      stalphonzo                 NaN             NaN               NaN   \n",
       "4        davenall                 NaN             NaN               NaN   \n",
       "5  Andy_Greenwell                 NaN             NaN               NaN   \n",
       "6         lilyean                 NaN             NaN               NaN   \n",
       "7    absentbebnim                 NaN             NaN               NaN   \n",
       "8          adherr                 NaN             NaN               NaN   \n",
       "9         auserzz                 NaN             NaN               NaN   \n",
       "\n",
       "  A_Tribe_Called_Quest  ABBA   ACDC  Adele  Aerosmith   Air  ...  \\\n",
       "0                 None   NaN    NaN   11.0        1.0   NaN  ...   \n",
       "1                 None   NaN    NaN    NaN        NaN   3.0  ...   \n",
       "2                 None   1.0  452.0    1.0      215.0  14.0  ...   \n",
       "3                 None   NaN    6.0    NaN        NaN   NaN  ...   \n",
       "4                 None   NaN    NaN    NaN        NaN   NaN  ...   \n",
       "5                 None   NaN    NaN    NaN        NaN   NaN  ...   \n",
       "6                 None   NaN    NaN    NaN        NaN   NaN  ...   \n",
       "7                 None   NaN    NaN    NaN        NaN   NaN  ...   \n",
       "8                 None   NaN    NaN    NaN        NaN   NaN  ...   \n",
       "9                 None   NaN    NaN   25.0        NaN   NaN  ...   \n",
       "\n",
       "   tag_shoegazer  tag_hair_metal  tag_rapcore  tag_underground_hip_hop  \\\n",
       "0            0.0             0.0          0.0                      0.0   \n",
       "1            0.0             0.0          0.0                      1.0   \n",
       "2            0.0             2.0          1.0                      0.0   \n",
       "3            0.0             0.0          0.0                      0.0   \n",
       "4            0.0             0.0          0.0                      0.0   \n",
       "5            0.0             0.0          0.0                      0.0   \n",
       "6            0.0             0.0          0.0                      0.0   \n",
       "7            0.0             0.0          0.0                      0.0   \n",
       "8            0.0             0.0          0.0                      0.0   \n",
       "9            0.0             1.0          0.0                      0.0   \n",
       "\n",
       "   tag_symphonic_black_metal tag_darkwave  tag_world  tag_latin  tag_spanish  \\\n",
       "0                        0.0          0.0        0.0        0.0          0.0   \n",
       "1                        0.0          0.0        0.0        1.0          1.0   \n",
       "2                        0.0          0.0        0.0        1.0          1.0   \n",
       "3                        0.0          0.0        0.0        0.0          0.0   \n",
       "4                        0.0          0.0        0.0        0.0          0.0   \n",
       "5                        0.0          0.0        0.0        0.0          0.0   \n",
       "6                        0.0          0.0        0.0        0.0          0.0   \n",
       "7                        0.0          0.0        0.0        0.0          0.0   \n",
       "8                        0.0          0.0        0.0        0.0          0.0   \n",
       "9                        0.0          0.0        0.0        1.0          1.0   \n",
       "\n",
       "   Like_The_Beatles  \n",
       "0              True  \n",
       "1             False  \n",
       "2              True  \n",
       "3              True  \n",
       "4             False  \n",
       "5              True  \n",
       "6             False  \n",
       "7             False  \n",
       "8             False  \n",
       "9             False  \n",
       "\n",
       "[10 rows x 514 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da1180b9-b634-45bb-9310-c5c451d050ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def predict_tabular_classification(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    endpoint_name: str,\n",
    "    instances: List[Dict],\n",
    "):\n",
    "    \"\"\"\n",
    "    Args\n",
    "        project: Your project ID or project number.\n",
    "        location: Region where Endpoint is located. For example, 'us-central1'.\n",
    "        endpoint_name: A fully qualified endpoint name or endpoint ID. Example: \"projects/123/locations/us-central1/endpoints/456\" or\n",
    "               \"456\" when project and location are initialized or passed.\n",
    "        instances: A list of one or more instances (examples) to return a prediction for.\n",
    "    \"\"\"\n",
    "    aiplatform.init(project=project, location=location)\n",
    "\n",
    "    endpoint = aiplatform.Endpoint(endpoint_name)\n",
    "\n",
    "    response = endpoint.predict(instances=instances)\n",
    "\n",
    "    for prediction_ in response.predictions:\n",
    "        print(prediction_)\n",
    "        return prediction_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6c2783d-bec4-4e90-bc0e-f81ae136c8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scores': [0.2971574068069458, 0.7028425931930542], 'classes': ['True', 'False']}\n",
      "{'scores': [0.4739128947257996, 0.5260871648788452], 'classes': ['True', 'False']}\n",
      "{'scores': [0.9814208745956421, 0.01857918873429298], 'classes': ['True', 'False']}\n",
      "{'scores': [0.4892224967479706, 0.510777473449707], 'classes': ['True', 'False']}\n",
      "{'scores': [0.02431050315499306, 0.9756895899772644], 'classes': ['True', 'False']}\n",
      "{'scores': [0.03823720291256905, 0.9617628455162048], 'classes': ['True', 'False']}\n",
      "{'scores': [0.03098485246300697, 0.9690151214599609], 'classes': ['True', 'False']}\n",
      "{'classes': ['True', 'False'], 'scores': [0.02387252263724804, 0.9761275053024292]}\n",
      "{'scores': [0.5519230365753174, 0.4480769634246826], 'classes': ['True', 'False']}\n",
      "{'scores': [0.04236870259046555, 0.9576313495635986], 'classes': ['True', 'False']}\n"
     ]
    }
   ],
   "source": [
    "inference_results = []\n",
    "for index, row in inference_sample.iterrows():\n",
    "    instance = json.loads(row.astype(str).to_json())\n",
    "    results = predict_tabular_classification(PROJECT_ID, REGION, 'projects/354621994428/locations/us-central1/endpoints/1823759936992051200', [instance])\n",
    "    inference_results.append(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564ebf3a-2971-4fd0-8514-f19876aacf6a",
   "metadata": {},
   "source": [
    "### Logging sampled requests\n",
    "\n",
    "Once the monitoring service has started, the sampled prediction requests will be logged to Cloud Storage. On the next monitoring interval, the sampled predictions are then copied over to the BigQuery logging table. Once the entries are in the BigQuery table, the monitoring service will analyze the sampled data.\n",
    "\n",
    "Next, you wait for the first logged entres to appear in the BigQuery table used for logging prediction samples. Since you sent 1000 prediction requests, with 50% sampling, you should see around 500 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33072155-eee2-48fd-be6c-006590ba4fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "bqclient = bigquery.Client(project=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79295e2d-def8-4bc5-bd9f-120f099b68e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "while True:\n",
    "    time.sleep(180)\n",
    "\n",
    "    ENDPOINT_ID = endpoint.resource_name.split(\"/\")[-1]\n",
    "\n",
    "    table = bigquery.TableReference.from_string(\n",
    "        f\"{PROJECT_ID}.model_deployment_monitoring_{ENDPOINT_ID}.serving_predict\"\n",
    "    )\n",
    "    rows = bqclient.list_rows(table)\n",
    "    print(rows.total_rows)\n",
    "    if rows.total_rows > 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e36f207-6121-4578-ad62-3e2aae0f679f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "table = bigquery.TableReference.from_string(\n",
    "        f\"{PROJECT_ID}.model_deployment_monitoring_{ENDPOINT_ID}.serving_predict\"\n",
    "    )\n",
    "rows = bqclient.list_rows(table)\n",
    "print(rows.total_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4ae883d-774a-4779-91f5-92af84847a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobState.JOB_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "print(job.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b224ef-d062-430f-9406-b4b9f65e488a",
   "metadata": {},
   "source": [
    "### Skew detection during monitoring\n",
    "\n",
    "The feature input skew detection will occur at the next monitoring interval. In this tutorial, you set the monitoring interval to one hour. So, in about an hour your monitoring job will go from `OFFLINE` to `RUNNING`. While running, it will analyze the logged sampled tables from the predictions during this interval and compare them to the baseline distribution.\n",
    "\n",
    "Once the analysis is completed, the monitoring job will send email notifications on the detected skew, in this case `year`, and the monitoring job will go into `OFFLINE` state until the next interval.\n",
    "\n",
    "#### Wait for monitoring interval\n",
    "\n",
    "It can take upwards of 40 minutes from when the analyis occurred on the monitoring interval to when you receive an email alert.\n",
    "\n",
    "The contents will appear like\n",
    "\n",
    "<blockquote>\n",
    "   Hello Vertex AI Customer,\n",
    "\n",
    "You are receiving this mail because you are subscribing to the Vertex AI Model Monitoring service.\n",
    "This mail is just to inform you that there are some anomalies detected in your deployed models and may need your attention.\n",
    "\n",
    "\n",
    "Basic Information:\n",
    "\n",
    "Endpoint Name: projects/[your-project-id]/locations/us-central1/endpoints/3315907167046860800\n",
    "Monitoring Job: projects/[your-project-id]/locations/us-central1/modelDeploymentMonitoringJobs/8672170640054157312\n",
    "Statistics and Anomalies Root Path(Google Cloud Storage): gs://cloud-ai-platform-773884b1-2a32-48d6-8b83-c03cde416b68/model_monitoring/job-8672170640054157312\n",
    "BigQuery Command: SELECT * FROM `bq://[your-project-id].model_deployment_monitoring_3315907167046860800.serving_predict`\n",
    "\n",
    "\n",
    "Training Prediction Skew Anomalies (Raw Feature):\n",
    "\n",
    "Anomalies Report Path(Google Cloud Storage): gs://cloud-ai-platform-773884b1-2a32-48d6-8b83-c03cde416b68/model_monitoring/job-8672170640054157312/serving/2022-08-25T00:00/stats_and_anomalies/<deployed-model-id>/anomalies/training_prediction_skew_anomalies\n",
    "\n",
    "For more information about the alert, please visit the model monitoring alert page.\n",
    "\n",
    "Deployed model id: <deployed-model-id>\n",
    "\n",
    "Feature name\tAnomaly short description\tAnomaly long description\n",
    "country\tHigh Linfty distance between training and serving\tThe Linfty distance between training and serving is 0.947563 (up to six significant digits), above the threshold 0.5. The feature value with maximum difference is: Year\n",
    "<blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053c083c-dc20-4aa0-85dd-595ab5608eb0",
   "metadata": {},
   "source": [
    "### Delete the monitoring job\n",
    "\n",
    "You can delete the monitoring job using the `delete()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "969d3ba3-eff4-4c70-95ec-bbe3e1043ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitoring_job.pause()\n",
    "monitoring_job.delete()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m104",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m104"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
