{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7430fcab-d000-4c6a-ba10-7e9e8708277b",
   "metadata": {},
   "source": [
    "# Deploy & Run Online Inference\n",
    "\n",
    "Now that we've trained the model, and we are (presumably) happy with the results of training, we can deploy the model to a Vertex AI endpoint and use online predictions in order to test out a sample datapoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81f76e5-7601-4c49-b580-105fb3243388",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = 'mwpmltr'\n",
    "LOCATION = \"us-central1\"\n",
    "MODEL_NAME = \"beatles_automl_file_out_2200_tags\"\n",
    "TARGET_COLUMN = \"Like_The_Beatles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35274ac6-fbd2-4138-95d6-6faea2b058ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dac1aaa-8b82-411c-bb25-e397631f6e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_endpoint(\n",
    "    project: str,\n",
    "    display_name: str,\n",
    "    location: str,\n",
    "):\n",
    "    \"\"\"Create an Vertex AI Model Endpoint in the given project and location\"\"\"\n",
    "    \n",
    "    aiplatform.init(project=project, location=location)\n",
    "\n",
    "    endpoint = aiplatform.Endpoint.create(\n",
    "        display_name=display_name,\n",
    "        project=project,\n",
    "        location=location,\n",
    "    )\n",
    "\n",
    "    print(endpoint.display_name)\n",
    "    print(endpoint.resource_name)\n",
    "    return endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3b443a-a111-46cc-a6f1-ec4d9f645d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that you don't have to create an endpoint every time you run this notebook\n",
    "# create_endpoint(PROJECT_NAME, f'{MODEL_NAME}_endpoint', LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e226cd-1690-43ae-bde1-8803a919ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_model(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    model_name: str,\n",
    "    endpoint_name: str\n",
    "):\n",
    "    \"\"\"\n",
    "    model_name: A fully-qualified model resource name or model ID.\n",
    "    endpoint_name: A fully-qualified endpoint resource name or endpoint ID.\n",
    "    \"\"\"\n",
    "\n",
    "    aiplatform.init(project=project, location=location)\n",
    "\n",
    "    model = aiplatform.Model(model_name=model_name)\n",
    "    endpoint = aiplatform.Endpoint(endpoint_name=endpoint_name)\n",
    "\n",
    "    model.deploy(\n",
    "        endpoint=endpoint,\n",
    "        machine_type=\"e2-standard-4\"\n",
    "    )\n",
    "\n",
    "    model.wait()\n",
    "\n",
    "    print(model.display_name)\n",
    "    print(model.resource_name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a09d5b6-3fde-43b0-853b-f2cf3b282762",
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_model(\n",
    "    PROJECT_NAME,\n",
    "    LOCATION,\n",
    "    \"projects/55590906972/locations/us-central1/models/8112673977777782784\",\n",
    "    \"projects/55590906972/locations/us-central1/endpoints/3602110043756953600\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c0aaac-db81-4d6f-8c0e-d40429140351",
   "metadata": {},
   "source": [
    "Now that the model is deployed to the prediction endpoint, we will use our test data point and make an API call to the Vertex AI online inference service, in order to predict whether this user would like the Beatles or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118063b9-b95c-4a6d-b9e2-82e2efad9d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def predict_tabular_classification(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    endpoint_name: str,\n",
    "    instances: List[Dict],\n",
    "):\n",
    "    \"\"\"\n",
    "    Args\n",
    "        project: Your project ID or project number.\n",
    "        location: Region where Endpoint is located. For example, 'us-central1'.\n",
    "        endpoint_name: A fully qualified endpoint name or endpoint ID. Example: \"projects/123/locations/us-central1/endpoints/456\" or\n",
    "               \"456\" when project and location are initialized or passed.\n",
    "        instances: A list of one or more instances (examples) to return a prediction for.\n",
    "    \"\"\"\n",
    "    aiplatform.init(project=project, location=location)\n",
    "\n",
    "    endpoint = aiplatform.Endpoint(endpoint_name)\n",
    "\n",
    "    response = endpoint.predict(instances=instances)\n",
    "\n",
    "    for prediction_ in response.predictions:\n",
    "        print(prediction_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86642cc-435f-40f1-bb21-e5d829412c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "inference_sample = pd.read_feather('test_data/inference_sample.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76147087-381d-4971-8046-7b5cf7cdbb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in inference_sample.iterrows():\n",
    "    instance = json.loads(row.astype(str).to_json())\n",
    "    inference_results = predict_tabular_classification(PROJECT_NAME, LOCATION, 'projects/55590906972/locations/us-central1/endpoints/3602110043756953600', [instance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d739dee6-25cb-4fbc-9cc0-f06867675f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('sample_request.json', 'w') as outfile:\n",
    "    outfile.write(inference_sample.iloc[0].astype(str).to_json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad662fa-be4b-452e-80e8-9b51744b7524",
   "metadata": {},
   "source": [
    "### Undeploy Model from Vertex AI Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0e9c36-91ec-4da2-846d-05c9cbee68cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e79ea956-0440-4362-8602-864468604a57",
   "metadata": {},
   "source": [
    "### Pricing Notes\n",
    "Resources that incur costs\n",
    "Answer: you pay for three main activities\n",
    "- Training the model\n",
    "    - Price per node hour of tabular classification is $21.252, so that's the charge I incur every time I train the AutoML Beatles Model\n",
    "- Deploying the model to an endpoint (models must be deployed before they can make either online predictions or online evaluations)\n",
    "    - You pay for each model deployed to an endpoint, even if no prediction is made\n",
    "    - Must undeploy your model to stop incurring further charges\n",
    "    - Models that are not deployed or have failed to deploy are not charged\n",
    "- Using the model to make predictions; this is for both batch and online predictions (which I think is BS, since we're also paying to host the model at an endpoint, but whatever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8737fc2a-d702-4c7e-8903-60178cabc22c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m98",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m98"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
